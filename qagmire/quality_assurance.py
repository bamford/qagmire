# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_quality_assurance.ipynb.

# %% auto 0
__all__ = ['Diagnostics']

# %% ../nbs/02_quality_assurance.ipynb 3
import time
import warnings
from abc import ABC, abstractmethod
from contextlib import nullcontext

import dask
import numpy as np
import pandas as pd
import xarray as xr
from dask import distributed

# %% ../nbs/02_quality_assurance.ipynb 5
# To avoid errors, we need to use dask single-threaded.
dask.config.set(scheduler="single-threaded")


class Diagnostics(ABC):
    """An abstract class to be subclassed to perform specific diagnostic checks.

    A subclass should perform a set of checks, implemented in a method named `tests`.

    Calling the method `run` will combine and compute the tests, putting the results
    as a single boolean `DataArray` the `detail` attribute for further analysis.

    Once `run` has been called, a `test_descriptions` will also be available, and
    summaries of the test results can be created using the `summary` method.
    """

    def __init__(
        self,
        n_processes=1,  # how many subprocesses to use for computing the tests
    ):
        """Initialise the diagnostic.

        If the subclass has options, these may be added like this:
        ```
        def __init__(
            self,
            tolerance: float = 0.0,  # the tolerance for the test
        ):
            self.tolerance = tolerance
            super().__init__()
        ```
        then `self.tolerance` can be used in the implementation of `tests`.
        """
        self.test_descriptions = None
        self.detail = None
        self.data = None
        self.stats = None
        self.n_processes = n_processes

    def run(self, **kwargs) -> xr.DataArray:
        """Compute the results of the tests.

        The `kwargs` are passed to `qagmire.data.read_*` functions to obtain the data
        for the tests.
        """
        start = time.perf_counter()
        tests = self.tests(**kwargs)
        dt = time.perf_counter() - start
        print(f"Tests took {dt:.2f} s to prepare (including reading data).")
        test_names = [t["name"] for t in tests]
        test_desc = [t["description"] for t in tests]
        self.test_descriptions = dict(zip(test_names, test_desc))
        test_array = [t["test"] for t in tests]
        detail = xr.concat(test_array, pd.Index(test_names, name="test"))
        detail.name = "failed"
        start = time.perf_counter()
        if self.n_processes > 1:
            maybe_dask_cluster = distributed.Client(
                n_workers=self.n_processes, threads_per_worker=1, memory_limit="2GiB"
            )
        else:
            maybe_dask_cluster = nullcontext()
        with warnings.catch_warnings(
            action="ignore", category=distributed.comm.core.CommClosedError
        ):
            with maybe_dask_cluster as _:
                with np.errstate(divide="ignore", invalid="ignore"):
                    # Tests may issues warnings, e.g. when calculating statistics on an
                    # all-NaN spectrum, these can usually be safely ignored.
                    # Unfortunately, this does not suppress warnings when running
                    # on a dask cluster.
                    self.detail = dask.compute(detail)[0]
        detail.close()
        dt = time.perf_counter() - start
        print(f"Tests took {dt:.2f} s to perform.")
        for name, desc in self.test_descriptions.items():
            print(f"{name}:\n    {desc}")

    @abstractmethod
    def tests(self, **kwargs):
        """Return the tests to be performed.

        Implementations of this method must pass `kwargs` to `qagmire.data.read_*` functions
        as necessary to obtain the data for the tests.

        This method must returns a list of dictionaries with the structure:
        ```
        [
            {
                "name": "a_short_name",
                "description": "The question that the test answers",
                "test": test_dataset,
            },
            ...
        ]
        ```
        where each `test_dataset` should be a boolean `xr.DataArray` of the same shape, giving
        the results of running the test on the data defined by `kwargs`.

        Note that it can be convenient to assign `self.data` and/or `self.stats` inside `tests`,
        to provide a way of accessing the source data and/or statistics for verification purposes,
        without having to construct them again.
        """
        return [
            {
                "name": "a_short_name",
                "description": "The question that the test answers",
                "test": None,
            },
        ]

    def summary(
        self,
        by: str | None = None,  # optionally sum element dims except for this one
        show_passed_tests=False,  # if `True`, then passed tests are included
        show_passed_elements=False,  # if `True`, then passed elements are included
        sort_by_total_fails=True,  # if `False`, then sort by index
        show_failure_count=True,  # if `False`, then omit the count of failures per row
        show_only_failure_count=False,  # if `True`, then only show the count of failures
        per_test=False,  # if `True`, then transpose output, such that each row is a test
        top: int | None = None,  # optionally limit to at most `top` elements
    ) -> pd.DataFrame:
        """Return a summary of the test failures."""
        if self.detail is None:
            print("You need to call `run` first.")
            return None
        df = self.detail.to_dataframe(name="failed")
        idx = [c for c in df.columns if c != "failed"]
        df = df.set_index(idx, append=True)
        df = df.unstack() if per_test else df.unstack("test")
        if by is not None:
            df = df.groupby(by).sum()
        if (not show_passed_tests and not per_test) or (
            not show_passed_elements and per_test
        ):
            df = df.loc[:, df.any(axis="rows")]
        if (not show_passed_elements and not per_test) or (
            not show_passed_tests and per_test
        ):
            df = df.loc[df.loc[:, "failed"].any(axis="columns")]
        df.loc[:, "total fails"] = df.sum(axis="columns")
        df = df.sort_index()
        if sort_by_total_fails:
            df = df.sort_values("total fails", ascending=False, kind="stable")
        if not (show_failure_count or show_only_failure_count):
            df = df.drop(columns="total fails")
        if show_only_failure_count:
            df = df.drop(columns="failed")
        if top is not None:
            df = df.iloc[:top]
        return df

    def summary_per_test(
        self,
        by: str | None = None,  # optionally sum element dims except for this one
    ) -> pd.DataFrame:
        """Return a per-test summary of the test outcomes in `detail`."""
        return self.summary(
            by=by,
            per_test=True,
            show_passed_tests=True,
            show_only_failure_count=True,
        )

    def full_summary(
        self,
        by: str | None = None,  # optionally sum element dims except for this one
    ) -> pd.DataFrame:
        """Return a full summary of the test outcomes in `detail`."""
        return self.summary(
            by=by,
            show_passed_tests=True,
            show_passed_elements=True,
            sort_by_total_fails=False,
            show_failure_count=False,
            top=None,
        )
