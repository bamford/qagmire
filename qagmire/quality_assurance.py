# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_quality_assurance.ipynb.

# %% auto 0
__all__ = ['Diagnostics', 'ObsCondCheck', 'LineFluxCheck']

# %% ../nbs/02_quality_assurance.ipynb 3
import time
from abc import ABC, abstractmethod

import dask
import numpy as np
import pandas as pd
import xarray as xr

from qagmire.data import (
    get_lr_l1_single_files,
    get_lr_l2_stack_files,
    read_class_spec,
    read_class_table,
    read_galaxy_table,
    read_primary_header,
)
from .utilities import parse_line_names, parse_obstemp

# %% ../nbs/02_quality_assurance.ipynb 5
class Diagnostics(ABC):
    """An abstract class to be subclassed to perform specific diagnostic checks.

    A subclass should perform a set of checks, implemented in a method named `tests`.

    Calling the method `run` will combine and compute the tests, returning the results
    as a single boolean `DataArray` for further analysis.
    """

    def run(self, **kwargs) -> xr.DataArray:
        """Compute the results of the tests.

        The `kwargs` are passed to `qagmire.data.read_*` functions to obtain the data
        for the tests.
        """
        tests = self.tests(**kwargs)
        test_names = [t["name"] for t in tests]
        test_desc = [t["description"] for t in tests]
        self.test_descriptions = dict(zip(test_names, test_desc))
        test_array = [t["test"] for t in tests]
        detail = xr.concat(test_array, pd.Index(test_names, name="test"))
        start = time.perf_counter()
        detail = dask.compute(detail)[0]
        dt = time.perf_counter() - start
        print(f"Tests took {dt:.2f} s to perform.")
        return detail

    @abstractmethod
    def tests(self, **kwargs):
        """Return the tests to be performed.

        Implementations of this method must pass `kwargs` to `qagmire.data.read_*` functions
        as necessary to obtain the data for the tests.

        This method must returns a list of dictionaries with the structure:
        ```
        [
            {
                "name": "a_short_name",
                "description": "The question that the test answers",
                "test": test_dataset,
            },
            ...
        ]
        ```
        where each `test_dataset` should be a boolean `xr.DataArray` of the same shape, giving
        the results of running the test on the data defined by `kwargs`.
        """
        return [
            {
                "name": "a_short_name",
                "description": "The question that the test answers",
                "test": None,
            },
        ]

    @staticmethod
    def summary(
        detail: xr.DataArray,  # the detailed test results
        by: str | None = None,  # optionally sum element dims except for this one
        show_passed_tests=False,  # if `True`, then passed tests are included
        show_passed_elements=False,  # if `True`, then passed elements are included
        sort_by_total_fails=True,  # if `False`, then keep in original order
        show_failure_count=True,  # if `False`, then omit the count of failures per row
        show_only_failure_count=False,  # if `True`, then only show the count of failures
        per_test=False,  # if `True`, then transpose output, such that each row is a test
        top: int | None = None,  # optionally limit to at most `top` elements
    ) -> pd.DataFrame:
        """Return a summary of the test failures in `detail`."""
        if by is not None:
            detail = detail.sum(dim=[d for d in detail.dims if d not in ("test", by)])
        df = detail.to_dataframe(name="failed")
        df = df.unstack() if per_test else df.unstack("test")
        if (not show_passed_tests and not per_test) or (
            not show_passed_elements and per_test
        ):
            df = df.loc[:, df.any(axis="rows")]
        if (not show_passed_elements and not per_test) or (
            not show_passed_tests and per_test
        ):
            df = df.loc[df.loc[:, "failed"].any(axis="columns")]
        df.loc[:, "total fails"] = df.sum(axis="columns")
        if sort_by_total_fails:
            df = df.sort_values("total fails", ascending=False)
        if not (show_failure_count or show_only_failure_count):
            df = df.drop(columns="total fails")
        if show_only_failure_count:
            df = df.drop(columns="failed")
        if top is not None:
            df = df.iloc[:top]
        return df

    @classmethod
    def summary_per_test(
        cls,
        detail: xr.DataArray,  # the detailed test results
        by: str | None = None,  # optionally sum element dims except for this one
    ) -> pd.DataFrame:
        """Return a per-test summary of the test outcomes in `detail`."""
        return cls.summary(
            detail,
            by=by,
            per_test=True,
            show_passed_tests=True,
            show_only_failure_count=True,
        )

    @classmethod
    def full_summary(
        cls,
        detail: xr.DataArray,  # the detailed test results
        by: str | None = None,  # optionally sum element dims except for this one
    ) -> pd.DataFrame:
        """Return a full summary of the test outcomes in `detail`."""
        return cls.summary(
            detail,
            by=by,
            show_passed_tests=True,
            show_passed_elements=True,
            sort_by_total_fails=False,
            show_failure_count=False,
            top=None,
        )

# %% ../nbs/02_quality_assurance.ipynb 14
class ObsCondCheck(Diagnostics):
    """Observing conditions check.

    A reproduction of the weaveio [obs_cond_check](https://github.com/bamford/QAG/blob/master/diagnostics/obs_cond_checks.py).

    This tests for the following cases:

    * Is the sky brighter than the requirement?
    * Is the seeing worse than the requirement?

    and also some supplementary tests:

    * Are there the other than two runs with the same MJD?
    * Do runs with the same MJD have different sky brightness?
    * Do runs with the same MJD have different seeing?
    """

    def __init__(
        self,
        sky_tolerance: float = 0.0,  # the tolerance in the sky brightness in magnitudes
        seeing_tolerance: float = 0.0,  # the tolerance in the seeing in arcsec
        by_exposure=False,  # should the checks be performed per exposure, or per OB (the default)
    ):
        self.sky_tolerance = sky_tolerance
        self.seeing_tolerance = seeing_tolerance
        if by_exposure:
            self._get_and_check = self._get_and_check_by_exp
        else:
            self._get_and_check = self._get_and_check_by_ob

    @staticmethod
    def _restore_coords(coords, da):
        return [d.assign_coords(coords) for d in da]

    @classmethod
    def _get_and_check_by_exp(cls, col):
        coords = (
            col.swap_dims(filename="MJD")
            .coords.to_dataset()
            .reset_coords()
            .groupby("MJD")
            .first()
        )
        by_exp = col.groupby("MJD")
        count, first, last = cls._restore_coords(
            coords, (by_exp.count(), by_exp.first(), by_exp.last())
        )
        expected_runs = count == 2
        runs_match = first == last
        return first, expected_runs, runs_match

    @staticmethod
    def _get_and_check_by_ob(col):
        by_ob = col.groupby("OBID")
        count, first = (by_ob.count(), by_ob.first())
        expected_runs = count == 6
        runs_match = (first != col).any(axis=-1)
        return first, expected_runs, runs_match

    def tests(
        self,
        **kwargs,
    ):
        files = get_lr_l1_single_files(**kwargs)
        hdr = read_primary_header(files)

        obstemp, two_runs, obstemp_runs_match = self._get_and_check(hdr["OBSTEMP"])
        obs = parse_obstemp(obstemp)

        sky, _, sky_runs_match = self._get_and_check(hdr["SKYBRTEL"])
        sky_fail = sky < obs["sky_brightness"] - self.sky_tolerance
        seeing, _, seeing_runs_match = self._get_and_check(hdr["SEEINGB"])
        seeing_fail = seeing > obs["seeing"] + self.seeing_tolerance

        tests = [
            {
                "name": "sky_too_bright",
                "description": "Is the sky brighter than the requirement?",
                "test": ~sky_fail,
            },
            {
                "name": "seeing_too_poor",
                "description": "Is the seeing worse than the requirement?",
                "test": ~seeing_fail,
            },
            {
                "name": "wrong_run_count",
                "description": "Are there the other than six runs in each OB?",
                "test": ~two_runs,
            },
            {
                "name": "unmatched_runs_sky",
                "description": "Do runs in the same OB have different sky brightness?",
                "test": ~sky_runs_match,
            },
            {
                "name": "unmatched_runs_seeing",
                "description": "Do runs in the same OB have different seeing?",
                "test": ~seeing_runs_match,
            },
        ]
        return tests

# %% ../nbs/02_quality_assurance.ipynb 19
class LineFluxCheck(Diagnostics):
    """A reproduction of the weaveio [line_flux_check](https://github.com/bamford/QAG/blob/master/diagnostics/line_flux_check.py).

    This tests for the following cases:

    * Do non-null line fluxes appear in completely null spectra?
    * Do non-null line fluxes appear in the blue chip gap?
    * Do non-null line fluxes appear in the red chip gap?
    * Do non-null line fluxes appear outside the observed wavelength range?
    * Do null line fluxes appear in an observed wavelength range?
    """

    @staticmethod
    def _line_wavelengths(
        galaxy_table: xr.Dataset,  # provides the wavelengths of all lines in the data
        class_table: xr.Dataset,  # provides the redshift of each spectrum
    ) -> xr.Dataset:  # the observed wavelength of every potential line
        """Determine the expected observed wavelengths of all potential lines."""
        line_species, line_rest_wl = parse_line_names(galaxy_table["LINE"])
        line_wl = (1 + class_table["Z"]) * line_rest_wl
        return line_wl

    @staticmethod
    def _wavelength_boundaries(
        class_spec: xr.Dataset,  # provides the rebinned spectra to check
    ) -> tuple[dict, dict]:  # the determined boundaries
        """Determine wavelength boundaries and wavelength gaps of blue and red spectra.

        Where a spectrum is entirely null, the returned gaps and boundaries will also be null.

        Returns two dictionaries, `boundaries` and `gaps`, each containing `low` and `high` entries,
        which are Datasets giving the low and high boundaries and gap edges determined for each spectrum.
        """
        gaps = {}
        boundaries = {}
        for band, low, high in (("B", 4000, 6000), ("R", 6000, 9000)):
            wl_dim = f"LAMBDA_{band}"
            wl = class_spec[wl_dim]
            null_flux = class_spec[f"FLUX_RR_{band}"].isnull()
            wl_null = wl.where(null_flux & (wl > low) & (wl < high))
            wl_not_null = wl.where(~null_flux)
            with np.errstate(invalid="ignore"):
                gaps[band] = {
                    "low": wl_null.min(dim=wl_dim),
                    "high": wl_null.max(dim=wl_dim),
                }
                boundaries[band] = {
                    "low": wl_not_null.min(dim=wl_dim),
                    "high": wl_not_null.max(dim=wl_dim),
                }
        return boundaries, gaps

    def tests(self, **kwargs):
        lr_l2_stack_files = get_lr_l2_stack_files(**kwargs)

        class_spec = read_class_spec(lr_l2_stack_files)
        galaxy_table = read_galaxy_table(lr_l2_stack_files)
        class_table = read_class_table(lr_l2_stack_files)

        line_wl = self._line_wavelengths(galaxy_table, class_table)
        boundaries, gaps = self._wavelength_boundaries(class_spec)

        measured_line_flux = galaxy_table["LINES"].sel(QTY="FLUX", drop=True)
        null_flux = measured_line_flux.isnull()

        is_in_red_gap = (line_wl > gaps["R"]["low"]) & (line_wl < gaps["R"]["high"])
        is_in_blue_gap = (line_wl > gaps["B"]["low"]) & (line_wl < gaps["B"]["high"])

        # ignore gaps in completely null spectra
        is_in_red_gap = is_in_red_gap.fillna(False)
        is_in_blue_gap = is_in_blue_gap.fillna(False)

        is_in_gap = is_in_blue_gap | is_in_red_gap

        is_off_spectrum = (
            (line_wl < boundaries["B"]["low"]) | (line_wl > boundaries["B"]["high"])
        ) & ((line_wl < boundaries["R"]["low"]) | (line_wl > boundaries["R"]["high"]))

        is_on_spectrum = ~is_in_gap & ~is_off_spectrum

        # ignore whether on/off spectrum for completely null spectra
        is_off_spectrum = is_off_spectrum.fillna(False)
        is_on_spectrum = is_in_blue_gap.fillna(False)

        null_spectrum = (
            boundaries["B"]["low"].isnull() | boundaries["R"]["low"].isnull()
        )

        tests = [
            {
                "name": "line_in_null_spectrum",
                "description": "Do non-null line fluxes appear in completely null spectra?",
                "test": ~null_flux & null_spectrum,
            },
            {
                "name": "line_in_blue_chip_gap",
                "description": "Do non-null line fluxes appear in the blue chip gap?",
                "test": ~null_flux & is_in_blue_gap,
            },
            {
                "name": "line_in_red_chip_gap",
                "description": "Do non-null line fluxes appear in the red chip gap?",
                "test": ~null_flux & is_in_red_gap,
            },
            {
                "name": "line_off_spectrum",
                "description": "Do non-null line fluxes appear outside the observed wavelength range?",
                "test": ~null_flux & is_off_spectrum,
            },
            {
                "name": "null_line_on_spectrum",
                "description": "Do null line fluxes appear in an observed wavelength range?",
                "test": null_flux & is_on_spectrum,
            },
        ]
        return tests
