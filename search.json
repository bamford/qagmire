[
  {
    "objectID": "diagnostics/l1_spectrum_value_check.html",
    "href": "diagnostics/l1_spectrum_value_check.html",
    "title": "L1 spectrum value check",
    "section": "",
    "text": "To write checks of the data, we create a subclass of Diagnostics and implement the tests method.\nsource",
    "crumbs": [
      "diagnostics",
      "L1 spectrum value check"
    ]
  },
  {
    "objectID": "diagnostics/l1_spectrum_value_check.html#demonstration-tests",
    "href": "diagnostics/l1_spectrum_value_check.html#demonstration-tests",
    "title": "L1 spectrum value check",
    "section": "Demonstration tests",
    "text": "Demonstration tests\nWe use multiple dask workers to speed up this test. Checking 15 billion pixels takes ~45 seconds with 8 workers.\n\nRed camera\n\nred_tests = L1SpectrumValueCheck(camera=\"RED\", n_processes=8)\nred_tests.run(date=\"201*\")\n\nLocating and converting where necessary:   0%|                                                                                     | 0/126 [00:00&lt;?, ?it/s]Locating and converting where necessary:   1%|▌                                                                            | 1/126 [00:01&lt;03:04,  1.47s/it]Locating and converting where necessary:   2%|█▏                                                                           | 2/126 [00:01&lt;01:23,  1.49it/s]Locating and converting where necessary:   2%|█▊                                                                           | 3/126 [00:01&lt;00:51,  2.40it/s]Locating and converting where necessary:   4%|███                                                                          | 5/126 [00:01&lt;00:27,  4.34it/s]Locating and converting where necessary:   5%|███▋                                                                         | 6/126 [00:02&lt;00:24,  4.88it/s]Locating and converting where necessary:   6%|████▎                                                                        | 7/126 [00:02&lt;00:34,  3.44it/s]Locating and converting where necessary:   6%|████▉                                                                        | 8/126 [00:03&lt;00:43,  2.71it/s]Locating and converting where necessary:   7%|█████▌                                                                       | 9/126 [00:03&lt;00:40,  2.87it/s]Locating and converting where necessary:   8%|██████                                                                      | 10/126 [00:03&lt;00:32,  3.58it/s]Locating and converting where necessary:  10%|███████▏                                                                    | 12/126 [00:03&lt;00:27,  4.11it/s]Locating and converting where necessary:  10%|███████▊                                                                    | 13/126 [00:04&lt;00:27,  4.14it/s]Locating and converting where necessary:  12%|█████████                                                                   | 15/126 [00:05&lt;00:57,  1.92it/s]Locating and converting where necessary:  13%|█████████▋                                                                  | 16/126 [00:25&lt;08:51,  4.83s/it]Locating and converting where necessary:  13%|██████████▎                                                                 | 17/126 [00:25&lt;06:49,  3.75s/it]Locating and converting where necessary:  16%|████████████                                                                | 20/126 [00:26&lt;03:23,  1.92s/it]Locating and converting where necessary:  17%|████████████▋                                                               | 21/126 [00:26&lt;02:52,  1.64s/it]Locating and converting where necessary:  17%|█████████████▎                                                              | 22/126 [00:27&lt;02:16,  1.31s/it]Locating and converting where necessary:  19%|██████████████▍                                                             | 24/126 [00:27&lt;01:29,  1.14it/s]Locating and converting where necessary:  20%|███████████████                                                             | 25/126 [00:27&lt;01:21,  1.24it/s]Locating and converting where necessary:  21%|███████████████▋                                                            | 26/126 [00:28&lt;01:21,  1.23it/s]Locating and converting where necessary:  21%|████████████████▎                                                           | 27/126 [00:28&lt;01:05,  1.51it/s]Locating and converting where necessary:  23%|█████████████████▍                                                          | 29/126 [00:29&lt;00:46,  2.09it/s]Locating and converting where necessary:  24%|██████████████████                                                          | 30/126 [00:29&lt;00:40,  2.40it/s]Locating and converting where necessary:  25%|██████████████████▋                                                         | 31/126 [00:29&lt;00:33,  2.83it/s]Locating and converting where necessary:  25%|███████████████████▎                                                        | 32/126 [00:29&lt;00:27,  3.39it/s]Locating and converting where necessary:  26%|███████████████████▉                                                        | 33/126 [00:30&lt;00:30,  3.03it/s]Locating and converting where necessary:  27%|████████████████████▌                                                       | 34/126 [00:30&lt;00:26,  3.53it/s]Locating and converting where necessary:  28%|█████████████████████                                                       | 35/126 [00:30&lt;00:24,  3.74it/s]Locating and converting where necessary:  29%|█████████████████████▋                                                      | 36/126 [00:30&lt;00:20,  4.36it/s]Locating and converting where necessary:  29%|██████████████████████▎                                                     | 37/126 [00:31&lt;00:23,  3.72it/s]Locating and converting where necessary:  30%|██████████████████████▉                                                     | 38/126 [00:31&lt;00:22,  3.93it/s]Locating and converting where necessary:  31%|███████████████████████▌                                                    | 39/126 [00:31&lt;00:25,  3.36it/s]Locating and converting where necessary:  33%|████████████████████████▋                                                   | 41/126 [00:32&lt;00:18,  4.51it/s]Locating and converting where necessary:  33%|█████████████████████████▎                                                  | 42/126 [00:32&lt;00:19,  4.24it/s]Locating and converting where necessary:  34%|█████████████████████████▉                                                  | 43/126 [00:32&lt;00:22,  3.70it/s]Locating and converting where necessary:  37%|███████████████████████████▋                                                | 46/126 [00:33&lt;00:17,  4.66it/s]Locating and converting where necessary:  38%|████████████████████████████▉                                               | 48/126 [00:34&lt;00:21,  3.56it/s]Locating and converting where necessary:  40%|██████████████████████████████▊                                             | 51/126 [00:34&lt;00:16,  4.56it/s]Locating and converting where necessary:  41%|███████████████████████████████▎                                            | 52/126 [00:34&lt;00:15,  4.74it/s]Locating and converting where necessary:  42%|███████████████████████████████▉                                            | 53/126 [00:39&lt;01:15,  1.04s/it]Locating and converting where necessary:  43%|████████████████████████████████▌                                           | 54/126 [00:39&lt;01:00,  1.19it/s]Locating and converting where necessary:  44%|█████████████████████████████████▊                                          | 56/126 [00:39&lt;00:44,  1.56it/s]Locating and converting where necessary:  45%|██████████████████████████████████▍                                         | 57/126 [00:40&lt;00:43,  1.59it/s]Locating and converting where necessary:  47%|███████████████████████████████████▌                                        | 59/126 [00:44&lt;01:13,  1.10s/it]Locating and converting where necessary:  95%|███████████████████████████████████████████████████████████████████████▍   | 120/126 [00:44&lt;00:00, 14.71it/s]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████| 126/126 [00:48&lt;00:00,  7.56it/s]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████| 126/126 [00:48&lt;00:00,  2.61it/s]\nReading netCDF files... took 7.01 s. Size is 57535.394 Mb\nTests took 57.80 s to prepare (including reading data).\nTests took 29.26 s to perform.\nnans_in_RED_FLUX:\n    Are there non-finite values in RED_FLUX?\nnans_in_RED_FLUX_NOSS:\n    Are there non-finite values in RED_FLUX_NOSS?\nnans_in_RED_IVAR:\n    Are there non-finite values in RED_IVAR?\nnans_in_RED_IVAR_NOSS:\n    Are there non-finite values in RED_IVAR_NOSS?\nnans_in_RED_SENSFUNC:\n    Are there non-finite values in RED_SENSFUNC?\nnegs_in_RED_IVAR:\n    Are there negative values in RED_IVAR?\nnegs_in_RED_IVAR_NOSS:\n    Are there negative values in RED_IVAR_NOSS?\nnegs_in_RED_SENSFUNC:\n    Are there negative values in RED_SENSFUNC?\n\n\n\nred_tests.summary(by=\"RUN\")\n\n8 varieties of test and 60480 tested elements per variety, for total of 483840 tests.\n60300 tests failed (12.46%) and 423540 tests passed (87.54%).\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\ntest\nnans_in_RED_FLUX\nnans_in_RED_FLUX_NOSS\nnans_in_RED_IVAR\nnans_in_RED_IVAR_NOSS\nnans_in_RED_SENSFUNC\n\n\n\nRUN\n\n\n\n\n\n\n\n\n\n\n1004097\n960\n960\n960\n960\n960\n4800\n\n\n1004099\n960\n960\n960\n960\n960\n4800\n\n\n1004101\n960\n960\n960\n960\n960\n4800\n\n\n1004109\n960\n960\n960\n960\n960\n4800\n\n\n1004111\n960\n960\n960\n960\n960\n4800\n\n\n1004113\n960\n960\n960\n960\n960\n4800\n\n\n1004121\n960\n960\n960\n960\n960\n4800\n\n\n1004123\n960\n960\n960\n960\n960\n4800\n\n\n1004125\n960\n960\n960\n960\n960\n4800\n\n\n1004145\n960\n960\n960\n960\n960\n4800\n\n\n1004147\n960\n960\n960\n960\n960\n4800\n\n\n1004149\n960\n960\n960\n960\n960\n4800\n\n\n1002249\n20\n20\n20\n20\n20\n100\n\n\n1002251\n20\n20\n20\n20\n20\n100\n\n\n1002253\n20\n20\n20\n20\n20\n100\n\n\n1002261\n20\n20\n20\n20\n20\n100\n\n\n1002263\n20\n20\n20\n20\n20\n100\n\n\n1002265\n20\n20\n20\n20\n20\n100\n\n\n1002285\n20\n20\n20\n20\n20\n100\n\n\n1002287\n20\n20\n20\n20\n20\n100\n\n\n1002289\n20\n20\n20\n20\n20\n100\n\n\n1002309\n20\n20\n20\n20\n20\n100\n\n\n1002311\n20\n20\n20\n20\n20\n100\n\n\n1002313\n20\n20\n20\n20\n20\n100\n\n\n1002321\n20\n20\n20\n20\n20\n100\n\n\n1002323\n20\n20\n20\n20\n20\n100\n\n\n1002325\n20\n20\n20\n20\n20\n100\n\n\n1002345\n20\n20\n20\n20\n20\n100\n\n\n1002347\n20\n20\n20\n20\n20\n100\n\n\n1002349\n20\n20\n20\n20\n20\n100\n\n\n1003329\n20\n20\n20\n20\n20\n100\n\n\n1003331\n20\n20\n20\n20\n20\n100\n\n\n1003333\n20\n20\n20\n20\n20\n100\n\n\n1003353\n20\n20\n20\n20\n20\n100\n\n\n1003355\n20\n20\n20\n20\n20\n100\n\n\n1003357\n20\n20\n20\n20\n20\n100\n\n\n1003437\n20\n20\n20\n20\n20\n100\n\n\n1003439\n20\n20\n20\n20\n20\n100\n\n\n1003441\n20\n20\n20\n20\n20\n100\n\n\n\n\n\n\n\n\n\nred_tests.summary(by=\"NSPEC\")\n\n8 varieties of test and 60480 tested elements per variety, for total of 483840 tests.\n60300 tests failed (12.46%) and 423540 tests passed (87.54%).\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\ntest\nnans_in_RED_FLUX\nnans_in_RED_FLUX_NOSS\nnans_in_RED_IVAR\nnans_in_RED_IVAR_NOSS\nnans_in_RED_SENSFUNC\n\n\n\nNSPEC\n\n\n\n\n\n\n\n\n\n\n941\n39\n39\n39\n39\n39\n195\n\n\n942\n39\n39\n39\n39\n39\n195\n\n\n943\n39\n39\n39\n39\n39\n195\n\n\n944\n39\n39\n39\n39\n39\n195\n\n\n945\n39\n39\n39\n39\n39\n195\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n936\n12\n12\n12\n12\n12\n60\n\n\n937\n12\n12\n12\n12\n12\n60\n\n\n938\n12\n12\n12\n12\n12\n60\n\n\n939\n12\n12\n12\n12\n12\n60\n\n\n940\n12\n12\n12\n12\n12\n60\n\n\n\n\n960 rows × 6 columns\n\n\n\n\n\n\nBlue camera\n\nblue_tests = L1SpectrumValueCheck(camera=\"BLUE\", n_processes=8)\nblue_tests.run(date=\"201*\")\n\nLocating and converting where necessary:   0%|                                                                                     | 0/126 [00:00&lt;?, ?it/s]Locating and converting where necessary: 100%|█████████████████████████████████████████████████████████████████████████| 126/126 [00:00&lt;00:00, 4882.91it/s]\nReading netCDF files... took 5.52 s. Size is 57535.394 Mb\nTests took 9.47 s to prepare (including reading data).\nTests took 21.20 s to perform.\nnans_in_BLUE_FLUX:\n    Are there non-finite values in BLUE_FLUX?\nnans_in_BLUE_FLUX_NOSS:\n    Are there non-finite values in BLUE_FLUX_NOSS?\nnans_in_BLUE_IVAR:\n    Are there non-finite values in BLUE_IVAR?\nnans_in_BLUE_IVAR_NOSS:\n    Are there non-finite values in BLUE_IVAR_NOSS?\nnans_in_BLUE_SENSFUNC:\n    Are there non-finite values in BLUE_SENSFUNC?\nnegs_in_BLUE_IVAR:\n    Are there negative values in BLUE_IVAR?\nnegs_in_BLUE_IVAR_NOSS:\n    Are there negative values in BLUE_IVAR_NOSS?\nnegs_in_BLUE_SENSFUNC:\n    Are there negative values in BLUE_SENSFUNC?\n\n\n\nblue_tests.summary(by=\"RUN\")\n\n8 varieties of test and 60480 tested elements per variety, for total of 483840 tests.\n60300 tests failed (12.46%) and 423540 tests passed (87.54%).\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\ntest\nnans_in_BLUE_FLUX\nnans_in_BLUE_FLUX_NOSS\nnans_in_BLUE_IVAR\nnans_in_BLUE_IVAR_NOSS\nnans_in_BLUE_SENSFUNC\n\n\n\nRUN\n\n\n\n\n\n\n\n\n\n\n1004098\n960\n960\n960\n960\n960\n4800\n\n\n1004100\n960\n960\n960\n960\n960\n4800\n\n\n1004102\n960\n960\n960\n960\n960\n4800\n\n\n1004110\n960\n960\n960\n960\n960\n4800\n\n\n1004112\n960\n960\n960\n960\n960\n4800\n\n\n1004114\n960\n960\n960\n960\n960\n4800\n\n\n1004122\n960\n960\n960\n960\n960\n4800\n\n\n1004124\n960\n960\n960\n960\n960\n4800\n\n\n1004126\n960\n960\n960\n960\n960\n4800\n\n\n1004146\n960\n960\n960\n960\n960\n4800\n\n\n1004148\n960\n960\n960\n960\n960\n4800\n\n\n1004150\n960\n960\n960\n960\n960\n4800\n\n\n1002250\n20\n20\n20\n20\n20\n100\n\n\n1002252\n20\n20\n20\n20\n20\n100\n\n\n1002254\n20\n20\n20\n20\n20\n100\n\n\n1002262\n20\n20\n20\n20\n20\n100\n\n\n1002264\n20\n20\n20\n20\n20\n100\n\n\n1002266\n20\n20\n20\n20\n20\n100\n\n\n1002286\n20\n20\n20\n20\n20\n100\n\n\n1002288\n20\n20\n20\n20\n20\n100\n\n\n1002290\n20\n20\n20\n20\n20\n100\n\n\n1002310\n20\n20\n20\n20\n20\n100\n\n\n1002312\n20\n20\n20\n20\n20\n100\n\n\n1002314\n20\n20\n20\n20\n20\n100\n\n\n1002322\n20\n20\n20\n20\n20\n100\n\n\n1002324\n20\n20\n20\n20\n20\n100\n\n\n1002326\n20\n20\n20\n20\n20\n100\n\n\n1002346\n20\n20\n20\n20\n20\n100\n\n\n1002348\n20\n20\n20\n20\n20\n100\n\n\n1002350\n20\n20\n20\n20\n20\n100\n\n\n1003330\n20\n20\n20\n20\n20\n100\n\n\n1003332\n20\n20\n20\n20\n20\n100\n\n\n1003334\n20\n20\n20\n20\n20\n100\n\n\n1003354\n20\n20\n20\n20\n20\n100\n\n\n1003356\n20\n20\n20\n20\n20\n100\n\n\n1003358\n20\n20\n20\n20\n20\n100\n\n\n1003438\n20\n20\n20\n20\n20\n100\n\n\n1003440\n20\n20\n20\n20\n20\n100\n\n\n1003442\n20\n20\n20\n20\n20\n100\n\n\n\n\n\n\n\n\n\nblue_tests.summary(by=\"NSPEC\")\n\n8 varieties of test and 60480 tested elements per variety, for total of 483840 tests.\n60300 tests failed (12.46%) and 423540 tests passed (87.54%).\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\ntest\nnans_in_BLUE_FLUX\nnans_in_BLUE_FLUX_NOSS\nnans_in_BLUE_IVAR\nnans_in_BLUE_IVAR_NOSS\nnans_in_BLUE_SENSFUNC\n\n\n\nNSPEC\n\n\n\n\n\n\n\n\n\n\n941\n39\n39\n39\n39\n39\n195\n\n\n942\n39\n39\n39\n39\n39\n195\n\n\n943\n39\n39\n39\n39\n39\n195\n\n\n944\n39\n39\n39\n39\n39\n195\n\n\n945\n39\n39\n39\n39\n39\n195\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n936\n12\n12\n12\n12\n12\n60\n\n\n937\n12\n12\n12\n12\n12\n60\n\n\n938\n12\n12\n12\n12\n12\n60\n\n\n939\n12\n12\n12\n12\n12\n60\n\n\n940\n12\n12\n12\n12\n12\n60\n\n\n\n\n960 rows × 6 columns",
    "crumbs": [
      "diagnostics",
      "L1 spectrum value check"
    ]
  },
  {
    "objectID": "diagnostics/l1_spectrum_value_check.html#verification",
    "href": "diagnostics/l1_spectrum_value_check.html#verification",
    "title": "L1 spectrum value check",
    "section": "Verification",
    "text": "Verification\nWe now do some spot checks to verify and expand upon the above test results. Note that we assigned self.data inside tests. This provides a way of accessing the source data, without having to construct it again.\nNote that the neg_ tests are omitted from the summaries above, which means they all passed.\n\nsource\n\nplot_qty_and_nans\n\n plot_qty_and_nans (data, run, ext)\n\nThere is some odd striping of NaN values in the spectra with many failures (Figure 1), but those with few failures just have a small number of spectra that are completely NaN (Figure 2).\n\nplot_qty_and_nans(red_tests.data, 1004097, \"RED_FLUX\")\nplot_qty_and_nans(blue_tests.data, 1004098, \"BLUE_FLUX\")\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\nplot_qty_and_nans(red_tests.data, 1003329, \"RED_FLUX\")\nplot_qty_and_nans(blue_tests.data, 1003330, \"BLUE_FLUX\")\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigure 2",
    "crumbs": [
      "diagnostics",
      "L1 spectrum value check"
    ]
  },
  {
    "objectID": "diagnostics/l1_spectrum_masked_value_check.html",
    "href": "diagnostics/l1_spectrum_masked_value_check.html",
    "title": "L1 spectrum masked value check",
    "section": "",
    "text": "To write checks of the data, we create a subclass of Diagnostics and implement the tests method.\nsource",
    "crumbs": [
      "diagnostics",
      "L1 spectrum masked value check"
    ]
  },
  {
    "objectID": "diagnostics/l1_spectrum_masked_value_check.html#demonstration-tests",
    "href": "diagnostics/l1_spectrum_masked_value_check.html#demonstration-tests",
    "title": "L1 spectrum masked value check",
    "section": "Demonstration tests",
    "text": "Demonstration tests\nWe use multiple dask workers to speed up this test. Checking 15 billion pixels takes ~45 seconds with 8 workers.\n\nRed camera\n\nred_tests = L1SpectrumMaskedValueCheck(camera=\"RED\", n_processes=8)\nred_tests.run(date=\"201*\")\n\nLocating and converting where necessary:   0%|                                                                                     | 0/126 [00:00&lt;?, ?it/s]Locating and converting where necessary: 100%|█████████████████████████████████████████████████████████████████████████| 126/126 [00:00&lt;00:00, 5493.46it/s]\nReading netCDF files... took 6.63 s. Size is 57535.394 Mb\nTests took 8.89 s to prepare (including reading data).\nTests took 19.75 s to perform.\nneg_flux_unmasked_in_RED_IVAR:\n    Are there unmasked pixels in IVAR where FLUX_NOSS is negative?\nnlr_flux_unmasked_in_RED_IVAR:\n    Are there unmasked pixels in IVAR where FLUX_NOSS is non-linear?\nneg_flux_unmasked_in_RED_IVAR_NOSS:\n    Are there unmasked pixels in IVAR_NOSS where FLUX_NOSS is negative?\nnlr_flux_unmasked_in_RED_IVAR_NOSS:\n    Are there unmasked pixels in IVAR_NOSS where FLUX_NOSS is non-linear?\n\n\n\nred_tests.summary(by=\"RUN\")\n\n4 varieties of test and 60480 tested elements per variety, for total of 241920 tests.\n78820 tests failed (32.58%) and 163100 tests passed (67.42%).\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\ntest\nneg_flux_unmasked_in_RED_IVAR\nneg_flux_unmasked_in_RED_IVAR_NOSS\nnlr_flux_unmasked_in_RED_IVAR\nnlr_flux_unmasked_in_RED_IVAR_NOSS\n\n\n\nRUN\n\n\n\n\n\n\n\n\n\n1003331\n917\n917\n0\n0\n1834\n\n\n1003329\n912\n912\n0\n0\n1824\n\n\n1003357\n911\n911\n0\n0\n1822\n\n\n1003333\n909\n909\n0\n0\n1818\n\n\n1003437\n908\n908\n0\n0\n1816\n\n\n...\n...\n...\n...\n...\n...\n\n\n1004147\n290\n290\n0\n0\n580\n\n\n1004111\n255\n255\n33\n33\n576\n\n\n1004109\n250\n250\n33\n33\n566\n\n\n1004113\n245\n245\n33\n33\n556\n\n\n1004149\n274\n274\n0\n0\n548\n\n\n\n\n63 rows × 5 columns\n\n\n\n\n\nred_tests.summary(by=\"NSPEC\")\n\n4 varieties of test and 60480 tested elements per variety, for total of 241920 tests.\n78820 tests failed (32.58%) and 163100 tests passed (67.42%).\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\ntest\nneg_flux_unmasked_in_RED_IVAR\nneg_flux_unmasked_in_RED_IVAR_NOSS\nnlr_flux_unmasked_in_RED_IVAR\nnlr_flux_unmasked_in_RED_IVAR_NOSS\n\n\n\nNSPEC\n\n\n\n\n\n\n\n\n\n325\n59\n59\n8\n8\n134\n\n\n375\n61\n61\n6\n6\n134\n\n\n382\n57\n57\n9\n9\n132\n\n\n385\n60\n60\n6\n6\n132\n\n\n283\n57\n57\n6\n6\n126\n\n\n...\n...\n...\n...\n...\n...\n\n\n942\n8\n8\n0\n0\n16\n\n\n944\n7\n7\n0\n0\n14\n\n\n960\n7\n7\n0\n0\n14\n\n\n943\n4\n4\n0\n0\n8\n\n\n959\n1\n1\n0\n0\n2\n\n\n\n\n959 rows × 5 columns\n\n\n\n\n\n\nBlue camera\n\nblue_tests = L1SpectrumMaskedValueCheck(camera=\"BLUE\", n_processes=8)\nblue_tests.run(date=\"201*\")\n\nLocating and converting where necessary:   0%|                                                                                     | 0/126 [00:00&lt;?, ?it/s]Locating and converting where necessary: 100%|█████████████████████████████████████████████████████████████████████████| 126/126 [00:00&lt;00:00, 5192.65it/s]\nReading netCDF files... took 5.71 s. Size is 57535.394 Mb\nTests took 7.96 s to prepare (including reading data).\nTests took 14.43 s to perform.\nneg_flux_unmasked_in_BLUE_IVAR:\n    Are there unmasked pixels in IVAR where FLUX_NOSS is negative?\nnlr_flux_unmasked_in_BLUE_IVAR:\n    Are there unmasked pixels in IVAR where FLUX_NOSS is non-linear?\nneg_flux_unmasked_in_BLUE_IVAR_NOSS:\n    Are there unmasked pixels in IVAR_NOSS where FLUX_NOSS is negative?\nnlr_flux_unmasked_in_BLUE_IVAR_NOSS:\n    Are there unmasked pixels in IVAR_NOSS where FLUX_NOSS is non-linear?\n\n\n\nblue_tests.summary(by=\"RUN\")\n\n4 varieties of test and 60480 tested elements per variety, for total of 241920 tests.\n91920 tests failed (38.00%) and 150000 tests passed (62.00%).\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\ntest\nneg_flux_unmasked_in_BLUE_IVAR\nneg_flux_unmasked_in_BLUE_IVAR_NOSS\nnlr_flux_unmasked_in_BLUE_IVAR\nnlr_flux_unmasked_in_BLUE_IVAR_NOSS\n\n\n\nRUN\n\n\n\n\n\n\n\n\n\n1003330\n937\n937\n0\n0\n1874\n\n\n1003332\n937\n937\n0\n0\n1874\n\n\n1003438\n937\n937\n0\n0\n1874\n\n\n1003442\n937\n937\n0\n0\n1874\n\n\n1002348\n936\n936\n0\n0\n1872\n\n\n...\n...\n...\n...\n...\n...\n\n\n1004100\n96\n96\n34\n34\n260\n\n\n1004102\n91\n91\n34\n34\n250\n\n\n1004112\n87\n87\n5\n5\n184\n\n\n1004110\n82\n82\n5\n5\n174\n\n\n1004114\n67\n67\n5\n5\n144\n\n\n\n\n63 rows × 5 columns\n\n\n\n\n\nblue_tests.summary(by=\"NSPEC\")\n\n4 varieties of test and 60480 tested elements per variety, for total of 241920 tests.\n91920 tests failed (38.00%) and 150000 tests passed (62.00%).\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\ntest\nneg_flux_unmasked_in_BLUE_IVAR\nneg_flux_unmasked_in_BLUE_IVAR_NOSS\nnlr_flux_unmasked_in_BLUE_IVAR\nnlr_flux_unmasked_in_BLUE_IVAR_NOSS\n\n\n\nNSPEC\n\n\n\n\n\n\n\n\n\n261\n56\n56\n6\n6\n124\n\n\n273\n56\n56\n6\n6\n124\n\n\n280\n56\n56\n6\n6\n124\n\n\n298\n62\n62\n0\n0\n124\n\n\n343\n57\n57\n3\n3\n120\n\n\n...\n...\n...\n...\n...\n...\n\n\n943\n18\n18\n0\n0\n36\n\n\n945\n18\n18\n0\n0\n36\n\n\n958\n18\n18\n0\n0\n36\n\n\n956\n12\n12\n0\n0\n24\n\n\n950\n2\n2\n0\n0\n4\n\n\n\n\n960 rows × 5 columns",
    "crumbs": [
      "diagnostics",
      "L1 spectrum masked value check"
    ]
  },
  {
    "objectID": "diagnostics/l1_spectrum_masked_value_check.html#verification",
    "href": "diagnostics/l1_spectrum_masked_value_check.html#verification",
    "title": "L1 spectrum masked value check",
    "section": "Verification",
    "text": "Verification\nWe now do some spot checks to verify and expand upon the above test results. Note that we assigned self.data inside tests. This provides a way of accessing the source data, without having to construct it again.\n\nsource\n\nplot_unmasked_and_invalid\n\n plot_unmasked_and_invalid (tests, run)\n\nThere is some odd striping of masked values in some spectra (Figure 1), but those that look more sensible (Figure 2) contain a significant number of unmasked pixels (yellow in top panel) that have negative fluxes (blue in bottom panel) or are above the non-linear threshold (yellow in bottom panel).\n\nplot_unmasked_and_invalid(red_tests, 1004111)\nplot_unmasked_and_invalid(blue_tests, 1004112)\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\nplot_unmasked_and_invalid(red_tests, 1003331)\nplot_unmasked_and_invalid(blue_tests, 1003332)\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigure 2",
    "crumbs": [
      "diagnostics",
      "L1 spectrum masked value check"
    ]
  },
  {
    "objectID": "diagnostics/obs_cond_check.html",
    "href": "diagnostics/obs_cond_check.html",
    "title": "Observing conditions check",
    "section": "",
    "text": "To write checks of the data, we create a subclass of Diagnostics and implement the tests method.\nsource",
    "crumbs": [
      "diagnostics",
      "Observing conditions check"
    ]
  },
  {
    "objectID": "diagnostics/obs_cond_check.html#demonstration-tests",
    "href": "diagnostics/obs_cond_check.html#demonstration-tests",
    "title": "Observing conditions check",
    "section": "Demonstration tests",
    "text": "Demonstration tests\n\ntests = ObsCondCheck()\ntests.run(date=\"201*\")\n\nReading files:   0%|                                                                                                               | 0/126 [00:00&lt;?, ?it/s]Reading files:   1%|▊                                                                                                      | 1/126 [00:00&lt;00:40,  3.08it/s]Reading files:   2%|█▋                                                                                                     | 2/126 [00:00&lt;00:33,  3.71it/s]Reading files:  15%|███████████████▍                                                                                      | 19/126 [00:00&lt;00:02, 43.05it/s]Reading files:  25%|█████████████████████████▉                                                                            | 32/126 [00:00&lt;00:01, 64.95it/s]Reading files:  33%|██████████████████████████████████                                                                    | 42/126 [00:00&lt;00:01, 69.06it/s]Reading files:  44%|█████████████████████████████████████████████▎                                                        | 56/126 [00:00&lt;00:00, 85.85it/s]Reading files:  53%|██████████████████████████████████████████████████████▏                                               | 67/126 [00:01&lt;00:00, 88.73it/s]Reading files:  64%|█████████████████████████████████████████████████████████████████▌                                    | 81/126 [00:01&lt;00:00, 99.73it/s]Reading files:  74%|██████████████████████████████████████████████████████████████████████████▌                          | 93/126 [00:01&lt;00:00, 103.50it/s]Reading files:  85%|████████████████████████████████████████████████████████████████████████████████████▉               | 107/126 [00:01&lt;00:00, 113.21it/s]Reading files:  94%|██████████████████████████████████████████████████████████████████████████████████████████████▍     | 119/126 [00:01&lt;00:00, 105.13it/s]Reading files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 126/126 [00:01&lt;00:00, 77.20it/s]\nCreating Dataset... took 2.01 s. Size is 0.800 Mb\nTests took 8.05 s to prepare (including reading data).\nTests took 1.00 s to perform.\nsky_too_bright:\n    Is the sky brighter than the requirement?\nseeing_too_poor:\n    Is the seeing worse than the requirement?\nwrong_run_count:\n    Are there other than two runs with the same EXPID?\nunmatched_runs_sky:\n    Do runs with the same EXPID have different sky brightness?\nunmatched_runs_seeing:\n    Do runs with the same EXPID have different seeing?\n\n\n\ntests.summary_per_test()\n\n5 varieties of test and 63 tested elements per variety, for total of 315 tests.\n6 tests failed (1.90%) and 309 tests passed (98.10%).\n\n\n\n\n\n\n\n\n\n\ntotal fails\n\n\ntest\n\n\n\n\n\nsky_too_bright\n6\n\n\nseeing_too_poor\n0\n\n\nunmatched_runs_seeing\n0\n\n\nunmatched_runs_sky\n0\n\n\nwrong_run_count\n0\n\n\n\n\n\n\n\n\n\ntests.summary()\n\n5 varieties of test and 63 tested elements per variety, for total of 315 tests.\n6 tests failed (1.90%) and 309 tests passed (98.10%).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\n\n\n\n\n\ntest\nsky_too_bright\n\n\n\nEXPID\nfilename\nRUN\nOBID\nMJD\nNIGHT\n\n\n\n\n\n\n321700000001\nsingle_1002310\n1002310\n3217\n57641.001725\n20160909\nTrue\n1\n\n\n321700000002\nsingle_1002312\n1002312\n3217\n57641.014919\n20160909\nTrue\n1\n\n\n321700000003\nsingle_1002313\n1002313\n3217\n57641.028113\n20160909\nTrue\n1\n\n\n343400000001\nsingle_1002250\n1002250\n3434\n57639.999560\n20160908\nTrue\n1\n\n\n343400000002\nsingle_1002251\n1002251\n3434\n57640.012755\n20160908\nTrue\n1\n\n\n343400000003\nsingle_1002253\n1002253\n3434\n57640.025949\n20160908\nTrue\n1\n\n\n\n\n\n\n\n\n\ntests.full_summary()\n\n5 varieties of test and 63 tested elements per variety, for total of 315 tests.\n6 tests failed (1.90%) and 309 tests passed (98.10%).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfailed\n\n\n\n\n\n\n\ntest\nseeing_too_poor\nsky_too_bright\nunmatched_runs_seeing\nunmatched_runs_sky\nwrong_run_count\n\n\nEXPID\nfilename\nRUN\nOBID\nMJD\nNIGHT\n\n\n\n\n\n\n\n\n\n313300000001\nsingle_1002226\n1002226\n3133\n57639.909236\n20160908\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n313300000002\nsingle_1002227\n1002227\n3133\n57639.922431\n20160908\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n313300000003\nsingle_1002229\n1002229\n3133\n57639.935625\n20160908\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n317000000001\nsingle_1002286\n1002286\n3170\n57640.911400\n20160909\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n317000000002\nsingle_1002287\n1002287\n3170\n57640.924595\n20160909\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n440700000002\nsingle_1004123\n1004123\n4407\n58027.050104\n20170930\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n440700000003\nsingle_1004126\n1004126\n4407\n58027.063299\n20170930\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n446400000001\nsingle_1004098\n1004098\n4464\n58026.823542\n20170930\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n446400000002\nsingle_1004099\n1004099\n4464\n58026.836736\n20170930\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n446400000003\nsingle_1004101\n1004101\n4464\n58026.849931\n20170930\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n63 rows × 5 columns",
    "crumbs": [
      "diagnostics",
      "Observing conditions check"
    ]
  },
  {
    "objectID": "diagnostics/sky_noise_distribution_check.html",
    "href": "diagnostics/sky_noise_distribution_check.html",
    "title": "Sky noise distribution check",
    "section": "",
    "text": "To write checks of the data, we create a subclass of Diagnostics and implement the tests method.\nsource",
    "crumbs": [
      "diagnostics",
      "Sky noise distribution check"
    ]
  },
  {
    "objectID": "diagnostics/sky_noise_distribution_check.html#demonstration-tests",
    "href": "diagnostics/sky_noise_distribution_check.html#demonstration-tests",
    "title": "Sky noise distribution check",
    "section": "Demonstration tests",
    "text": "Demonstration tests\n\nStacked observations\n\ntests_stack = SkyNoiseDistributionCheck(stack=True, n_processes=8)\ntests_stack.run(date=\"201*\")\n\nLocating and converting where necessary:   0%|                                                                                      | 0/34 [00:00&lt;?, ?it/s]Locating and converting where necessary:   3%|██▎                                                                           | 1/34 [00:01&lt;00:52,  1.58s/it]Locating and converting where necessary:   6%|████▌                                                                         | 2/34 [00:01&lt;00:23,  1.34it/s]Locating and converting where necessary:  12%|█████████▏                                                                    | 4/34 [00:01&lt;00:10,  2.90it/s]Locating and converting where necessary:  15%|███████████▍                                                                  | 5/34 [00:02&lt;00:10,  2.68it/s]Locating and converting where necessary:  21%|████████████████                                                              | 7/34 [00:02&lt;00:06,  4.17it/s]Locating and converting where necessary:  24%|██████████████████▎                                                           | 8/34 [00:02&lt;00:07,  3.52it/s]Locating and converting where necessary:  26%|████████████████████▋                                                         | 9/34 [00:03&lt;00:08,  2.92it/s]Locating and converting where necessary:  29%|██████████████████████▋                                                      | 10/34 [00:03&lt;00:08,  2.93it/s]Locating and converting where necessary:  32%|████████████████████████▉                                                    | 11/34 [00:04&lt;00:07,  3.02it/s]Locating and converting where necessary:  35%|███████████████████████████▏                                                 | 12/34 [00:04&lt;00:10,  2.14it/s]Locating and converting where necessary:  41%|███████████████████████████████▋                                             | 14/34 [00:05&lt;00:05,  3.50it/s]Locating and converting where necessary:  44%|█████████████████████████████████▉                                           | 15/34 [00:05&lt;00:05,  3.45it/s]Locating and converting where necessary:  47%|████████████████████████████████████▏                                        | 16/34 [00:05&lt;00:04,  3.76it/s]Locating and converting where necessary:  50%|██████████████████████████████████████▌                                      | 17/34 [00:09&lt;00:20,  1.21s/it]Locating and converting where necessary:  53%|████████████████████████████████████████▊                                    | 18/34 [00:09&lt;00:16,  1.01s/it]Locating and converting where necessary:  56%|███████████████████████████████████████████                                  | 19/34 [00:09&lt;00:11,  1.30it/s]Locating and converting where necessary:  62%|███████████████████████████████████████████████▌                             | 21/34 [00:10&lt;00:05,  2.23it/s]Locating and converting where necessary:  68%|████████████████████████████████████████████████████                         | 23/34 [00:10&lt;00:04,  2.33it/s]Locating and converting where necessary:  71%|██████████████████████████████████████████████████████▎                      | 24/34 [00:11&lt;00:03,  2.59it/s]Locating and converting where necessary:  74%|████████████████████████████████████████████████████████▌                    | 25/34 [00:11&lt;00:03,  2.64it/s]Locating and converting where necessary:  76%|██████████████████████████████████████████████████████████▉                  | 26/34 [00:11&lt;00:02,  3.21it/s]Locating and converting where necessary:  79%|█████████████████████████████████████████████████████████████▏               | 27/34 [00:11&lt;00:01,  3.64it/s]Locating and converting where necessary:  85%|█████████████████████████████████████████████████████████████████▋           | 29/34 [00:12&lt;00:01,  3.03it/s]Locating and converting where necessary:  88%|███████████████████████████████████████████████████████████████████▉         | 30/34 [00:12&lt;00:01,  3.43it/s]Locating and converting where necessary:  91%|██████████████████████████████████████████████████████████████████████▏      | 31/34 [00:13&lt;00:00,  3.53it/s]Locating and converting where necessary:  97%|██████████████████████████████████████████████████████████████████████████▋  | 33/34 [00:13&lt;00:00,  3.49it/s]Locating and converting where necessary: 100%|█████████████████████████████████████████████████████████████████████████████| 34/34 [00:15&lt;00:00,  1.44it/s]Locating and converting where necessary: 100%|█████████████████████████████████████████████████████████████████████████████| 34/34 [00:15&lt;00:00,  2.17it/s]\nReading netCDF files... took 2.07 s. Size is 15525.568 Mb\nReading files:   0%|                                                                                                                | 0/34 [00:00&lt;?, ?it/s]Reading files:   3%|███                                                                                                     | 1/34 [00:00&lt;00:07,  4.67it/s]Reading files:  26%|███████████████████████████▌                                                                            | 9/34 [00:00&lt;00:00, 30.87it/s]Reading files:  50%|███████████████████████████████████████████████████▌                                                   | 17/34 [00:00&lt;00:00, 43.68it/s]Reading files:  68%|█████████████████████████████████████████████████████████████████████▋                                 | 23/34 [00:00&lt;00:00, 48.37it/s]Reading files:  85%|███████████████████████████████████████████████████████████████████████████████████████▊               | 29/34 [00:00&lt;00:00, 45.93it/s]Reading files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00&lt;00:00, 45.11it/s]\nCreating Dataset... took 0.26 s. Size is 10.214 Mb\nTests took 20.22 s to prepare (including reading data).\nTests took 26.30 s to perform.\nmean_non_zero:\n    Is the mean of the normalised flux in sky fibres significantly different from zero?\nstdev_non_unit:\n    Is the standard deviation of the normalised flux in sky fibres significantly different from unity?\nks_non_normal:\n    Does the distribution of normalised flux in sky fibres fail a KS test comparison with a standard Normal?\n\n\n\ntests_stack.summary(by=[\"OBID\", \"CAMERA\"], sort_by_total_fails=False)\n\n3 varieties of test and 3278 tested elements per variety, for total of 9834 tests.\n7524 tests failed (76.51%) and 2310 tests passed (23.49%).\n\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\n\ntest\nks_non_normal\nmean_non_zero\nstdev_non_unit\n\n\n\nOBID\nCAMERA\n\n\n\n\n\n\n\n\n3133\nBLUE\n100\n12\n100\n212\n\n\nRED\n100\n25\n100\n225\n\n\n3170\nBLUE\n100\n5\n100\n205\n\n\nRED\n100\n20\n100\n220\n\n\n3175\nBLUE\n100\n18\n100\n218\n\n\nRED\n100\n33\n100\n233\n\n\n3189\nBLUE\n100\n7\n99\n206\n\n\nRED\n100\n22\n100\n222\n\n\n3191\nBLUE\n100\n94\n93\n287\n\n\nRED\n100\n94\n96\n290\n\n\n3217\nBLUE\n99\n46\n99\n244\n\n\nRED\n99\n40\n98\n237\n\n\n3295\nBLUE\n100\n9\n100\n209\n\n\nRED\n100\n30\n100\n230\n\n\n3346\nBLUE\n100\n48\n99\n247\n\n\nRED\n100\n71\n98\n269\n\n\n3372\nBLUE\n100\n9\n100\n209\n\n\nRED\n100\n25\n100\n225\n\n\n3380\nBLUE\n100\n13\n100\n213\n\n\nRED\n100\n34\n100\n234\n\n\n3434\nBLUE\n100\n15\n100\n215\n\n\nRED\n100\n33\n100\n233\n\n\n3653\nBLUE\n100\n19\n100\n219\n\n\nRED\n100\n32\n100\n232\n\n\n3756\nBLUE\n100\n20\n100\n220\n\n\nRED\n100\n35\n100\n235\n\n\n3802\nBLUE\n80\n15\n80\n175\n\n\nRED\n80\n26\n80\n186\n\n\n3803\nBLUE\n80\n19\n80\n179\n\n\nRED\n80\n24\n80\n184\n\n\n3806\nBLUE\n80\n15\n80\n175\n\n\nRED\n80\n25\n80\n185\n\n\n3900\nBLUE\n100\n17\n100\n217\n\n\nRED\n100\n34\n100\n234\n\n\n\n\n\n\n\n\n\n\nSingle observations\n\ntests_single = SkyNoiseDistributionCheck(n_processes=8)\ntests_single.run(date=\"201*\")\n\nLocating and converting where necessary:   0%|                                                                                     | 0/126 [00:00&lt;?, ?it/s]Locating and converting where necessary: 100%|█████████████████████████████████████████████████████████████████████████| 126/126 [00:00&lt;00:00, 6443.26it/s]\nReading netCDF files... took 6.44 s. Size is 57535.394 Mb\nReading files:   0%|                                                                                                               | 0/126 [00:00&lt;?, ?it/s]Reading files:   1%|▊                                                                                                      | 1/126 [00:00&lt;00:20,  6.14it/s]Reading files:   8%|████████                                                                                              | 10/126 [00:00&lt;00:02, 44.67it/s]Reading files:  15%|███████████████▍                                                                                      | 19/126 [00:00&lt;00:01, 58.63it/s]Reading files:  22%|██████████████████████▋                                                                               | 28/126 [00:00&lt;00:01, 67.38it/s]Reading files:  29%|█████████████████████████████▉                                                                        | 37/126 [00:00&lt;00:01, 73.89it/s]Reading files:  36%|████████████████████████████████████▍                                                                 | 45/126 [00:00&lt;00:01, 71.98it/s]Reading files:  42%|██████████████████████████████████████████▉                                                           | 53/126 [00:00&lt;00:00, 73.97it/s]Reading files:  48%|█████████████████████████████████████████████████▍                                                    | 61/126 [00:00&lt;00:00, 73.39it/s]Reading files:  56%|████████████████████████████████████████████████████████▋                                             | 70/126 [00:01&lt;00:00, 75.48it/s]Reading files:  62%|███████████████████████████████████████████████████████████████▏                                      | 78/126 [00:01&lt;00:00, 76.40it/s]Reading files:  69%|██████████████████████████████████████████████████████████████████████▍                               | 87/126 [00:01&lt;00:00, 71.77it/s]Reading files:  76%|█████████████████████████████████████████████████████████████████████████████▋                        | 96/126 [00:01&lt;00:00, 76.33it/s]Reading files:  83%|████████████████████████████████████████████████████████████████████████████████████▏                | 105/126 [00:01&lt;00:00, 77.63it/s]Reading files:  90%|███████████████████████████████████████████████████████████████████████████████████████████▍         | 114/126 [00:01&lt;00:00, 77.23it/s]Reading files:  98%|███████████████████████████████████████████████████████████████████████████████████████████████████▍ | 124/126 [00:01&lt;00:00, 83.45it/s]Reading files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 126/126 [00:01&lt;00:00, 72.16it/s]\nCreating Dataset... took 0.98 s. Size is 37.848 Mb\nTests took 12.65 s to prepare (including reading data).\nTests took 81.56 s to perform.\nmean_non_zero:\n    Is the mean of the normalised flux in sky fibres significantly different from zero?\nstdev_non_unit:\n    Is the standard deviation of the normalised flux in sky fibres significantly different from unity?\nks_non_normal:\n    Does the distribution of normalised flux in sky fibres fail a KS test comparison with a standard Normal?\n\n\n\ntests_single.summary(by=\"RUN\")\n\n3 varieties of test and 11178 tested elements per variety, for total of 33534 tests.\n28874 tests failed (86.10%) and 4660 tests passed (13.90%).\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\ntest\nks_non_normal\nmean_non_zero\nstdev_non_unit\n\n\n\nRUN\n\n\n\n\n\n\n\n\n1003330\n100\n97\n100\n297\n\n\n1002326\n100\n96\n100\n296\n\n\n1003442\n100\n96\n100\n296\n\n\n1002218\n100\n96\n99\n295\n\n\n1002322\n100\n94\n100\n294\n\n\n...\n...\n...\n...\n...\n\n\n1004098\n54\n5\n42\n101\n\n\n1004102\n53\n3\n45\n101\n\n\n1004100\n53\n2\n42\n97\n\n\n1004114\n53\n2\n41\n96\n\n\n1004110\n52\n1\n40\n93\n\n\n\n\n126 rows × 4 columns",
    "crumbs": [
      "diagnostics",
      "Sky noise distribution check"
    ]
  },
  {
    "objectID": "diagnostics/sky_noise_distribution_check.html#verification",
    "href": "diagnostics/sky_noise_distribution_check.html#verification",
    "title": "Sky noise distribution check",
    "section": "Verification",
    "text": "Verification\nWe now do some spot checks to verify and expand upon the above test results. Note that we assigned self.stats inside tests. This provides a way of accessing the statistics used in the tests, without having to construct them again. However, we still need to recompute the statistics (or whatever is derived from the self.stats DataArray), which takes a little time.\n\nStacked observations\n\ndask_cluster = Client(n_workers=8, threads_per_worker=1, memory_limit=\"2GiB\")\nwith dask_cluster as _:\n    stats_stack = tests_stack.stats.to_pandas()\nstats_stack = stats_stack.drop(columns=[\"RUN\", \"NSPEC\", \"filename\"]).dropna()\nstats_stack\n\n\n\n\n\n\n\n\n\n\nCAMERA\nMJD\nNIGHT\nOBID\nstdev_measured\nstdev_expected\nmean_zscore\nstdev_zscore\nerr_on_mean_zscore\nerr_on_stdev_zscore\nsig_mean_zscore\nsig_stdev_zscore\nks_prob\n\n\nRUN\nNSPEC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1002213\n11\nRED\n57639.865255\n20160908\n3191\n14.434108\n17.138083\n0.019939\n0.699874\n0.005754\n0.004068\n3.465475\n73.768521\n8.035202e-153\n\n\n24\nRED\n57639.865255\n20160908\n3191\n13.561947\n18.409519\n0.062587\n0.665258\n0.005469\n0.003867\n11.444790\n86.563817\n2.036983e-214\n\n\n28\nRED\n57639.865255\n20160908\n3191\n12.528222\n20.226862\n0.072141\n0.668574\n0.005496\n0.003886\n13.126402\n85.281153\n1.338991e-252\n\n\n29\nRED\n57639.865255\n20160908\n3191\n11.424335\n16.328005\n0.109784\n0.734996\n0.006042\n0.004272\n18.170614\n62.027562\n7.630893e-246\n\n\n30\nRED\n57639.865255\n20160908\n3191\n11.832997\n17.077747\n0.105105\n0.714683\n0.005875\n0.004154\n17.891294\n68.682428\n5.134166e-246\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1003438\n886\nBLUE\n57811.080127\n20170226\n3756\n7.301003\n10.209663\n-0.013633\n0.740153\n0.007678\n0.005430\n1.775526\n47.856661\n1.006452e-60\n\n\n887\nBLUE\n57811.080127\n20170226\n3756\n7.056021\n9.612802\n-0.034382\n0.743715\n0.007715\n0.005456\n4.456348\n46.974609\n6.240768e-72\n\n\n903\nBLUE\n57811.080127\n20170226\n3756\n8.306773\n11.312715\n-0.035773\n0.745957\n0.007739\n0.005473\n4.622261\n46.418748\n7.650716e-69\n\n\n908\nBLUE\n57811.080127\n20170226\n3756\n7.620360\n10.488612\n-0.024473\n0.743780\n0.007716\n0.005457\n3.171575\n46.956013\n2.096569e-60\n\n\n933\nBLUE\n57811.080127\n20170226\n3756\n8.280155\n10.955614\n-0.032483\n0.756778\n0.007852\n0.005552\n4.137045\n43.805981\n2.679887e-67\n\n\n\n\n3278 rows × 13 columns\n\n\n\n\n\nsource\n\n\nplot_hist\n\n plot_hist (stats, mean_range=None, stdev_range=None)\n\n\nplot_hist(stats_stack, mean_range=(-0.2, 0.2), stdev_range=(0.5, 1.2))\n\n\n\n\n\n\n\n\nThe mean flux in the sky-subtracted sky is significantly below zero, and the standard deviation of the sky is significantly below that expected from the errors.\nLet’s break it down by OB.\n\nsource\n\n\nplot_dist\n\n plot_dist (stats, by='OBID', mean_range=None, stdev_range=None,\n            mean_bw=None, stdev_bw=None, sigma_clip=5.0, inner=None)\n\n\nplot_dist(\n    stats_stack, mean_range=(-0.2, 0.2), stdev_range=(0.5, 1.2), mean_bw=1, stdev_bw=1\n)\n\n\n\n\n\n\n\n\nThe same behaviour is seen for all OBs, apart from a few which show very broad distributions.\n\n\nSingle observations\n\ndask_cluster = Client(n_workers=8, threads_per_worker=1, memory_limit=\"2GiB\")\nwith dask_cluster as _:\n    stats_single = tests_single.stats.to_pandas()\nstats_single = stats_single.drop(columns=[\"RUN\", \"NSPEC\", \"filename\"]).dropna()\nstats_single\n\n\n\n\n\n\n\n\n\n\nCAMERA\nMJD\nNIGHT\nOBID\nstdev_measured\nstdev_expected\nmean_zscore\nstdev_zscore\nerr_on_mean_zscore\nerr_on_stdev_zscore\nsig_mean_zscore\nsig_stdev_zscore\nks_prob\n\n\nRUN\nNSPEC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1002213\n11\nRED\n57639.865255\n20160908\n3191\n6.530848\n9.903826\n0.004332\n0.632706\n0.005201\n0.003678\n0.832840\n99.861802\n4.281802e-183\n\n\n24\nRED\n57639.865255\n20160908\n3191\n6.876608\n10.628039\n0.017358\n0.622439\n0.005117\n0.003618\n3.392516\n104.353498\n3.658854e-195\n\n\n28\nRED\n57639.865255\n20160908\n3191\n6.576695\n11.682731\n0.025585\n0.608206\n0.005000\n0.003535\n5.117397\n110.821595\n1.657524e-232\n\n\n29\nRED\n57639.865255\n20160908\n3191\n5.930667\n9.438472\n0.066189\n0.642155\n0.005279\n0.003733\n12.538981\n95.867471\n9.701559e-234\n\n\n30\nRED\n57639.865255\n20160908\n3191\n5.989196\n9.864829\n0.047176\n0.628069\n0.005163\n0.003651\n9.137824\n101.879522\n1.397214e-228\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1004150\n547\nBLUE\n58027.195868\n20170930\n3936\n12.288969\n14.835949\n-0.035239\n0.890939\n0.013070\n0.009243\n2.696268\n11.799818\n2.363494e-07\n\n\n561\nBLUE\n58027.195868\n20170930\n3936\n13.323919\n14.854663\n-0.005482\n0.886231\n0.012999\n0.009193\n0.421754\n12.375995\n1.253771e-06\n\n\n567\nBLUE\n58027.195868\n20170930\n3936\n12.312105\n14.828223\n-0.041646\n0.895168\n0.013132\n0.009286\n3.171409\n11.288642\n2.010916e-07\n\n\n581\nBLUE\n58027.195868\n20170930\n3936\n12.971208\n14.846780\n-0.025220\n0.901099\n0.013220\n0.009349\n1.907710\n10.578802\n1.294121e-07\n\n\n596\nBLUE\n58027.195868\n20170930\n3936\n12.668753\n14.827168\n-0.056254\n0.902742\n0.013244\n0.009366\n4.247448\n10.384169\n1.070085e-08\n\n\n\n\n11178 rows × 13 columns\n\n\n\n\n\nplot_hist(stats_single, mean_range=(-0.2, 0.2), stdev_range=(0.5, 1.2))\n\n\n\n\n\n\n\n\n\nplot_dist(stats_single, mean_range=(-0.2, 0.2), stdev_range=(0.5, 1.2))\n\n\n\n\n\n\n\n\nA similar pattern to the stacks, although for some reason we don’t have stacks for all the OBS.\n\n\nCompare noise level in stacks and singles\n\nstack_over_single = (\n    stats_stack.set_index([\"OBID\", \"CAMERA\"])[[\"stdev_measured\", \"stdev_expected\"]]\n    / stats_single.set_index([\"OBID\", \"CAMERA\"])[[\"stdev_measured\", \"stdev_expected\"]]\n)\n\n\nstack_over_single = stack_over_single.dropna()\nstack_over_single\n\n\n\n\n\n\n\n\n\n\nstdev_measured\nstdev_expected\n\n\nOBID\nCAMERA\n\n\n\n\n\n\n3133\nBLUE\n1.730016\n1.732364\n\n\nBLUE\n1.871599\n1.882437\n\n\nBLUE\n1.413495\n1.451536\n\n\nBLUE\n1.517625\n1.521315\n\n\nBLUE\n1.836264\n1.853856\n\n\n...\n...\n...\n...\n\n\n3900\nRED\n2.221029\n1.820005\n\n\nRED\n2.285764\n1.895699\n\n\nRED\n1.914870\n1.688769\n\n\nRED\n2.007282\n1.781666\n\n\nRED\n1.980907\n1.731235\n\n\n\n\n954006 rows × 2 columns\n\n\n\n\n\nsource\n\n\nplot_stack_over_single\n\n plot_stack_over_single (df)\n\n\nplot_stack_over_single(stack_over_single)\n\n\n\n\n\n\n\n\nThe noise increases by a factor of \\(\\sqrt{3}\\), as expected for stacks that are the sum of three single exposures. However, there is sign of an additional contribution to the measured noise in the red stacks.",
    "crumbs": [
      "diagnostics",
      "Sky noise distribution check"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "qagmire",
    "section": "",
    "text": "Qagmire tries to make dealing with WEAVE data products quick and easy, so you can focus on verifying the data quality and producing science results. The focus is on working directly with data stored in FITS files, each typically containing information for a single WEAVE observation.\nQagmire is being developed for the needs of the Quality Assurance Group (QAG) and Science Verifiation phase of the WEAVE-LOFAR survey, so is primarily focussed on WEAVE MOS data. However, Qagmire is primarily a demonstration of techniques to efficiently analyse data in very large and growing collections of FITS files. The approaches can easily be extended to other WEAVE surveys and beyond.\nA key concept is to read data from the FITS files into xarray Datasets, via a netCDF cache to improve efficiency. Operations can be performed on the resulting Dataset, e.g. performing calculations using specific data products for a particular selection of observed sources, in a lazy fashion. This means that the required computations are not performed until the final results are required. At that point, they can be computed (via dask) in a manner that makes best use of the available computational resources. Time-consuming computations can be easily accelerated by assigning more computational resources to the task.\nAnother important element of qagmire is that tests, verification and analysis can all be performed interactively in Jupyter notebooks. Code in one notebook can be automatically exported into the qagmire library for reuse elsewhere, so each notebook can focus on a single issue. Thanks to nbdev, the notebooks are automatically available online for others to inspect.\nThere is some explanation below of why one might prefer these approaches to some alternatives.",
    "crumbs": [
      "qagmire"
    ]
  },
  {
    "objectID": "index.html#structure",
    "href": "index.html#structure",
    "title": "qagmire",
    "section": "Structure",
    "text": "Structure\nIf you are primarily interested in seeing qagmire used to run diagnostic tests on WEAVE data products, then take a look at the observing conditions check, the L1 spectrum value check, and other notebooks in the diagnostics folder.\nThe approach to data access is implemented in data. This includes a set of get_*_files for locating WEAVE files for specific dates, etc. and read_* functions which return xarray Datasets of WEAVE data. The data notebook also demonstrates the use of these functions and documents the structure of the resulting Datasets.\nA framework for writing and running diagnostic tests is implemented in quality_assurance. This defines a Diagnostics class that is used by all the notebooks in the diagnostics folder.\nFinally, utility functions used in other notebooks are collected in utilities.",
    "crumbs": [
      "qagmire"
    ]
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "qagmire",
    "section": "Installation",
    "text": "Installation\nQagmire is currently being developed at github.com/bamford/qagmire.\nAt the moment the best way to install it (ideally in a fresh environment), is probably:\ngit clone https://github.com/bamford/qagmire.git\ncd qagmire\npip install -e .\nThe -e option ensures that you can make edits to the code in your local copy of the repository and they will be picked up without needing to reinstall.\nOnce development has progressed a little further, I plan to transfer the repo to the WEAVE-LOFAR organisation and submit it to PyPi.",
    "crumbs": [
      "qagmire"
    ]
  },
  {
    "objectID": "index.html#development",
    "href": "index.html#development",
    "title": "qagmire",
    "section": "Development",
    "text": "Development\nQagmire is developed using nbdev. If you want to contribute to the main code, then you would be best getting familiar with nbdev, e.g. via the walkthrough. You can write and execute notebooks that use qagmire without needing to use nbdev. However, you should use nbdev (ideally via the git hooks by running pre-commit install) when commiting back to the repository.",
    "crumbs": [
      "qagmire"
    ]
  },
  {
    "objectID": "index.html#why-is-qagmire-needed",
    "href": "index.html#why-is-qagmire-needed",
    "title": "qagmire",
    "section": "Why is qagmire needed?",
    "text": "Why is qagmire needed?\nThose in the know will be aware that we already have a tool for reading and analysing WEAVE data, weave-io. The approach taken by weave-io is to ingest data from the original FITS files into a database. This database has a carefully designed relational structure, with a specialised syntax for accessing the data. Information about the structure of the data, as well as various quantities from the headers of the FITS files, are stored in the database itself, but when pixel data is required, weave-io reads it as required from the original FITS files.\nUnfortunately, this approach has proved to have a few downsides:\n\nThe structure of the FITS files is hardcoded into weave-io. This means that if the structure changes, which is likely during the early Quality Assurance and Science Verification stages of survey, then ingesting the data may fail. The code would need to be adapted to work with the new structure.\nWeave-io’s code is very sophisticated, containing many layers of abstraction and conventions. Unfortunately, it can therefore be quite difficult to make changes, especially in a way that doesn’t break some other functionality.\nIngesting data is a slow process. It can take on the order of hours to ingest a single night of data.\nIf there is a change in the data structure, within weave-io or in the FITS files, then the entire database may need to be reingested.\nWhile it is possible to ingest different subsets of data into different databases, it is then very difficult to perform computations that use data across different databases.\nThe relational syntax sometimes produces hard-to-understand or non-intuitive results.\nAccessing many elements of data is slow. If a test is written to operate on a single element (e.g. a spectrum), then a database access is required for each element, which is very slow. However, this can be sped up by writing the tests to work on a larger unit, e.g. an OB, in one go.\nAccessing pixel data is particularly slow, and it is difficult to speed up such queries. Each spectrum is a separate element in the database, its data is read individually. This means that performing a test on all spectra in an observation involves ~1000 individual disk read operations. This is much slower than simply reading all the spectra into memory in one go.\nAlthough a multi-process job distribution method was intended to be part of weave-io, this has not been tested and there are signs that it may be difficult to get working (and would still be inefficient). Increasing the capabilities of the weave-io requires involvement of the cluster manager.\n\nSome of these issues could likely be addressed with further development of weave-io. However, at least in the interim, it seems wise to have an appoach that enables more direct and flexible access to the data in the original FITS files, while allowing computations across large amounts of data to be performed in a reasonable time. This is the goal of qagmire.\nWith qagmire, tests take orders of magnitude less time than they would in weave-io. Long-running computations can be easily accelerated by taking advantage of multiple processors or even nodes through the regular user facing job submission system.\nThis certainly doesn’t preclude making data available via a database front-end once things are more stable. It may be interesting to explore using TileDB.",
    "crumbs": [
      "qagmire"
    ]
  },
  {
    "objectID": "ga-calib/l1_spectrum_value_check.html",
    "href": "ga-calib/l1_spectrum_value_check.html",
    "title": "L1 spectrum value check",
    "section": "",
    "text": "from qagmire.diagnostics import L1SpectrumValueCheck\nfrom qagmire.diagnostics.l1_spectrum_value_check import plot_qty_and_nans",
    "crumbs": [
      "ga-calib",
      "L1 spectrum value check"
    ]
  },
  {
    "objectID": "ga-calib/l1_spectrum_value_check.html#test-ga-calib-dataset",
    "href": "ga-calib/l1_spectrum_value_check.html#test-ga-calib-dataset",
    "title": "L1 spectrum value check",
    "section": "Test GA-CALIB dataset",
    "text": "Test GA-CALIB dataset\n\nRed camera\n\nred_tests = L1SpectrumValueCheck(camera=\"RED\", n_processes=8)\nred_tests.run(folder=\"GA-CALIB\")\n\nLocating and converting where necessary:   0%|                                                                                      | 0/36 [00:00&lt;?, ?it/s]Locating and converting where necessary:   3%|██▏                                                                           | 1/36 [00:01&lt;00:37,  1.08s/it]Locating and converting where necessary:  11%|████████▋                                                                     | 4/36 [00:01&lt;00:08,  3.63it/s]Locating and converting where necessary:  14%|██████████▊                                                                   | 5/36 [00:01&lt;00:08,  3.77it/s]Locating and converting where necessary:  19%|███████████████▏                                                              | 7/36 [00:02&lt;00:07,  3.68it/s]Locating and converting where necessary:  22%|█████████████████▎                                                            | 8/36 [00:02&lt;00:07,  3.55it/s]Locating and converting where necessary:  25%|███████████████████▌                                                          | 9/36 [00:02&lt;00:06,  3.91it/s]Locating and converting where necessary:  31%|███████████████████████▌                                                     | 11/36 [00:02&lt;00:04,  5.92it/s]Locating and converting where necessary:  33%|█████████████████████████▋                                                   | 12/36 [00:02&lt;00:03,  6.45it/s]Locating and converting where necessary:  36%|███████████████████████████▊                                                 | 13/36 [00:03&lt;00:05,  3.95it/s]Locating and converting where necessary:  42%|████████████████████████████████                                             | 15/36 [00:03&lt;00:03,  5.91it/s]Locating and converting where necessary:  47%|████████████████████████████████████▎                                        | 17/36 [00:03&lt;00:03,  5.68it/s]Locating and converting where necessary:  53%|████████████████████████████████████████▋                                    | 19/36 [00:04&lt;00:03,  5.61it/s]Locating and converting where necessary:  58%|████████████████████████████████████████████▉                                | 21/36 [00:04&lt;00:03,  4.71it/s]Locating and converting where necessary:  64%|█████████████████████████████████████████████████▏                           | 23/36 [00:04&lt;00:02,  6.24it/s]Locating and converting where necessary:  69%|█████████████████████████████████████████████████████▍                       | 25/36 [00:05&lt;00:02,  3.96it/s]Locating and converting where necessary:  72%|███████████████████████████████████████████████████████▌                     | 26/36 [00:05&lt;00:02,  4.24it/s]Locating and converting where necessary:  75%|█████████████████████████████████████████████████████████▊                   | 27/36 [00:06&lt;00:02,  4.26it/s]Locating and converting where necessary:  78%|███████████████████████████████████████████████████████████▉                 | 28/36 [00:06&lt;00:01,  4.23it/s]Locating and converting where necessary:  83%|████████████████████████████████████████████████████████████████▏            | 30/36 [00:07&lt;00:01,  3.06it/s]Locating and converting where necessary:  86%|██████████████████████████████████████████████████████████████████▎          | 31/36 [00:07&lt;00:01,  3.28it/s]Locating and converting where necessary:  89%|████████████████████████████████████████████████████████████████████▍        | 32/36 [00:07&lt;00:01,  3.89it/s]Locating and converting where necessary:  92%|██████████████████████████████████████████████████████████████████████▌      | 33/36 [00:07&lt;00:00,  3.86it/s]Locating and converting where necessary:  94%|████████████████████████████████████████████████████████████████████████▋    | 34/36 [00:09&lt;00:00,  2.03it/s]Locating and converting where necessary: 100%|█████████████████████████████████████████████████████████████████████████████| 36/36 [00:09&lt;00:00,  2.93it/s]Locating and converting where necessary: 100%|█████████████████████████████████████████████████████████████████████████████| 36/36 [00:09&lt;00:00,  3.83it/s]\nReading netCDF files... took 1.66 s. Size is 15887.744 Mb\nTests took 11.66 s to prepare (including reading data).\nTests took 9.71 s to perform.\nnans_in_RED_FLUX:\n    Are there non-finite values in RED_FLUX?\nnans_in_RED_FLUX_NOSS:\n    Are there non-finite values in RED_FLUX_NOSS?\nnans_in_RED_IVAR:\n    Are there non-finite values in RED_IVAR?\nnans_in_RED_IVAR_NOSS:\n    Are there non-finite values in RED_IVAR_NOSS?\nnans_in_RED_SENSFUNC:\n    Are there non-finite values in RED_SENSFUNC?\nnegs_in_RED_IVAR:\n    Are there negative values in RED_IVAR?\nnegs_in_RED_IVAR_NOSS:\n    Are there negative values in RED_IVAR_NOSS?\nnegs_in_RED_SENSFUNC:\n    Are there negative values in RED_SENSFUNC?\n\n\n\nred_tests.summary()\n\n8 varieties of test and 17280 tested elements per variety, for total of 138240 tests.\nAll tests passed.\n\n\n\nred_tests.full_summary(by=\"RUN\")\n\n8 varieties of test and 17280 tested elements per variety, for total of 138240 tests.\n0 tests failed (0.00%) and 138240 tests passed (100.00%).\n\n\n\n\n\n\n\n\n\n\nfailed\n\n\ntest\nnans_in_RED_FLUX\nnans_in_RED_FLUX_NOSS\nnans_in_RED_IVAR\nnans_in_RED_IVAR_NOSS\nnans_in_RED_SENSFUNC\nnegs_in_RED_IVAR\nnegs_in_RED_IVAR_NOSS\nnegs_in_RED_SENSFUNC\n\n\nRUN\n\n\n\n\n\n\n\n\n\n\n\n\n3050611\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050613\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050615\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050636\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050638\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050640\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050886\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050888\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050890\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050924\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050926\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050928\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3051172\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3051174\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3051176\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3051210\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3051212\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3051214\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\n\n\n\n\n\nBlue camera\n\nblue_tests = L1SpectrumValueCheck(camera=\"BLUE\", n_processes=8)\nblue_tests.run(folder=\"GA-CALIB\")\n\nLocating and converting where necessary:   0%|                                                                                      | 0/36 [00:00&lt;?, ?it/s]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████| 36/36 [00:00&lt;00:00, 3601.46it/s]\nReading netCDF files... took 0.65 s. Size is 15887.744 Mb\nTests took 2.09 s to prepare (including reading data).\nTests took 7.59 s to perform.\nnans_in_BLUE_FLUX:\n    Are there non-finite values in BLUE_FLUX?\nnans_in_BLUE_FLUX_NOSS:\n    Are there non-finite values in BLUE_FLUX_NOSS?\nnans_in_BLUE_IVAR:\n    Are there non-finite values in BLUE_IVAR?\nnans_in_BLUE_IVAR_NOSS:\n    Are there non-finite values in BLUE_IVAR_NOSS?\nnans_in_BLUE_SENSFUNC:\n    Are there non-finite values in BLUE_SENSFUNC?\nnegs_in_BLUE_IVAR:\n    Are there negative values in BLUE_IVAR?\nnegs_in_BLUE_IVAR_NOSS:\n    Are there negative values in BLUE_IVAR_NOSS?\nnegs_in_BLUE_SENSFUNC:\n    Are there negative values in BLUE_SENSFUNC?\n\n\n\nblue_tests.summary()\n\n8 varieties of test and 17280 tested elements per variety, for total of 138240 tests.\nAll tests passed.\n\n\n\nblue_tests.full_summary(by=\"RUN\")\n\n8 varieties of test and 17280 tested elements per variety, for total of 138240 tests.\n0 tests failed (0.00%) and 138240 tests passed (100.00%).\n\n\n\n\n\n\n\n\n\n\nfailed\n\n\ntest\nnans_in_BLUE_FLUX\nnans_in_BLUE_FLUX_NOSS\nnans_in_BLUE_IVAR\nnans_in_BLUE_IVAR_NOSS\nnans_in_BLUE_SENSFUNC\nnegs_in_BLUE_IVAR\nnegs_in_BLUE_IVAR_NOSS\nnegs_in_BLUE_SENSFUNC\n\n\nRUN\n\n\n\n\n\n\n\n\n\n\n\n\n3050612\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050614\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050616\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050637\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050639\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050641\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050887\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050889\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050891\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050925\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050927\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3050929\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3051173\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3051175\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3051177\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3051211\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3051213\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3051215\n0\n0\n0\n0\n0\n0\n0\n0",
    "crumbs": [
      "ga-calib",
      "L1 spectrum value check"
    ]
  },
  {
    "objectID": "ga-calib/l1_spectrum_value_check.html#details",
    "href": "ga-calib/l1_spectrum_value_check.html#details",
    "title": "L1 spectrum value check",
    "section": "Details",
    "text": "Details\n\nplot_qty_and_nans(red_tests.data, 3050611, \"RED_FLUX\")\nplot_qty_and_nans(blue_tests.data, 3050612, \"BLUE_FLUX\")",
    "crumbs": [
      "ga-calib",
      "L1 spectrum value check"
    ]
  },
  {
    "objectID": "ga-calib/raw_spectrum_value_check.html",
    "href": "ga-calib/raw_spectrum_value_check.html",
    "title": "Raw spectrum value check",
    "section": "",
    "text": "from qagmire.diagnostics import RawSpectrumValueCheck",
    "crumbs": [
      "ga-calib",
      "Raw spectrum value check"
    ]
  },
  {
    "objectID": "ga-calib/raw_spectrum_value_check.html#test-ga-calib-dataset",
    "href": "ga-calib/raw_spectrum_value_check.html#test-ga-calib-dataset",
    "title": "Raw spectrum value check",
    "section": "Test GA-CALIB dataset",
    "text": "Test GA-CALIB dataset\n\ntests = RawSpectrumValueCheck(n_processes=8)\ntests.run(folder=\"GA-CALIB\")\n\nLocating and converting where necessary:   0%|                                                                                      | 0/36 [00:00&lt;?, ?it/s]Locating and converting where necessary:   3%|██▏                                                                           | 1/36 [00:01&lt;01:04,  1.85s/it]Locating and converting where necessary:   8%|██████▌                                                                       | 3/36 [00:02&lt;00:18,  1.77it/s]Locating and converting where necessary:  19%|███████████████▏                                                              | 7/36 [00:02&lt;00:05,  5.01it/s]Locating and converting where necessary:  25%|███████████████████▌                                                          | 9/36 [00:04&lt;00:11,  2.29it/s]Locating and converting where necessary:  33%|█████████████████████████▋                                                   | 12/36 [00:04&lt;00:06,  3.61it/s]Locating and converting where necessary:  39%|█████████████████████████████▉                                               | 14/36 [00:04&lt;00:04,  4.54it/s]Locating and converting where necessary:  44%|██████████████████████████████████▏                                          | 16/36 [00:04&lt;00:04,  4.69it/s]Locating and converting where necessary:  50%|██████████████████████████████████████▌                                      | 18/36 [00:06&lt;00:06,  2.93it/s]Locating and converting where necessary:  61%|███████████████████████████████████████████████                              | 22/36 [00:06&lt;00:03,  4.57it/s]Locating and converting where necessary:  67%|███████████████████████████████████████████████████▎                         | 24/36 [00:06&lt;00:02,  4.55it/s]Locating and converting where necessary:  69%|█████████████████████████████████████████████████████▍                       | 25/36 [00:07&lt;00:03,  3.15it/s]Locating and converting where necessary:  72%|███████████████████████████████████████████████████████▌                     | 26/36 [00:07&lt;00:03,  3.22it/s]Locating and converting where necessary:  75%|█████████████████████████████████████████████████████████▊                   | 27/36 [00:08&lt;00:02,  3.67it/s]Locating and converting where necessary:  78%|███████████████████████████████████████████████████████████▉                 | 28/36 [00:08&lt;00:01,  4.21it/s]Locating and converting where necessary:  83%|████████████████████████████████████████████████████████████████▏            | 30/36 [00:08&lt;00:01,  5.47it/s]Locating and converting where necessary:  86%|██████████████████████████████████████████████████████████████████▎          | 31/36 [00:08&lt;00:00,  5.55it/s]Locating and converting where necessary:  89%|████████████████████████████████████████████████████████████████████▍        | 32/36 [00:08&lt;00:00,  5.94it/s]Locating and converting where necessary:  92%|██████████████████████████████████████████████████████████████████████▌      | 33/36 [00:09&lt;00:01,  2.37it/s]Locating and converting where necessary:  94%|████████████████████████████████████████████████████████████████████████▋    | 34/36 [00:09&lt;00:00,  2.83it/s]Locating and converting where necessary:  97%|██████████████████████████████████████████████████████████████████████████▊  | 35/36 [00:10&lt;00:00,  3.26it/s]Locating and converting where necessary: 100%|█████████████████████████████████████████████████████████████████████████████| 36/36 [00:10&lt;00:00,  3.77it/s]Locating and converting where necessary: 100%|█████████████████████████████████████████████████████████████████████████████| 36/36 [00:10&lt;00:00,  3.48it/s]\nReading netCDF files... took 1.36 s. Size is 5336.749 Mb\nTests took 13.13 s to prepare (including reading data).\nTests took 7.47 s to perform.\ntoo_many_sat_in_counts1:\n    Are there too many pixels saturated above the ADU threshold in counts1?\nneg_pixels_in_counts1:\n    Are there negative pixel values in counts1?\nnan_pixels_in_counts1:\n    Are there non-finite pixel values in counts1?\ntoo_many_sat_in_counts2:\n    Are there too many pixels saturated above the ADU threshold in counts2?\nneg_pixels_in_counts2:\n    Are there negative pixel values in counts2?\nnan_pixels_in_counts2:\n    Are there non-finite pixel values in counts2?\n\n\n\ntests.summary()\n\n6 varieties of test and 36 tested elements per variety, for total of 216 tests.\n13 tests failed (6.02%) and 203 tests passed (93.98%).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\n\n\n\n\n\ntest\ntoo_many_sat_in_counts1\ntoo_many_sat_in_counts2\n\n\n\nfilename\nRUN\nCAMERA\nMJD\nNIGHT\nOBID\n\n\n\n\n\n\n\nr3050928\n3050928\nRED\n60385.97607\n20240316\n12366\nTrue\nTrue\n2\n\n\nr3051213\n3051213\nBLUE\n60386.97421\n20240317\n12392\nTrue\nTrue\n2\n\n\nr3050613\n3050613\nRED\n60384.88693\n20240315\n12398\nTrue\nFalse\n1\n\n\nr3050637\n3050637\nBLUE\n60384.93435\n20240315\n12382\nTrue\nFalse\n1\n\n\nr3050638\n3050638\nRED\n60384.94846\n20240315\n12382\nTrue\nFalse\n1\n\n\nr3050641\n3050641\nBLUE\n60384.96260\n20240315\n12382\nFalse\nTrue\n1\n\n\nr3050926\n3050926\nRED\n60385.96193\n20240316\n12366\nTrue\nFalse\n1\n\n\nr3050929\n3050929\nBLUE\n60385.97609\n20240316\n12366\nTrue\nFalse\n1\n\n\nr3051172\n3051172\nRED\n60386.87492\n20240317\n12383\nFalse\nTrue\n1\n\n\nr3051174\n3051174\nRED\n60386.88906\n20240317\n12383\nTrue\nFalse\n1\n\n\nr3051176\n3051176\nRED\n60386.90320\n20240317\n12383\nFalse\nTrue\n1\n\n\n\n\n\n\n\n\n\ntests.summary(per_test=True, by=\"RUN\")\n\n6 varieties of test and 36 tested elements per variety, for total of 216 tests.\n13 tests failed (6.02%) and 203 tests passed (93.98%).\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\nRUN\n3050613\n3050637\n3050638\n3050641\n3050926\n3050928\n3050929\n3051172\n3051174\n3051176\n3051213\n\n\n\ntest\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntoo_many_sat_in_counts1\n1\n1\n1\n0\n1\n1\n1\n0\n1\n0\n1\n8\n\n\ntoo_many_sat_in_counts2\n0\n0\n0\n1\n0\n1\n0\n1\n0\n1\n1\n5",
    "crumbs": [
      "ga-calib",
      "Raw spectrum value check"
    ]
  },
  {
    "objectID": "ga-calib/raw_spectrum_value_check.html#details",
    "href": "ga-calib/raw_spectrum_value_check.html#details",
    "title": "Raw spectrum value check",
    "section": "Details",
    "text": "Details\nThere are no NaN or negative pixels, but around a third of the runs contain saturated pixels. Let’s find out how many.\n\ndf = tests.stats.to_dataframe()\n\n\nsat_counts = df[[\"counts1_sat\", \"counts2_sat\"]]\nsat_counts = sat_counts[sat_counts.sum(axis=\"columns\") &gt; 0]\nsat_counts\n\n\n\n\n\n\n\n\n\ncounts1_sat\ncounts2_sat\n\n\nfilename\n\n\n\n\n\n\nr3050613\n1\n0\n\n\nr3050637\n3\n0\n\n\nr3050641\n0\n4\n\n\nr3050638\n1\n0\n\n\nr3050926\n1\n0\n\n\nr3050928\n5\n7\n\n\nr3050929\n8\n0\n\n\nr3051172\n0\n1\n\n\nr3051174\n1\n0\n\n\nr3051176\n0\n1\n\n\nr3051213\n1\n1\n\n\n\n\n\n\n\n\nOnly a few saturated pixels in each image. Could set n_allowed_saturated_pixels=10 to allow these tests to pass.",
    "crumbs": [
      "ga-calib",
      "Raw spectrum value check"
    ]
  },
  {
    "objectID": "ga-calib/obs_cond_check.html",
    "href": "ga-calib/obs_cond_check.html",
    "title": "Observing conditions check",
    "section": "",
    "text": "from qagmire.diagnostics import ObsCondCheck",
    "crumbs": [
      "ga-calib",
      "Observing conditions check"
    ]
  },
  {
    "objectID": "ga-calib/obs_cond_check.html#test-ga-calib-dataset",
    "href": "ga-calib/obs_cond_check.html#test-ga-calib-dataset",
    "title": "Observing conditions check",
    "section": "Test GA-CALIB dataset",
    "text": "Test GA-CALIB dataset\n\ntests = ObsCondCheck()\ntests.run(folder=\"GA-CALIB\")\n\nReading files: 100%|██████████| 36/36 [00:00&lt;00:00, 42.76it/s]\nCreating Dataset... took 0.76 s. Size is 0.227 Mb\nTests took 5.15 s to prepare (including reading data).\nTests took 1.00 s to perform.\nsky_too_bright:\n    Is the sky brighter than the requirement?\nseeing_too_poor:\n    Is the seeing worse than the requirement?\nwrong_run_count:\n    Are there other than two runs with the same EXPID?\nunmatched_runs_sky:\n    Do runs with the same EXPID have different sky brightness?\nunmatched_runs_seeing:\n    Do runs with the same EXPID have different seeing?\nReading files:  28%|████████████████████████████▌                                                                          | 10/36 [00:00&lt;00:00, 51.64it/s]Reading files:  44%|█████████████████████████████████████████████▊                                                         | 16/36 [00:00&lt;00:00, 42.15it/s]Reading files:  61%|██████████████████████████████████████████████████████████████▉                                        | 22/36 [00:00&lt;00:00, 47.22it/s]Reading files:  75%|█████████████████████████████████████████████████████████████████████████████▎                         | 27/36 [00:00&lt;00:00, 37.28it/s]Reading files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00&lt;00:00, 49.30it/s]Reading files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00&lt;00:00, 44.79it/s]\nCreating Dataset... took 0.60 s. Size is 0.227 Mb\nTests took 3.05 s to prepare (including reading data).\nTests took 1.00 s to perform.\nsky_too_bright:\n    Is the sky brighter than the requirement?\nseeing_too_poor:\n    Is the seeing worse than the requirement?\nwrong_run_count:\n    Are there other than two runs with the same EXPID?\nunmatched_runs_sky:\n    Do runs with the same EXPID have different sky brightness?\nunmatched_runs_seeing:\n    Do runs with the same EXPID have different seeing?\n\n\n\ntests.summary_per_test()\n\n5 varieties of test and 18 tested elements per variety, for total of 90 tests.\n17 tests failed (18.89%) and 73 tests passed (81.11%).\n\n\n\n\n\n\n\n\n\n\ntotal fails\n\n\ntest\n\n\n\n\n\nunmatched_runs_seeing\n11\n\n\nunmatched_runs_sky\n3\n\n\nsky_too_bright\n2\n\n\nseeing_too_poor\n1\n\n\nwrong_run_count\n0\n\n\n\n\n\n\n\n\n\ntests.summary()\n\n5 varieties of test and 18 tested elements per variety, for total of 90 tests.\n17 tests failed (18.89%) and 73 tests passed (81.11%).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\n\n\n\n\n\ntest\nseeing_too_poor\nsky_too_bright\nunmatched_runs_seeing\nunmatched_runs_sky\n\n\n\nEXPID\nfilename\nRUN\nOBID\nMJD\nNIGHT\n\n\n\n\n\n\n\n\n\n1238300000002\nsingle_3051174\n3051174\n12383\n60386.88906\n20240317\nFalse\nTrue\nTrue\nTrue\n3\n\n\n1238300000001\nsingle_3051172\n3051172\n12383\n60386.87492\n20240317\nFalse\nTrue\nTrue\nFalse\n2\n\n\n1239200000002\nsingle_3051212\n3051212\n12392\n60386.97419\n20240317\nTrue\nFalse\nTrue\nFalse\n2\n\n\n1239800000002\nsingle_3050613\n3050613\n12398\n60384.88693\n20240315\nFalse\nFalse\nTrue\nTrue\n2\n\n\n1236700000003\nsingle_3050890\n3050890\n12367\n60385.90479\n20240316\nFalse\nFalse\nFalse\nTrue\n1\n\n\n1238200000001\nsingle_3050636\n3050636\n12382\n60384.93434\n20240315\nFalse\nFalse\nTrue\nFalse\n1\n\n\n1238200000002\nsingle_3050638\n3050638\n12382\n60384.94846\n20240315\nFalse\nFalse\nTrue\nFalse\n1\n\n\n1238200000003\nsingle_3050640\n3050640\n12382\n60384.96259\n20240315\nFalse\nFalse\nTrue\nFalse\n1\n\n\n1238300000003\nsingle_3051176\n3051176\n12383\n60386.90320\n20240317\nFalse\nFalse\nTrue\nFalse\n1\n\n\n1239200000003\nsingle_3051214\n3051214\n12392\n60386.98834\n20240317\nFalse\nFalse\nTrue\nFalse\n1\n\n\n1239800000001\nsingle_3050611\n3050611\n12398\n60384.87280\n20240315\nFalse\nFalse\nTrue\nFalse\n1\n\n\n1239800000003\nsingle_3050615\n3050615\n12398\n60384.90106\n20240315\nFalse\nFalse\nTrue\nFalse\n1",
    "crumbs": [
      "ga-calib",
      "Observing conditions check"
    ]
  },
  {
    "objectID": "ga-calib/obs_cond_check.html#details",
    "href": "ga-calib/obs_cond_check.html#details",
    "title": "Observing conditions check",
    "section": "Details",
    "text": "Details\nThere are a couple of cases of seeing or sky not meeting requirements. Sometimes the seeing and sky values differ for the two runs in an exposure.\n\nhdr, obs = tests.data\nobs = obs.to_dataframe().reset_index().set_index(\"EXPID\")\nhdr = hdr.to_dataframe().reset_index().set_index([\"EXPID\", \"CAMERA\"])\n\n\ndef highlight(s, col, greater=False):\n    col1 = col2 = \"\"\n    if greater:\n        if (s[\"BLUE\"] &gt; s[col]) or (s[\"RED\"] &gt; s[col]):\n            col1 = \"yellow\"\n    else:\n        if (s[\"BLUE\"] &lt; s[col]) or (s[\"RED\"] &lt; s[col]):\n            col1 = \"yellow\"\n    if s[\"BLUE\"] != s[\"RED\"]:\n        col2 = \"yellow\"\n    return [f\"background-color: {c}\" for c in (col1, col2, col2)]\n\n\nrequested = obs[[\"sky_brightness\"]]\nreported = hdr[[\"SKYBRTEL\"]].unstack(\"CAMERA\").droplevel(0, axis=\"columns\")\nsky_table = requested.join(reported)\nsky_table.style.apply(highlight, axis=1, col=\"sky_brightness\")\n\n\n\n\n\n\n\n \nsky_brightness\nBLUE\nRED\n\n\nEXPID\n \n \n \n\n\n\n\n1236600000001\n18.500000\n18.920000\n18.920000\n\n\n1236600000002\n18.500000\n18.830000\n18.830000\n\n\n1236600000003\n18.500000\n18.960000\n18.960000\n\n\n1236700000001\n18.500000\n18.840000\n18.840000\n\n\n1236700000002\n18.500000\n19.150000\n19.150000\n\n\n1236700000003\n18.500000\n19.120000\n19.080000\n\n\n1238200000001\n18.500000\n19.440000\n19.440000\n\n\n1238200000002\n18.500000\n19.440000\n19.440000\n\n\n1238200000003\n18.500000\n19.450000\n19.450000\n\n\n1238300000001\n18.500000\n18.060000\n18.060000\n\n\n1238300000002\n18.500000\n18.090000\n18.060000\n\n\n1238300000003\n18.500000\n18.860000\n18.860000\n\n\n1239200000001\n18.500000\n18.710000\n18.710000\n\n\n1239200000002\n18.500000\n18.730000\n18.730000\n\n\n1239200000003\n18.500000\n18.740000\n18.740000\n\n\n1239800000001\n18.500000\n19.450000\n19.450000\n\n\n1239800000002\n18.500000\n19.470000\n19.450000\n\n\n1239800000003\n18.500000\n19.470000\n19.470000\n\n\n\n\n\n\n\nrequested = obs[[\"seeing\"]]\nreported = hdr[[\"SEEINGB\"]].unstack(\"CAMERA\").droplevel(0, axis=\"columns\")\nseeing_table = requested.join(reported)\nseeing_table.style.apply(highlight, axis=1, col=\"seeing\", greater=True)\n\n\n\n\n\n\n\n \nseeing\nBLUE\nRED\n\n\nEXPID\n \n \n \n\n\n\n\n1236600000001\n1.200000\n1.050897\n1.050897\n\n\n1236600000002\n1.200000\n1.050897\n1.050897\n\n\n1236600000003\n1.200000\n1.050897\n1.050897\n\n\n1236700000001\n1.200000\n1.143888\n1.143888\n\n\n1236700000002\n1.200000\n1.143888\n1.143888\n\n\n1236700000003\n1.200000\n1.143888\n1.143888\n\n\n1238200000001\n1.200000\n0.959378\n0.763409\n\n\n1238200000002\n1.200000\n0.607656\n0.462677\n\n\n1238200000003\n1.200000\n0.692259\n0.780901\n\n\n1238300000001\n1.200000\n0.921568\n0.630301\n\n\n1238300000002\n1.200000\n0.556373\n0.702032\n\n\n1238300000003\n1.200000\n0.780123\n0.792634\n\n\n1239200000001\n1.200000\n0.858645\n0.858645\n\n\n1239200000002\n1.200000\n0.790407\n1.464800\n\n\n1239200000003\n1.200000\n0.819922\n0.765080\n\n\n1239800000001\n1.200000\n1.021651\n1.008862\n\n\n1239800000002\n1.200000\n0.707760\n0.595759\n\n\n1239800000003\n1.200000\n0.608158\n0.577733\n\n\n\n\n\n\nSEEINGB often differs between the two runs within an exposure, sometimes substantially. On the other hand SEEINGE, does not. Note that SEEINGB for the RED camera matches SEEINGE for the previous exposure, as one might hope.\n\nrequested = obs[[\"seeing\"]]\nreported = hdr[[\"SEEINGE\"]].unstack(\"CAMERA\").droplevel(0, axis=\"columns\")\nseeing_table = requested.join(reported)\nseeing_table.style.apply(highlight, axis=1, col=\"seeing\", greater=True)\n\n\n\n\n\n\n\n \nseeing\nBLUE\nRED\n\n\nEXPID\n \n \n \n\n\n\n\n1236600000001\n1.200000\n1.050897\n1.050897\n\n\n1236600000002\n1.200000\n1.050897\n1.050897\n\n\n1236600000003\n1.200000\n1.050897\n1.050897\n\n\n1236700000001\n1.200000\n1.143888\n1.143888\n\n\n1236700000002\n1.200000\n1.143888\n1.143888\n\n\n1236700000003\n1.200000\n1.143888\n1.143888\n\n\n1238200000001\n1.200000\n0.462677\n0.462677\n\n\n1238200000002\n1.200000\n0.780901\n0.780901\n\n\n1238200000003\n1.200000\n0.602429\n0.602429\n\n\n1238300000001\n1.200000\n0.702032\n0.702032\n\n\n1238300000002\n1.200000\n0.792634\n0.792634\n\n\n1238300000003\n1.200000\n0.903237\n0.903237\n\n\n1239200000001\n1.200000\n1.464800\n1.464800\n\n\n1239200000002\n1.200000\n0.765080\n0.765080\n\n\n1239200000003\n1.200000\n0.955168\n0.955168\n\n\n1239800000001\n1.200000\n0.595759\n0.595759\n\n\n1239800000002\n1.200000\n0.577733\n0.577733\n\n\n1239800000003\n1.200000\n0.701651\n0.701651",
    "crumbs": [
      "ga-calib",
      "Observing conditions check"
    ]
  },
  {
    "objectID": "quality_assurance.html",
    "href": "quality_assurance.html",
    "title": "quality_assurance",
    "section": "",
    "text": "To write checks of the data, we will create a subclass of Diagnostics.\nTo speed up running calculations on large datasets, this includes an option to run a set of workers on a single node. There are also ways to easily leverage multiple nodes.\n\nsource\n\nDiagnostics\n\n Diagnostics (n_processes=1)\n\nAn abstract class to be subclassed to perform specific diagnostic checks.\nA subclass should perform a set of checks, implemented in a method named tests.\nCalling the method run will combine and compute the tests, putting the results as a single boolean DataArray the detail attribute for further analysis.\nOnce run has been called, a test_descriptions will also be available, and summaries of the test results can be created using the summary method.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nn_processes\nint\n1\nhow many subprocesses to use for computing the tests\n\n\n\nIn this subclass we need to implement the tests method.\nThese tests are executed by calling the run method.\nThe summary method outputs a pandas DataFrame summary of the test outcomes, by default this shows only failed tests and elements (e.g. OBs or exposures) with the most failures.\nSee the diagnostics submodule for example tests.",
    "crumbs": [
      "quality_assurance"
    ]
  },
  {
    "objectID": "ga-calib/measured_sky_check.html",
    "href": "ga-calib/measured_sky_check.html",
    "title": "Measured sky check",
    "section": "",
    "text": "from qagmire.diagnostics import MeasuredSkyCheck",
    "crumbs": [
      "ga-calib",
      "Measured sky check"
    ]
  },
  {
    "objectID": "ga-calib/measured_sky_check.html#test-ga-calib-dataset",
    "href": "ga-calib/measured_sky_check.html#test-ga-calib-dataset",
    "title": "Measured sky check",
    "section": "Test GA-CALIB dataset",
    "text": "Test GA-CALIB dataset\n\ntests = MeasuredSkyCheck(n_processes=1)\ntests.run(folder=\"GA-CALIB\")\n\nLocating and converting where necessary:   0%|                                                                                      | 0/12 [00:00&lt;?, ?it/s]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████| 12/12 [00:00&lt;00:00, 1390.80it/s]\nReading netCDF files... took 0.74 s. Size is 5296.042 Mb\nReading files:   0%|                                                                                                                | 0/12 [00:00&lt;?, ?it/s]Reading files:   8%|████████▋                                                                                               | 1/12 [00:00&lt;00:01,  8.17it/s]Reading files:  75%|██████████████████████████████████████████████████████████████████████████████                          | 9/12 [00:00&lt;00:00, 25.52it/s]Reading files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00&lt;00:00, 25.57it/s]Reading files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00&lt;00:00, 24.14it/s]\nCreating Dataset... took 0.06 s. Size is 4.738 Mb\nReading files:   0%|                                                                                                                | 0/12 [00:00&lt;?, ?it/s]Reading files:   8%|████████▋                                                                                               | 1/12 [00:00&lt;00:03,  3.29it/s]Reading files:  83%|█████████████████████████████████████████████████████████████████████████████████████▊                 | 10/12 [00:00&lt;00:00, 20.44it/s]Reading files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00&lt;00:00, 21.13it/s]\nCreating Dataset... took 0.28 s. Size is 0.078 Mb\nTests took 2.85 s to prepare (including reading data).\nTests took 6.21 s to perform.\nsky_too_bright:\n    Does the measured sky brightness in the raw spectra satisfy the observational requirement?\nsky_too_variable:\n    Does the measured sky brightness vary substantially (&gt; 0.2 mag) between the sky fibres for each OB?\n\n\n\ntests.summary()\n\n2 varieties of test and 6 tested elements per variety, for total of 12 tests.\n9 tests failed (75.00%) and 3 tests passed (25.00%).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\n\n\n\n\n\ntest\nsky_too_bright\nsky_too_variable\n\n\n\nOBID\nfilename\nRUN\nCAMERA\nMJD\nNIGHT\n\n\n\n\n\n\n\n12366\nstack_3050925\n3050925\nBLUE\n60385.94781\n20240316\nTrue\nTrue\n2\n\n\n12382\nstack_3050637\n3050637\nBLUE\n60384.93435\n20240315\nTrue\nTrue\n2\n\n\n12383\nstack_3051173\n3051173\nBLUE\n60386.87493\n20240317\nTrue\nTrue\n2\n\n\n12392\nstack_3051211\n3051211\nBLUE\n60386.96006\n20240317\nTrue\nTrue\n2\n\n\n12367\nstack_3050887\n3050887\nBLUE\n60385.87653\n20240316\nFalse\nTrue\n1",
    "crumbs": [
      "ga-calib",
      "Measured sky check"
    ]
  },
  {
    "objectID": "ga-calib/measured_sky_check.html#details",
    "href": "ga-calib/measured_sky_check.html#details",
    "title": "Measured sky check",
    "section": "Details",
    "text": "Details\nThe high (in some cases infinite) sigma_sky suggests the sky is being contaminated by bad pixels. This is likely, since the photometry is being done without use of the noise map. Work to be done.\n\ntests.stats.to_dataframe()[tests.stats.data_vars]\n\n\n\n\n\n\n\n\n\nmedian_sky\nsky_limit\nsigma_sky\n\n\nOBID\n\n\n\n\n\n\n\n12398\n18.889899\n18.5\n0.084998\n\n\n12382\n17.781169\n18.5\ninf\n\n\n12367\n18.683502\n18.5\ninf\n\n\n12366\n17.431117\n18.5\n0.350555\n\n\n12383\n18.377818\n18.5\n0.933422\n\n\n12392\n17.363829\n18.5\ninf",
    "crumbs": [
      "ga-calib",
      "Measured sky check"
    ]
  },
  {
    "objectID": "ga-calib/l1_spectrum_masked_value_check.html",
    "href": "ga-calib/l1_spectrum_masked_value_check.html",
    "title": "L1 spectrum masked value check",
    "section": "",
    "text": "import dask\n\nfrom qagmire.diagnostics import L1SpectrumMaskedValueCheck\nfrom qagmire.diagnostics.l1_spectrum_masked_value_check import plot_unmasked_and_invalid",
    "crumbs": [
      "ga-calib",
      "L1 spectrum masked value check"
    ]
  },
  {
    "objectID": "ga-calib/l1_spectrum_masked_value_check.html#test-ga-calib-dataset",
    "href": "ga-calib/l1_spectrum_masked_value_check.html#test-ga-calib-dataset",
    "title": "L1 spectrum masked value check",
    "section": "Test GA-CALIB dataset",
    "text": "Test GA-CALIB dataset\n\nRed camera\n\nred_tests = L1SpectrumMaskedValueCheck(camera=\"RED\", n_processes=8)\nred_tests.run(folder=\"GA-CALIB\")\n\nLocating and converting where necessary:   0%|                                                                                      | 0/36 [00:00&lt;?, ?it/s]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████| 36/36 [00:00&lt;00:00, 3577.57it/s]\nReading netCDF files... took 1.57 s. Size is 15887.744 Mb\nTests took 2.30 s to prepare (including reading data).\nTests took 7.03 s to perform.\nneg_flux_unmasked_in_RED_IVAR:\n    Are there unmasked pixels in IVAR where FLUX_NOSS is negative?\nnlr_flux_unmasked_in_RED_IVAR:\n    Are there unmasked pixels in IVAR where FLUX_NOSS is non-linear?\nneg_flux_unmasked_in_RED_IVAR_NOSS:\n    Are there unmasked pixels in IVAR_NOSS where FLUX_NOSS is negative?\nnlr_flux_unmasked_in_RED_IVAR_NOSS:\n    Are there unmasked pixels in IVAR_NOSS where FLUX_NOSS is non-linear?\n\n\n\nred_tests.summary(by=\"RUN\")\n\n4 varieties of test and 17280 tested elements per variety, for total of 69120 tests.\n806 tests failed (1.17%) and 68314 tests passed (98.83%).\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\ntest\nneg_flux_unmasked_in_RED_IVAR\nneg_flux_unmasked_in_RED_IVAR_NOSS\nnlr_flux_unmasked_in_RED_IVAR\nnlr_flux_unmasked_in_RED_IVAR_NOSS\n\n\n\nRUN\n\n\n\n\n\n\n\n\n\n3050615\n32\n32\n0\n0\n64\n\n\n3050886\n29\n29\n0\n0\n58\n\n\n3051214\n29\n29\n0\n0\n58\n\n\n3050611\n27\n27\n0\n0\n54\n\n\n3050926\n27\n27\n0\n0\n54\n\n\n3050924\n26\n26\n0\n0\n52\n\n\n3051212\n25\n25\n0\n0\n50\n\n\n3050638\n23\n23\n0\n0\n46\n\n\n3050640\n22\n22\n0\n0\n44\n\n\n3050890\n22\n22\n0\n0\n44\n\n\n3051210\n21\n21\n0\n0\n42\n\n\n3050636\n20\n20\n0\n0\n40\n\n\n3050888\n19\n19\n0\n0\n38\n\n\n3050613\n18\n18\n0\n0\n36\n\n\n3051176\n17\n17\n1\n1\n36\n\n\n3050928\n17\n17\n0\n0\n34\n\n\n3051174\n17\n17\n0\n0\n34\n\n\n3051172\n11\n11\n0\n0\n22\n\n\n\n\n\n\n\n\n\nred_tests.summary(by=\"NSPEC\")\n\n4 varieties of test and 17280 tested elements per variety, for total of 69120 tests.\n806 tests failed (1.17%) and 68314 tests passed (98.83%).\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\ntest\nneg_flux_unmasked_in_RED_IVAR\nneg_flux_unmasked_in_RED_IVAR_NOSS\nnlr_flux_unmasked_in_RED_IVAR\nnlr_flux_unmasked_in_RED_IVAR_NOSS\n\n\n\nNSPEC\n\n\n\n\n\n\n\n\n\n561\n8\n8\n0\n0\n16\n\n\n333\n7\n7\n0\n0\n14\n\n\n647\n6\n6\n0\n0\n12\n\n\n651\n6\n6\n0\n0\n12\n\n\n729\n6\n6\n0\n0\n12\n\n\n...\n...\n...\n...\n...\n...\n\n\n825\n1\n1\n0\n0\n2\n\n\n828\n1\n1\n0\n0\n2\n\n\n850\n0\n0\n1\n1\n2\n\n\n903\n1\n1\n0\n0\n2\n\n\n933\n1\n1\n0\n0\n2\n\n\n\n\n158 rows × 5 columns\n\n\n\n\n\n\nBlue camera\n\nblue_tests = L1SpectrumMaskedValueCheck(camera=\"BLUE\", n_processes=8)\nblue_tests.run(folder=\"GA-CALIB\")\n\nLocating and converting where necessary:   0%|                                                                                      | 0/36 [00:00&lt;?, ?it/s]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████| 36/36 [00:00&lt;00:00, 3718.63it/s]\nReading netCDF files... took 0.94 s. Size is 15887.744 Mb\nTests took 1.48 s to prepare (including reading data).\nTests took 5.99 s to perform.\nneg_flux_unmasked_in_BLUE_IVAR:\n    Are there unmasked pixels in IVAR where FLUX_NOSS is negative?\nnlr_flux_unmasked_in_BLUE_IVAR:\n    Are there unmasked pixels in IVAR where FLUX_NOSS is non-linear?\nneg_flux_unmasked_in_BLUE_IVAR_NOSS:\n    Are there unmasked pixels in IVAR_NOSS where FLUX_NOSS is negative?\nnlr_flux_unmasked_in_BLUE_IVAR_NOSS:\n    Are there unmasked pixels in IVAR_NOSS where FLUX_NOSS is non-linear?\n\n\n\nblue_tests.summary(by=\"RUN\")\n\n4 varieties of test and 17280 tested elements per variety, for total of 69120 tests.\n3738 tests failed (5.41%) and 65382 tests passed (94.59%).\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\ntest\nneg_flux_unmasked_in_BLUE_IVAR\nneg_flux_unmasked_in_BLUE_IVAR_NOSS\n\n\n\nRUN\n\n\n\n\n\n\n\n3050929\n150\n150\n300\n\n\n3050927\n138\n138\n276\n\n\n3051215\n131\n131\n262\n\n\n3050925\n114\n114\n228\n\n\n3050889\n113\n113\n226\n\n\n3050891\n113\n113\n226\n\n\n3051175\n108\n108\n216\n\n\n3050616\n107\n107\n214\n\n\n3051213\n106\n106\n212\n\n\n3050887\n105\n105\n210\n\n\n3050612\n98\n98\n196\n\n\n3050614\n91\n91\n182\n\n\n3050637\n90\n90\n180\n\n\n3051211\n90\n90\n180\n\n\n3050641\n88\n88\n176\n\n\n3051173\n85\n85\n170\n\n\n3051177\n78\n78\n156\n\n\n3050639\n64\n64\n128\n\n\n\n\n\n\n\n\n\nblue_tests.summary(by=\"NSPEC\")\n\n4 varieties of test and 17280 tested elements per variety, for total of 69120 tests.\n3738 tests failed (5.41%) and 65382 tests passed (94.59%).\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\ntest\nneg_flux_unmasked_in_BLUE_IVAR\nneg_flux_unmasked_in_BLUE_IVAR_NOSS\n\n\n\nNSPEC\n\n\n\n\n\n\n\n396\n12\n12\n24\n\n\n561\n12\n12\n24\n\n\n623\n12\n12\n24\n\n\n832\n12\n12\n24\n\n\n620\n10\n10\n20\n\n\n...\n...\n...\n...\n\n\n857\n1\n1\n2\n\n\n863\n1\n1\n2\n\n\n898\n1\n1\n2\n\n\n916\n1\n1\n2\n\n\n946\n1\n1\n2\n\n\n\n\n523 rows × 3 columns",
    "crumbs": [
      "ga-calib",
      "L1 spectrum masked value check"
    ]
  },
  {
    "objectID": "ga-calib/l1_spectrum_masked_value_check.html#details",
    "href": "ga-calib/l1_spectrum_masked_value_check.html#details",
    "title": "L1 spectrum masked value check",
    "section": "Details",
    "text": "Details\nThere is one spectrum (in red camera) in which there is a single pixel above the chosen non-linearity threshold of 60000, but which is not masked. The few pixels with higher values (presumably at least 65535) are masked, but they are not capped at 65535.\n\nn_nlr = (\n    (red_tests.data[\"RED_FLUX_NOSS\"] &gt; 60000)\n    & (red_tests.data[\"RED_FLUX_NOSS\"] &lt; 65535)\n).sum()\nn_sat = (red_tests.data[\"RED_FLUX_NOSS\"] &gt;= 65535).sum()\nval_sat = (\n    red_tests.data[\"RED_FLUX_NOSS\"]\n    .where(red_tests.data[\"RED_FLUX_NOSS\"] &gt;= 65535)\n    .mean()\n)\nn_nlr, n_sat, val_sat = (x.to_numpy() for x in dask.compute(n_nlr, n_sat, val_sat))\nprint(\n    f\"There are {n_nlr} pixels between 60000 and 65535, \"\n    f\"and {n_sat} pixels with a value of at least 65535, \"\n    f\"with an average value of {val_sat}.\"\n)\n\nThere are 1 pixels between 60000 and 65535, and 3 pixels with a value of at least 65535, with an average value of 72913.21875.\n\n\nIt is relatively common for spectra (especially in the blue camera) to have negative values that are not masked.\n\nplot_unmasked_and_invalid(red_tests, 3050615)\nplot_unmasked_and_invalid(blue_tests, 3050929)",
    "crumbs": [
      "ga-calib",
      "L1 spectrum masked value check"
    ]
  },
  {
    "objectID": "ga-calib/sky_noise_distribution_check.html",
    "href": "ga-calib/sky_noise_distribution_check.html",
    "title": "Sky noise distribution check",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport xarray as xr\nfrom dask.distributed import Client\n\nfrom qagmire.data import (\n    get_weave_files,\n    read_fibre_table_nspec,\n    read_l1_data,\n    read_raw_data,\n)\nfrom qagmire.diagnostics import SkyNoiseDistributionCheck\nfrom qagmire.diagnostics.sky_noise_distribution_check import (\n    plot_dist,\n    plot_hist,\n    plot_stack_over_single,\n)",
    "crumbs": [
      "ga-calib",
      "Sky noise distribution check"
    ]
  },
  {
    "objectID": "ga-calib/sky_noise_distribution_check.html#test-ga-calib-dataset",
    "href": "ga-calib/sky_noise_distribution_check.html#test-ga-calib-dataset",
    "title": "Sky noise distribution check",
    "section": "Test GA-CALIB dataset",
    "text": "Test GA-CALIB dataset\n\nStacked observations\n\ntests_stack = SkyNoiseDistributionCheck(stack=True, n_processes=8)\ntests_stack.run(folder=\"GA-CALIB\")\n\nLocating and converting where necessary: 100%|██████████| 12/12 [00:00&lt;00:00, 1502.84it/s]\nReading netCDF files... took 2.60 s. Size is 5296.042 Mb\nReading files: 100%|██████████| 12/12 [00:00&lt;00:00, 21.36it/s]\nCreating Dataset... took 0.09 s. Size is 4.738 Mb\nTests took 4.51 s to prepare (including reading data).\nTests took 5.56 s to perform.\nmean_non_zero:\n    Is the mean of the normalised flux in sky fibres significantly different from zero?\nstdev_non_unit:\n    Is the standard deviation of the normalised flux in sky fibres significantly different from unity?\nks_non_normal:\n    Does the distribution of normalised flux in sky fibres fail a KS test comparison with a standard Normal?\ntook 0.74 s. Size is 5296.042 Mb\nReading files:   0%|                                                                                                                | 0/12 [00:00&lt;?, ?it/s]Reading files:   8%|████████▋                                                                                               | 1/12 [00:00&lt;00:03,  2.95it/s]Reading files:  17%|█████████████████▎                                                                                      | 2/12 [00:00&lt;00:02,  4.22it/s]Reading files:  92%|██████████████████████████████████████████████████████████████████████████████████████████████▍        | 11/12 [00:00&lt;00:00, 26.20it/s]Reading files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00&lt;00:00, 18.26it/s]\nCreating Dataset... took 0.06 s. Size is 4.738 Mb\nTests took 5.35 s to prepare (including reading data).\nTests took 5.68 s to perform.\nmean_non_zero:\n    Is the mean of the normalised flux in sky fibres significantly different from zero?\nstdev_non_unit:\n    Is the standard deviation of the normalised flux in sky fibres significantly different from unity?\nks_non_normal:\n    Does the distribution of normalised flux in sky fibres fail a KS test comparison with a standard Normal?\n\n\n\ntests_stack.summary(by=[\"OBID\", \"CAMERA\"], sort_by_total_fails=False)\n\n3 varieties of test and 114 tested elements per variety, for total of 342 tests.\n333 tests failed (97.37%) and 9 tests passed (2.63%).\n\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\n\ntest\nks_non_normal\nmean_non_zero\nstdev_non_unit\n\n\n\nOBID\nCAMERA\n\n\n\n\n\n\n\n\n12366\nBLUE\n10\n10\n7\n27\n\n\nRED\n10\n10\n10\n30\n\n\n12367\nBLUE\n9\n8\n9\n26\n\n\nRED\n9\n9\n9\n27\n\n\n12382\nBLUE\n9\n9\n9\n27\n\n\nRED\n9\n9\n8\n26\n\n\n12383\nBLUE\n10\n10\n10\n30\n\n\nRED\n10\n10\n10\n30\n\n\n12392\nBLUE\n9\n9\n8\n26\n\n\nRED\n9\n8\n9\n26\n\n\n12398\nBLUE\n10\n9\n9\n28\n\n\nRED\n10\n10\n10\n30\n\n\n\n\n\n\n\n\n\n\nSingle observations\n\ntests_single = SkyNoiseDistributionCheck(n_processes=8)\ntests_single.run(folder=\"GA-CALIB\")\n\nLocating and converting where necessary: 100%|██████████| 36/36 [00:00&lt;00:00, 3385.99it/s]\nReading netCDF files... took 7.60 s. Size is 15887.744 Mb\nReading files: 100%|██████████| 36/36 [00:01&lt;00:00, 24.83it/s]\nCreating Dataset... took 0.13 s. Size is 14.210 Mb\nTests took 11.66 s to prepare (including reading data).\nTests took 20.10 s to perform.\nmean_non_zero:\n    Is the mean of the normalised flux in sky fibres significantly different from zero?\nstdev_non_unit:\n    Is the standard deviation of the normalised flux in sky fibres significantly different from unity?\nks_non_normal:\n    Does the distribution of normalised flux in sky fibres fail a KS test comparison with a standard Normal?\n\nCreating Dataset... took 0.12 s. Size is 14.210 Mb\nTests took 3.06 s to prepare (including reading data).\nTests took 9.67 s to perform.\nmean_non_zero:\n    Is the mean of the normalised flux in sky fibres significantly different from zero?\nstdev_non_unit:\n    Is the standard deviation of the normalised flux in sky fibres significantly different from unity?\nks_non_normal:\n    Does the distribution of normalised flux in sky fibres fail a KS test comparison with a standard Normal?\n\n\n\ntests_single.summary(by=\"RUN\")\n\n3 varieties of test and 342 tested elements per variety, for total of 1026 tests.\n998 tests failed (97.27%) and 28 tests passed (2.73%).\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\ntest\nks_non_normal\nmean_non_zero\nstdev_non_unit\n\n\n\nRUN\n\n\n\n\n\n\n\n\n3050615\n10\n10\n10\n30\n\n\n3050924\n10\n10\n10\n30\n\n\n3050925\n10\n10\n10\n30\n\n\n3050927\n10\n10\n10\n30\n\n\n3050928\n10\n10\n10\n30\n\n\n3050929\n10\n10\n10\n30\n\n\n3051172\n10\n10\n10\n30\n\n\n3051173\n10\n10\n10\n30\n\n\n3051174\n10\n10\n10\n30\n\n\n3051175\n10\n10\n10\n30\n\n\n3051176\n10\n10\n10\n30\n\n\n3051177\n10\n10\n10\n30\n\n\n3050611\n10\n9\n10\n29\n\n\n3050613\n10\n9\n10\n29\n\n\n3050616\n10\n9\n10\n29\n\n\n3050926\n10\n10\n9\n29\n\n\n3050612\n10\n9\n9\n28\n\n\n3050636\n9\n9\n9\n27\n\n\n3050637\n9\n9\n9\n27\n\n\n3050638\n9\n9\n9\n27\n\n\n3050641\n9\n9\n9\n27\n\n\n3051215\n9\n9\n9\n27\n\n\n3050614\n10\n7\n9\n26\n\n\n3050639\n9\n8\n9\n26\n\n\n3050640\n9\n8\n9\n26\n\n\n3050886\n9\n9\n8\n26\n\n\n3050887\n9\n8\n9\n26\n\n\n3050888\n9\n9\n8\n26\n\n\n3050889\n9\n8\n9\n26\n\n\n3050890\n9\n8\n9\n26\n\n\n3051210\n9\n9\n8\n26\n\n\n3051211\n9\n9\n8\n26\n\n\n3051212\n9\n8\n8\n25\n\n\n3051213\n9\n8\n8\n25\n\n\n3051214\n9\n8\n8\n25\n\n\n3050891\n9\n6\n9\n24",
    "crumbs": [
      "ga-calib",
      "Sky noise distribution check"
    ]
  },
  {
    "objectID": "ga-calib/sky_noise_distribution_check.html#detail",
    "href": "ga-calib/sky_noise_distribution_check.html#detail",
    "title": "Sky noise distribution check",
    "section": "Detail",
    "text": "Detail\nThere are systematic shifts, but there are also a substantial number of outliers on the measured mean and standard deviation of the sky. I suspect this is simply due to bad pixels, which require more robust statistics. However, should also be careful to ensure we identify places where the noise map is not accurate. Work to be done.\n\nStacked observations\n\ndask_cluster = Client(n_workers=8, threads_per_worker=1, memory_limit=\"2GiB\")\nwith dask_cluster as _:\n    stats_stack = tests_stack.stats.to_pandas()\nstats_stack = stats_stack.drop(columns=[\"RUN\", \"NSPEC\", \"filename\"]).dropna()\nstats_stack\n\n\n\n\n\n\n\n\n\n\nCAMERA\nMJD\nNIGHT\nOBID\nstdev_measured\nstdev_expected\nmean_zscore\nstdev_zscore\nerr_on_mean_zscore\nerr_on_stdev_zscore\nsig_mean_zscore\nsig_stdev_zscore\nks_prob\n\n\nRUN\nNSPEC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3050611\n97\nRED\n60384.87280\n20240315\n12398\n9.784142\n17.635326\n0.200687\n0.741577\n0.006200\n0.004384\n32.370790\n58.947347\n0.000000e+00\n\n\n193\nRED\n60384.87280\n20240315\n12398\n9.957287\n17.721449\n0.241912\n0.633261\n0.005294\n0.003744\n45.691306\n97.956419\n0.000000e+00\n\n\n375\nRED\n60384.87280\n20240315\n12398\n22.402952\n16.108976\n-0.758258\n0.813899\n0.006806\n0.004813\n111.415295\n38.670142\n0.000000e+00\n\n\n432\nRED\n60384.87280\n20240315\n12398\n10.245201\n18.929451\n0.127768\n0.670510\n0.005607\n0.003965\n22.787741\n83.103565\n1.618329e-287\n\n\n467\nRED\n60384.87280\n20240315\n12398\n11.391346\n17.731205\n-0.532087\n0.750421\n0.006276\n0.004438\n84.787263\n56.241242\n0.000000e+00\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3051211\n491\nBLUE\n60386.96006\n20240317\n12392\n29.135481\n19.476557\n2.419528\n1.351321\n0.014154\n0.010009\n170.942682\n35.100643\n0.000000e+00\n\n\n503\nBLUE\n60386.96006\n20240317\n12392\n112.048241\n20.322018\n-5.847955\n5.145679\n0.053900\n0.038115\n108.496524\n108.767379\n0.000000e+00\n\n\n711\nBLUE\n60386.96006\n20240317\n12392\n18.216553\n18.226244\n-0.288502\n0.980142\n0.010284\n0.007272\n28.052720\n2.730530\n4.886305e-105\n\n\n806\nBLUE\n60386.96006\n20240317\n12392\n441.106659\n20.856630\n-12.845191\n17.947260\n0.188491\n0.133291\n68.147554\n127.145279\n0.000000e+00\n\n\n913\nBLUE\n60386.96006\n20240317\n12392\n15.477137\n18.385750\n0.096679\n0.813556\n0.008554\n0.006049\n11.301803\n30.821575\n1.168551e-56\n\n\n\n\n114 rows × 13 columns\n\n\n\n\n\nplot_hist(stats_stack, mean_range=(-10, 10), stdev_range=(0.0, 5.0))\n\n\n\n\n\n\n\n\nThe mean flux in the sky-subtracted sky is significantly below zero, and the standard deviation of the sky is significantly below that expected from the errors. Both display a substantial number of outliers, which need investigating.\nLet’s break it down by OB. Note that the extreme outliers make selecting the bandwidth for these plots difficult.\n\nplot_dist(\n    stats_stack,\n    sigma_clip=5,\n    mean_range=(-10, 10),\n    stdev_range=(0.0, 5.0),\n    inner=\"stick\",\n)\n\n\n\n\n\n\n\n\n\n\nSingle observations\n\ndask_cluster = Client(n_workers=8, threads_per_worker=1, memory_limit=\"2GiB\")\nwith dask_cluster as _:\n    stats_single = tests_single.stats.to_pandas()\nstats_single = stats_single.drop(columns=[\"RUN\", \"NSPEC\", \"filename\"]).dropna()\nstats_single\n\n\n\n\n\n\n\n\n\n\nCAMERA\nMJD\nNIGHT\nOBID\nstdev_measured\nstdev_expected\nmean_zscore\nstdev_zscore\nerr_on_mean_zscore\nerr_on_stdev_zscore\nsig_mean_zscore\nsig_stdev_zscore\nks_prob\n\n\nRUN\nNSPEC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3050611\n97\nRED\n60384.87280\n20240315\n12398\n4.732673\n10.332288\n0.110196\n0.620430\n0.005187\n0.003668\n21.245287\n103.487723\n0.000000e+00\n\n\n193\nRED\n60384.87280\n20240315\n12398\n5.425674\n10.377344\n0.130211\n0.580347\n0.004852\n0.003431\n26.836056\n122.309783\n0.000000e+00\n\n\n375\nRED\n60384.87280\n20240315\n12398\n12.930606\n9.455182\n-0.464787\n0.838622\n0.007013\n0.004959\n66.273529\n32.540965\n0.000000e+00\n\n\n432\nRED\n60384.87280\n20240315\n12398\n5.644597\n11.092417\n0.069947\n0.593808\n0.004966\n0.003512\n14.084639\n115.666472\n0.000000e+00\n\n\n467\nRED\n60384.87280\n20240315\n12398\n6.891780\n10.386356\n-0.331541\n0.691167\n0.005781\n0.004088\n57.349730\n75.546990\n0.000000e+00\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3051215\n491\nBLUE\n60386.98835\n20240317\n12392\n11.595710\n11.406978\n1.408187\n0.957842\n0.010033\n0.007095\n140.360450\n5.942263\n0.000000e+00\n\n\n503\nBLUE\n60386.98835\n20240317\n12392\n35.203259\n11.851339\n-3.080350\n2.901796\n0.030396\n0.021494\n101.341605\n88.479513\n0.000000e+00\n\n\n711\nBLUE\n60386.98835\n20240317\n12392\n8.160785\n10.654712\n-0.127563\n0.806889\n0.008466\n0.005987\n15.067002\n32.255081\n1.155737e-88\n\n\n806\nBLUE\n60386.98835\n20240317\n12392\n139.362228\n12.133641\n-6.953392\n9.953850\n0.104540\n0.073925\n66.514065\n121.120491\n0.000000e+00\n\n\n913\nBLUE\n60386.98835\n20240317\n12392\n7.899908\n10.707053\n0.080167\n0.752101\n0.007908\n0.005592\n10.137305\n44.329564\n2.187225e-94\n\n\n\n\n342 rows × 13 columns\n\n\n\n\n\nplot_hist(stats_single, mean_range=(-10, 10), stdev_range=(0.0, 5.0))\n\n\n\n\n\n\n\n\n\nplot_dist(\n    stats_single,\n    sigma_clip=5,\n    mean_range=(-10, 10),\n    stdev_range=(0.0, 5.0),\n    inner=\"stick\",\n)\n\n\n\n\n\n\n\n\n\n\nCompare noise level in stacks and singles\n\nstack_over_single = (\n    stats_stack.set_index([\"OBID\", \"CAMERA\"])[[\"stdev_measured\", \"stdev_expected\"]]\n    / stats_single.set_index([\"OBID\", \"CAMERA\"])[[\"stdev_measured\", \"stdev_expected\"]]\n)\n\n\nstack_over_single = stack_over_single.dropna()\nstack_over_single\n\n\n\n\n\n\n\n\n\n\nstdev_measured\nstdev_expected\n\n\nOBID\nCAMERA\n\n\n\n\n\n\n12366\nBLUE\n2.043285\n1.709613\n\n\nBLUE\n2.935687\n1.682709\n\n\nBLUE\n2.904439\n1.607477\n\n\nBLUE\n2.325622\n1.476084\n\n\nBLUE\n3.100327\n1.667831\n\n\n...\n...\n...\n...\n\n\n12398\nRED\n0.870969\n1.555680\n\n\nRED\n1.817556\n1.819420\n\n\nRED\n1.600257\n1.708372\n\n\nRED\n1.642207\n1.764194\n\n\nRED\n1.413976\n1.758083\n\n\n\n\n3258 rows × 2 columns\n\n\n\n\n\nplot_stack_over_single(stack_over_single)\n\n\n\n\n\n\n\n\nThe noise increases by a factor of \\(\\sqrt{3}\\), as expected for stacks that are the sum of three single exposures. However, there is sign of an additional contribution to the measured noise in the red stacks.",
    "crumbs": [
      "ga-calib",
      "Sky noise distribution check"
    ]
  },
  {
    "objectID": "ga-calib/sky_noise_distribution_check.html#data-exploration",
    "href": "ga-calib/sky_noise_distribution_check.html#data-exploration",
    "title": "Sky noise distribution check",
    "section": "Data exploration",
    "text": "Data exploration\nHere we examine the data a bit more closely.\nFirst we define a function for visualising the spectra.\n\ndef plot(data, vmin=0, vmax=100, figsize=(15, 8), just_noss=False):\n    lamdim = [d for d in data.dims if d.startswith(\"LAMBDA\")][0]\n    data = data.transpose(..., lamdim)\n    wl = data[lamdim]\n    wlmin, wlmax, dwl = wl[0], wl[-1], wl[1] - wl[0]\n    extent = (wlmin - 0.5 * dwl, wlmax + 0.5 * dwl, data[\"FLUX\"].shape[0] + 0.5, +0.5)\n    nrow = 1 if just_noss else 3\n    fig, ax = plt.subplots(\n        nrow, 1, figsize=figsize, sharex=True, sharey=True, squeeze=False\n    )\n    ax = ax[:, 0]\n    ax[0].imshow(\n        data[\"FLUX_NOSS\"],\n        vmin=vmin,\n        vmax=vmax,\n        interpolation=\"none\",\n        aspect=\"auto\",\n        extent=extent,\n    )\n    ax[0].set_title(\"FLUX_NOSS\")\n    if not just_noss:\n        ax[1].imshow(\n            data[\"FLUX\"],\n            vmin=vmin,\n            vmax=vmax,\n            interpolation=\"none\",\n            aspect=\"auto\",\n            extent=extent,\n        )\n        ax[1].set_title(\"FLUX\")\n        ax[2].imshow(data[\"IVAR\"], interpolation=\"none\", aspect=\"auto\", extent=extent)\n        ax[2].set_title(\"IVAR\")\n    ax[-1].set_xlabel(r\"wavelength ($\\rm\\AA$)\")\n    plt.tight_layout()\n\nAlso define a function which stacks all provided spectra along a single dimension, for the RED and BLUE cameras separately (since they have different numbers of pixels in the wavelength dimension).\n\ndef stack_spec(\n    data,\n    persist=False,  # using persist=True makes interactive use faster for datasets that fit in memory\n):\n    def stack_camera_spec(data, camera, drop_no_targuse=False):\n        data = data.sel(RUN=data.CAMERA == camera)\n        drop_band = \"B\" if camera == \"RED\" else \"R\"\n        data = data.drop_dims(f\"LAMBDA_{drop_band}\")\n        data = data.rename_vars(\n            {n: n.replace(f\"{camera}_\", \"\") for n in data.variables}\n        )\n        data = data.stack({\"SPEC\": [\"RUN\", \"NSPEC\"]})\n        if persist:\n            data = data.persist()\n        data = data.dropna(\"SPEC\", how=\"all\")\n        if drop_no_targuse:\n            no_use = data.TARGUSE.str.strip() != b\"\"\n            data = data.sel(SPEC=no_use)\n        return data\n\n    return {camera: stack_camera_spec(data, camera) for camera in (\"RED\", \"BLUE\")}\n\nNow, lets look at all the spectra tagged as sky in the GA-CALIB data. We will focus on the RED camera for now.\n\nskyspec = stack_spec(tests_single.data)\n\n\nplot(skyspec[\"RED\"])\n\n\n\n\n\n\n\n\nClearly there are sources in some of these spectra. Is this contamination, or have I messed up identifying sky spectra?\nLet’s take a look at a single run and compare spectra with different TARGUSE codes. We need to get the data again as we had discarded non-sky spectra previously.\n\nfiles = get_weave_files(level=\"L1\", lowres=True, filetype=\"single\", folder=\"GA-CALIB\")\ndata = read_l1_data(files)\nfibre_table = read_fibre_table_nspec(files)\ndata = xr.merge((data, fibre_table))\ndata = data.swap_dims(filename=\"RUN\")\n\nLocating and converting where necessary: 100%|██████████| 36/36 [00:00&lt;00:00, 5036.35it/s]\nReading netCDF files... took 0.91 s. Size is 15887.744 Mb\nReading files: 100%|██████████| 36/36 [00:00&lt;00:00, 59.62it/s]\nCreating Dataset... took 0.13 s. Size is 14.210 Mb\n\n\nWe’ll start by looking at a run with a fairly well behaved sky noise distribution. RUN 3050611 is in OBID 12398.\n\nexample_run = 3050611\n\n\nspec_all = stack_spec(data.sel(RUN=slice(example_run, example_run + 1)))\nspec_all = spec_all[\"RED\"]\nspec_tar = spec_all.where(spec_all[\"TARGUSE\"] == b\"T\", drop=True)\nspec_cal = spec_all.where(spec_all[\"TARGUSE\"] == b\"C\", drop=True)\nspec_sky = spec_all.where(spec_all[\"TARGUSE\"] == b\"S\", drop=True)\n\nFirst plot all the spectra in the RUN and indicate their TARGUSE.\n\nplot(spec_all, vmax=1000, figsize=(15, 15), just_noss=True)\nfor ax in plt.gcf().axes:\n    nspec_tar = spec_tar.NSPEC\n    ax.plot([7640] * len(nspec_tar), nspec_tar, \"_\", markersize=15, color=\"red\")\n    nspec_cal = spec_cal.NSPEC\n    ax.plot([7640] * len(nspec_cal), nspec_cal, \"_\", markersize=15, color=\"pink\")\n    nspec_sky = spec_sky.NSPEC\n    ax.plot([7640] * len(nspec_sky), nspec_sky, \"_\", markersize=15, color=\"cyan\")\n\n\n\n\n\n\n\n\n\nplot(spec_tar, vmax=10000, figsize=(15, 5), just_noss=True)\n\n\n\n\n\n\n\n\n\nplot(spec_cal, vmax=100, figsize=(15, 2), just_noss=True)\n\n\n\n\n\n\n\n\n\nplot(spec_sky, vmax=100, figsize=(15, 2), just_noss=True)\n\n\n\n\n\n\n\n\nThe sky spectra look pretty clean for that RUN. Now let’s try another. RUN 3050886 is in OBID 12367.\n\nexample_run = 3050886\n\n\nspec_all = stack_spec(data.sel(RUN=slice(example_run, example_run + 1)))\nspec_all = spec_all[\"RED\"]\nspec_tar = spec_all.where(spec_all[\"TARGUSE\"] == b\"T\", drop=True)\nspec_cal = spec_all.where(spec_all[\"TARGUSE\"] == b\"C\", drop=True)\nspec_sky = spec_all.where(spec_all[\"TARGUSE\"] == b\"S\", drop=True)\n\nFirst plot all the spectra in the RUN and indicate their TARGUSE.\n\nplot(spec_all, vmax=1000, figsize=(15, 15), just_noss=True)\nfor ax in plt.gcf().axes:\n    nspec_tar = spec_tar.NSPEC\n    ax.plot([7640] * len(nspec_tar), nspec_tar, \"_\", markersize=15, color=\"firebrick\")\n    nspec_cal = spec_cal.NSPEC\n    ax.plot([7640] * len(nspec_cal), nspec_cal, \"_\", markersize=15, color=\"pink\")\n    nspec_sky = spec_sky.NSPEC\n    ax.plot([7640] * len(nspec_sky), nspec_sky, \"_\", markersize=15, color=\"cyan\")\n\n\n\n\n\n\n\n\n\nplot(spec_tar, vmax=10000, figsize=(15, 5), just_noss=True)\n\n\n\n\n\n\n\n\n\nplot(spec_cal, vmax=100, figsize=(15, 2), just_noss=True)\n\n\n\n\n\n\n\n\n\nplot(spec_sky, vmax=100, figsize=(15, 2), just_noss=True)\n\n\n\n\n\n\n\n\nThis time several of the sky spectra have contamination. The main difference betwen the two runs is that this one has sky spectra right next to target spectra on the CCD, suggesting that the contaimination is coming from neighbouring bright spectra.\nWe can try to examine the raw images to see if we see sign of signal contaminating neighbouring spectra.\n\nfiles = get_weave_files(level=\"raw\", lowres=True, folder=\"GA-CALIB\")\n\n\nraw_data = read_raw_data(files)\nraw_data = raw_data.swap_dims(filename=\"RUN\")\n\nLocating and converting where necessary: 100%|██████████| 36/36 [00:00&lt;00:00, 2242.61it/s]\nReading netCDF files... took 3.73 s. Size is 5336.749 Mb\n\n\n\nimg = raw_data.sel(RUN=3050886)[\"counts1\"]\n\nDisplay a corner of the image.\n\nplt.figure(figsize=(15, 15))\nplt.imshow(img[:1000, :3000], vmin=1510, vmax=1700)\n\n\n\n\n\n\n\n\nPlot a slice across the spectra roughly at the position of a sky line. It looks like the spectra are close enough for a bright neighbour to cause contamination.\n\nfig = plt.figure(figsize=(15, 5))\nplt.plot(img[250:750, 1476])\nplt.ylim(ymin=1500, ymax=10000)\nplt.yscale(\"log\")\n\n\n\n\n\n\n\n\nFor the purposes of the test, we could do with a way of rejecting contaminated sky spectra.",
    "crumbs": [
      "ga-calib",
      "Sky noise distribution check"
    ]
  },
  {
    "objectID": "utilities.html",
    "href": "utilities.html",
    "title": "utilities",
    "section": "",
    "text": "The header entry “OBSTEMP” encodes the requested observational constraints for the OB: the seeing, transparency, elevation, lunar angle and sky brightness. The OBSTEMP code consists of a letter for each constraint. This converts the codes to numerical values and adds airmass.\n\nsource\n\n\n\n parse_obstemp (codes:xarray.core.dataarray.DataArray)\n\nConvert an OBSTEMP code to a dictionary of constraint values.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ncodes\nDataArray\na DataArray of OBSTEMP codes\n\n\nReturns\ndict\nthe numerical value for each observing constraint",
    "crumbs": [
      "utilities"
    ]
  },
  {
    "objectID": "utilities.html#parsing-codes-in-the-fits-headers",
    "href": "utilities.html#parsing-codes-in-the-fits-headers",
    "title": "utilities",
    "section": "",
    "text": "The header entry “OBSTEMP” encodes the requested observational constraints for the OB: the seeing, transparency, elevation, lunar angle and sky brightness. The OBSTEMP code consists of a letter for each constraint. This converts the codes to numerical values and adds airmass.\n\nsource\n\n\n\n parse_obstemp (codes:xarray.core.dataarray.DataArray)\n\nConvert an OBSTEMP code to a dictionary of constraint values.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ncodes\nDataArray\na DataArray of OBSTEMP codes\n\n\nReturns\ndict\nthe numerical value for each observing constraint",
    "crumbs": [
      "utilities"
    ]
  },
  {
    "objectID": "utilities.html#parsing-line-names",
    "href": "utilities.html#parsing-line-names",
    "title": "utilities",
    "section": "Parsing line names",
    "text": "Parsing line names\nLine names in the galaxy table are a combination of the species and restframe wavelength, e.g. [OIII]_5006.77. This splits them and returns the species and wavelength separately.\n\nsource\n\nparse_line_names\n\n parse_line_names (lines:xarray.core.dataarray.DataArray)\n\nSplit the line names into species and restframe wavelength.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nlines\nDataArray\na DataArray of line names, e.g. [OIII]_5006.77\n\n\nReturns\ntuple\nthe species and wavelength of each line",
    "crumbs": [
      "utilities"
    ]
  },
  {
    "objectID": "utilities.html#statistics",
    "href": "utilities.html#statistics",
    "title": "utilities",
    "section": "Statistics",
    "text": "Statistics\n\nsource\n\nks_norm_prob\n\n ks_norm_prob (x:xarray.core.dataarray.DataArray, dim='SPEC', cdf=&lt;bound\n               method rv_continuous.cdf of\n               &lt;scipy.stats._continuous_distns.norm_gen object at\n               0x7f1a31383730&gt;&gt;)\n\nCalculate the KS probability that x are drawn from a standard Normal distribution.\nThe implementation is based on scipy.stats.ks_1samp and adapted to xarray for speed.\nThe input DataArray must be 2D, with one dimension to be kept (specified by dim) and the other for which the distribution of values will be tested. A multi-dimensional DataArray may be converted to 2D using DataArray.stack.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nx\nDataArray\n\na 2D array of values to test\n\n\ndim\nstr\nSPEC\nthe dimension of x to retain\n\n\ncdf\nmethod\ncdf\nthe cdf to compare against\n\n\nReturns\nDataArray",
    "crumbs": [
      "utilities"
    ]
  },
  {
    "objectID": "utilities.html#time",
    "href": "utilities.html#time",
    "title": "utilities",
    "section": "Time",
    "text": "Time\n\nsource\n\nmjd_to_night\n\n mjd_to_night (mjd:float|numpy.ndarray)\n\nReturn the date (YYYYMMDD) at the start of the night containing mjd.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nmjd\nfloat | numpy.ndarray\na Modified Julian Date\n\n\nReturns\nfloat | numpy.ndarray\nthe night in YYYYMMDD format\n\n\n\n\nassert mjd_to_night(57639.8653) == \"20160908\"\n\n\nassert mjd_to_night(57639.8653) == mjd_to_night(57640.1234)",
    "crumbs": [
      "utilities"
    ]
  },
  {
    "objectID": "utilities.html#magnitude-from-spectra",
    "href": "utilities.html#magnitude-from-spectra",
    "title": "utilities",
    "section": "Magnitude from spectra",
    "text": "Magnitude from spectra\n\nsource\n\nget_mags_from_spectra\n\n get_mags_from_spectra (wl:xarray.core.dataarray.DataArray,\n                        flam:xarray.core.dataarray.DataArray,\n                        band='GROUND_JOHNSON_V')\n\nCompute magnitudes from a DataArray of spectra.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nwl\nDataArray\n\nwavelengths, in Angstroms, at which all the spectra are sampled\n\n\nflam\nDataArray\n\nvalues of the spectra, in erg/s/cm^2/AA\n\n\nband\nstr\nGROUND_JOHNSON_V\nthe filter for which to determine the magnitude\n\n\nReturns\nDataArray",
    "crumbs": [
      "utilities"
    ]
  },
  {
    "objectID": "utilities.html#add-unique-exposure-id-coordinates",
    "href": "utilities.html#add-unique-exposure-id-coordinates",
    "title": "utilities",
    "section": "Add unique exposure ID coordinates",
    "text": "Add unique exposure ID coordinates\n\nsource\n\nadd_expid\n\n add_expid (ds:xarray.core.dataset.Dataset)\n\nAdd EXPID coord to a Dataset.\nThis is constructed by numbering filename/RUNs for each CAMERA in order of MJD and adding this to OBID * 100000000, to create a unique ID for each exposure (i.e. a pair of RUNs taken with each CAMERA).\n\n\n\n\nType\nDetails\n\n\n\n\nds\nDataset\nthe Dataset to which to add the EXPID coord\n\n\nReturns\nDataset",
    "crumbs": [
      "utilities"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "data",
    "section": "",
    "text": "The data module provides functions for locating and reading WEAVE data as xarray Datasets.",
    "crumbs": [
      "data"
    ]
  },
  {
    "objectID": "data.html#accessing-fits-tables-as-xarray-datasets-via-cached-netcdf-files",
    "href": "data.html#accessing-fits-tables-as-xarray-datasets-via-cached-netcdf-files",
    "title": "data",
    "section": "Accessing FITS tables as xarray Datasets via cached netCDF files",
    "text": "Accessing FITS tables as xarray Datasets via cached netCDF files\nThe approach of qagmire is to access WEAVE data stored on disk in FITS files on disk. To analyse this large, multi-dimensional dataset we utilize xarray, making use of its ability to use dask to perform computations in parallel in a memory efficient and scaleable manner. To make this work we need to write the data to disk in a suitable format: netCDF files, then load those files as an xarray.Dataset. This functionality is implemented in FITStoDataset, which is used to wrap simpler functions which focus on reading data from a single FITS file into a convenient Dataset. Reading the original FITS files, and caching them to NetCDF, is (by default) parallelised using multiprocessing. In general, the aim is for the resulting Datasets to preserve the structure in the FITS files. However, there are some cases where it is sensible to rearrange the data into a more convenient and/or efficient format.\nTo help with accessing the data, we define several “coordinates”. The fundamental one is filename. RUN is unique for each filename and, like OBID, CAMERA and MJD, is taken directly from the header, where available. NIGHT is the date, in YYYYMMDD format, at the start of the night in which the observation was taken.\n\nsource\n\nFITStoDataset\n\n FITStoDataset (cache=True, netcdf_store:str|None=None, progress=True,\n                update_cache=False, n_processes=8)\n\nAccess multiple FITS tables as an xarray Dataset, optionally via cached netCDF files.\nFor each FITS table or image we wish to read, we will write a read_*(fn) function which reads the table from the single provided filename fn and returns a Dataset. Wrapping such a function with an instance of this class adapts the function to take a list of FITS filenames and return a Dataset. If cache=True, the Dataset is lazily loaded data from a cache of netCDF files. The cache is stored in the netcdf_store folder defined when the instance is initialised.\nIf cache=True, when the wrapped function is initially run, it repeatedly calls single_via_netcdf to apply the original read_* function to each FITS filename and save each resulting Dataset as a netCDF file, then opens them together and returns a combined, distributed Dataset. If a previously converted file is found in the netcdf_store, then the original read_* function is skipped and the netCDF file loaded directly. This caching can vastly increase the speed of subsequent calls. If n_processes &gt; 1, which it is by default, then this reading and caching is performed in parallel using n_processes processes.\nAlthough instances of this class can be used as a decorator, doing so with n_processes &gt; 1 will lead to an exception due to pickling issues with multiprocessing. Instead they should be used to wrap functions, without replacing the original function name. For example,\nto_dataset = FITStoDataset()\n\ndef _class_spec_reader(fn):\n    ...\n\nread_class_spec = to_dataset(_class_spec_reader)\nIf a source FITS file is changed, the corresponding files in netcdf_store can simply be deleted and they will be recreated on the next call of the decorated read_* function.\nIf cache=False, then the data is always read from the specified FITS files, combined and returned as an in-memory Dataset. This may be faster when dealing with lots of small files.\nIf update_cache=False, then existing cache files are not read, but are recreated.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncache\nbool\nTrue\ncache the dataset to netCDF files\n\n\nnetcdf_store\nstr | None\nNone\nfolder in which to store the netCDF files\n\n\nprogress\nbool\nTrue\ndisplay a progress bar\n\n\nupdate_cache\nbool\nFalse\nread FITS files and recreate netCDF files, no effect if cache=False\n\n\nn_processes\nint\n8\nhow many subprocesses to use\n\n\n\n\n\nCreate the to_dataset and to_dataset_without_cache wrapping functions\nThese are used to wrap all the read_* functions defined below. The function to_dataset is an instance of FITStoDataset with all the default behaviour described above.\nFor datasets consisting of small amounts of data per FITS file, it appears to be more efficient to simply read from the FITS files every time. In such cases, we use to_dataset_without_cache, an instance of FITStoDataset with caching disabled.\nNote that both of must be used to wrap functions, with the result being assigned a different name to the original. They cannot be used as decorators, unless n_processes=1.\n\nto_dataset = FITStoDataset()\nto_dataset_without_cache = FITStoDataset(cache=False)\n\nExisting cache files will be used when using the qagmire.data module. However, if running this notebook, the following line means we always update the cache, such that the timings reflect the original reading and conversion process.\n\nto_dataset = FITStoDataset(update_cache=True)",
    "crumbs": [
      "data"
    ]
  },
  {
    "objectID": "data.html#locating-weave-fits-files",
    "href": "data.html#locating-weave-fits-files",
    "title": "data",
    "section": "Locating WEAVE FITS files",
    "text": "Locating WEAVE FITS files\nHere we define some functions to get lists of WEAVE FITS filenames.\n\nsource\n\nget_lr_l2_stack_files\n\n get_lr_l2_stack_files (date='*', runid='*', folder='weaveio')\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndate\nstr\n*\npattern to match to the date in format yyyymmdd\n\n\nrunid\nstr\n*\npattern to match to the runid\n\n\nfolder\nstr\nweaveio\nfolder within the data_path\n\n\n\n\nsource\n\n\nget_lr_l1_stack_files\n\n get_lr_l1_stack_files (date='*', runid='*', folder='weaveio')\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndate\nstr\n*\npattern to match to the date in format yyyymmdd\n\n\nrunid\nstr\n*\npattern to match to the runid\n\n\nfolder\nstr\nweaveio\nfolder within the data_path\n\n\n\n\nsource\n\n\nget_lr_l1_single_files\n\n get_lr_l1_single_files (date='*', runid='*', folder='weaveio')\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndate\nstr\n*\npattern to match to the date in format yyyymmdd\n\n\nrunid\nstr\n*\npattern to match to the runid\n\n\nfolder\nstr\nweaveio\nfolder within the data_path\n\n\n\n\nsource\n\n\nget_lr_raw_files\n\n get_lr_raw_files (date='*', runid='*', folder='weaveio')\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndate\nstr\n*\npattern to match to the date in format yyyymmdd\n\n\nrunid\nstr\n*\npattern to match to the runid\n\n\nfolder\nstr\nweaveio\nfolder within the data_path\n\n\n\n\nsource\n\n\nget_weave_files\n\n get_weave_files (level='*', filetype='*', date='*', runid='*',\n                  lowres=True, folder='weaveio')\n\nGet a list of matching WEAVE files.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlevel\nstr\n*\npattern to match to the file level, e.g. raw, L1, L2\n\n\nfiletype\nstr\n*\npattern to match to the file type, e.g. single, stack\n\n\ndate\nstr\n*\npattern to match to the date in format yyyymmdd\n\n\nrunid\nstr\n*\npattern to match to the runid\n\n\nlowres\nbool\nTrue\nselect low-res files, or high-res if False\n\n\nfolder\nstr\nweaveio\nfolder within the data_path",
    "crumbs": [
      "data"
    ]
  },
  {
    "objectID": "data.html#raw-files",
    "href": "data.html#raw-files",
    "title": "data",
    "section": "Raw files",
    "text": "Raw files\nThese contain the raw observations.\nWe will read some simulated files to show examples.\n\nlr_raw_files = get_lr_raw_files(date=\"2017*\")\nprint(len(lr_raw_files), \"low-res raw files\")\n\n120 low-res raw files\n\n\n\nraw_hdus = fits.open(lr_raw_files[0])\n\nWEAVE raw files contain six extensions:\n\nprint([hdu.name for hdu in raw_hdus])\n\n['PRIMARY', 'RED1_DATA', 'RED2_DATA', 'FIBTABLE', 'GUIDINFO', 'METINFO']\n\n\n\nPRIMARY\nThe PRIMARY extension contains only a header with lots of information about the observation.\n\nraw_hdus[\"PRIMARY\"].header[:15]\n\nSIMPLE  =                    T / conforms to FITS standard                      \nBITPIX  =                    8 / array data type                                \nNAXIS   =                    0 / number of array dimensions                     \nEXTEND  =                    T                                                  \nCOMMENT -------- Start of the CAMERA Packet -------                             \nRUN     =              1003313                                                  \nIRAFNAME= 'r1003313'           / redir r2840373.fit &gt; r1003313                  \nDETECTOR= 'WVRED   '           / Selected by inference                          \nCCDSPEED= 'SLOW    '                                                            \nCCDXBIN =                    1                                                  \nCCDYBIN =                    1                                                  \nCCDSUM  = '1 1     '                                                            \nCCDTEMP =    132.0555378866794 / Randomly generated                             \nCCDTEMP1=    124.5350077054515 / Randomly generated                             \nCCDTEMP2=    127.1948417375027 / Randomly generated                             \n\n\n\nraw_primary_header = read_primary_header(lr_raw_files)\n\nReading files:   0%|                                                                                                               | 0/120 [00:00&lt;?, ?it/s]Reading files:   2%|█▋                                                                                                     | 2/120 [00:00&lt;00:06, 18.91it/s]Reading files:   9%|█████████▎                                                                                            | 11/120 [00:00&lt;00:01, 59.64it/s]Reading files:  19%|███████████████████▌                                                                                  | 23/120 [00:00&lt;00:01, 86.42it/s]Reading files:  32%|███████████████████████████████▉                                                                     | 38/120 [00:00&lt;00:00, 108.16it/s]Reading files:  42%|██████████████████████████████████████████▉                                                          | 51/120 [00:00&lt;00:00, 111.96it/s]Reading files:  53%|█████████████████████████████████████████████████████▊                                               | 64/120 [00:00&lt;00:00, 117.83it/s]Reading files:  64%|████████████████████████████████████████████████████████████████▊                                    | 77/120 [00:00&lt;00:00, 114.52it/s]Reading files:  76%|████████████████████████████████████████████████████████████████████████████▌                        | 91/120 [00:00&lt;00:00, 119.89it/s]Reading files:  88%|████████████████████████████████████████████████████████████████████████████████████████▎           | 106/120 [00:00&lt;00:00, 128.31it/s]Reading files:  99%|████████████████████████████████████████████████████████████████████████████████████████████████████▏| 119/120 [00:01&lt;00:00, 99.60it/s]Reading files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 120/120 [00:01&lt;00:00, 104.08it/s]\nCreating Dataset... took 1.53 s. Size is 0.604 Mb\n\n\n\nprint(raw_primary_header)\n\n&lt;xarray.Dataset&gt; Size: 633kB\nDimensions:   (filename: 120)\nCoordinates:\n  * filename  (filename) object 960B 'r1003313' 'r1003314' ... 'r1004150'\n    RUN       (filename) int64 960B 1003313 1003314 1003317 ... 1004151 1004150\n    CAMERA    (filename) &lt;U4 2kB 'RED' 'BLUE' 'RED' ... 'BLUE' 'RED' 'BLUE'\n    OBID      (filename) int64 960B 3802 3802 3802 3802 ... 3936 3936 3936 3936\n    MJD       (filename) float64 960B 5.781e+04 5.781e+04 ... 5.803e+04\n    NIGHT     (filename) &lt;U8 4kB '20170224' '20170224' ... '20170930' '20170930'\nData variables: (12/410)\n    SIMPLE    (filename) bool 120B True True True True ... True True True True\n    BITPIX    (filename) int64 960B 8 8 8 8 8 8 8 8 8 8 ... 8 8 8 8 8 8 8 8 8 8\n    NAXIS     (filename) int64 960B 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0\n    EXTEND    (filename) bool 120B True True True True ... True True True True\n    IRAFNAME  (filename) &lt;U8 4kB 'r1003313' 'r1003314' ... 'r1004151' 'r1004150'\n    DETECTOR  (filename) &lt;U6 3kB 'WVRED' 'WVBLUE' 'WVRED' ... 'WVRED' 'WVBLUE'\n    ...        ...\n    CCNAME17  (filename) &lt;U1 480B '' '' '' '' '' '' '' ... '' '' '' '' '' '' ''\n    CCNAME18  (filename) &lt;U1 480B '' '' '' '' '' '' '' ... '' '' '' '' '' '' ''\n    CCNAME19  (filename) &lt;U1 480B '' '' '' '' '' '' '' ... '' '' '' '' '' '' ''\n    CCNAME20  (filename) &lt;U1 480B '' '' '' '' '' '' '' ... '' '' '' '' '' '' ''\n    CHECKSUM  (filename) &lt;U16 8kB '6Zki8Wkh6Wkh6Wkh' ... 'nXIAqWF5nWFAnWF5'\n    DATASUM   (filename) &lt;U10 5kB '         0' '         0' ... '         0'\n\n\n\n\nDATA\nThe RED1_DATA, RED2_DATA and BLUE1_DATA, BLUE2_DATA extensions contain raw imaging of the spectra.\n\nraw_data = read_raw_data(lr_raw_files)\n\nLocating and converting where necessary:   0%|                                                                                     | 0/120 [00:00&lt;?, ?it/s]Locating and converting where necessary:   1%|▋                                                                            | 1/120 [00:02&lt;04:36,  2.32s/it]Locating and converting where necessary:   4%|███▏                                                                         | 5/120 [00:02&lt;00:42,  2.70it/s]Locating and converting where necessary:   7%|█████▏                                                                       | 8/120 [00:03&lt;00:33,  3.39it/s]Locating and converting where necessary:   8%|██████▎                                                                     | 10/120 [00:04&lt;00:41,  2.66it/s]Locating and converting where necessary:  11%|████████▏                                                                   | 13/120 [00:04&lt;00:27,  3.94it/s]Locating and converting where necessary:  12%|█████████▌                                                                  | 15/120 [00:04&lt;00:25,  4.14it/s]Locating and converting where necessary:  13%|██████████▏                                                                 | 16/120 [00:05&lt;00:24,  4.29it/s]Locating and converting where necessary:  14%|██████████▊                                                                 | 17/120 [00:05&lt;00:26,  3.91it/s]Locating and converting where necessary:  15%|███████████▍                                                                | 18/120 [00:05&lt;00:30,  3.37it/s]Locating and converting where necessary:  16%|████████████                                                                | 19/120 [00:05&lt;00:26,  3.85it/s]Locating and converting where necessary:  18%|█████████████▎                                                              | 21/120 [00:06&lt;00:20,  4.79it/s]Locating and converting where necessary:  18%|█████████████▉                                                              | 22/120 [00:06&lt;00:18,  5.31it/s]Locating and converting where necessary:  19%|██████████████▌                                                             | 23/120 [00:06&lt;00:19,  4.90it/s]Locating and converting where necessary:  20%|███████████████▏                                                            | 24/120 [00:07&lt;00:29,  3.26it/s]Locating and converting where necessary:  22%|████████████████▍                                                           | 26/120 [00:07&lt;00:22,  4.12it/s]Locating and converting where necessary:  22%|█████████████████                                                           | 27/120 [00:07&lt;00:21,  4.24it/s]Locating and converting where necessary:  24%|██████████████████▎                                                         | 29/120 [00:08&lt;00:19,  4.70it/s]Locating and converting where necessary:  25%|███████████████████                                                         | 30/120 [00:08&lt;00:18,  4.93it/s]Locating and converting where necessary:  26%|███████████████████▋                                                        | 31/120 [00:08&lt;00:18,  4.92it/s]Locating and converting where necessary:  27%|████████████████████▎                                                       | 32/120 [00:08&lt;00:22,  3.93it/s]Locating and converting where necessary:  28%|█████████████████████▌                                                      | 34/120 [00:09&lt;00:21,  4.07it/s]Locating and converting where necessary:  30%|██████████████████████▊                                                     | 36/120 [00:09&lt;00:16,  5.20it/s]Locating and converting where necessary:  31%|███████████████████████▍                                                    | 37/120 [00:09&lt;00:19,  4.32it/s]Locating and converting where necessary:  32%|████████████████████████▋                                                   | 39/120 [00:10&lt;00:16,  4.98it/s]Locating and converting where necessary:  33%|█████████████████████████▎                                                  | 40/120 [00:10&lt;00:23,  3.45it/s]Locating and converting where necessary:  35%|██████████████████████████▌                                                 | 42/120 [00:11&lt;00:19,  4.07it/s]Locating and converting where necessary:  37%|███████████████████████████▊                                                | 44/120 [00:11&lt;00:13,  5.62it/s]Locating and converting where necessary:  38%|████████████████████████████▌                                               | 45/120 [00:11&lt;00:17,  4.35it/s]Locating and converting where necessary:  38%|█████████████████████████████▏                                              | 46/120 [00:11&lt;00:15,  4.88it/s]Locating and converting where necessary:  39%|█████████████████████████████▊                                              | 47/120 [00:11&lt;00:13,  5.31it/s]Locating and converting where necessary:  40%|██████████████████████████████▍                                             | 48/120 [00:12&lt;00:20,  3.59it/s]Locating and converting where necessary:  41%|███████████████████████████████                                             | 49/120 [00:13&lt;00:24,  2.88it/s]Locating and converting where necessary:  42%|███████████████████████████████▋                                            | 50/120 [00:13&lt;00:21,  3.33it/s]Locating and converting where necessary:  44%|█████████████████████████████████▌                                          | 53/120 [00:13&lt;00:12,  5.50it/s]Locating and converting where necessary:  45%|██████████████████████████████████▏                                         | 54/120 [00:13&lt;00:11,  5.63it/s]Locating and converting where necessary:  46%|██████████████████████████████████▊                                         | 55/120 [00:13&lt;00:11,  5.69it/s]Locating and converting where necessary:  47%|███████████████████████████████████▍                                        | 56/120 [00:14&lt;00:16,  4.00it/s]Locating and converting where necessary:  48%|████████████████████████████████████                                        | 57/120 [00:14&lt;00:20,  3.07it/s]Locating and converting where necessary:  48%|████████████████████████████████████▋                                       | 58/120 [00:14&lt;00:17,  3.60it/s]Locating and converting where necessary:  49%|█████████████████████████████████████▎                                      | 59/120 [00:15&lt;00:16,  3.59it/s]Locating and converting where necessary:  50%|██████████████████████████████████████                                      | 60/120 [00:15&lt;00:13,  4.35it/s]Locating and converting where necessary:  52%|███████████████████████████████████████▉                                    | 63/120 [00:15&lt;00:06,  8.14it/s]Locating and converting where necessary:  54%|█████████████████████████████████████████▏                                  | 65/120 [00:16&lt;00:15,  3.62it/s]Locating and converting where necessary:  55%|█████████████████████████████████████████▊                                  | 66/120 [00:16&lt;00:13,  4.09it/s]Locating and converting where necessary:  56%|██████████████████████████████████████████▍                                 | 67/120 [00:16&lt;00:13,  3.95it/s]Locating and converting where necessary:  57%|███████████████████████████████████████████▋                                | 69/120 [00:17&lt;00:09,  5.55it/s]Locating and converting where necessary:  60%|█████████████████████████████████████████████▌                              | 72/120 [00:17&lt;00:10,  4.58it/s]Locating and converting where necessary:  61%|██████████████████████████████████████████████▏                             | 73/120 [00:18&lt;00:14,  3.31it/s]Locating and converting where necessary:  62%|██████████████████████████████████████████████▊                             | 74/120 [00:18&lt;00:12,  3.75it/s]Locating and converting where necessary:  62%|███████████████████████████████████████████████▌                            | 75/120 [00:19&lt;00:12,  3.64it/s]Locating and converting where necessary:  65%|█████████████████████████████████████████████████▍                          | 78/120 [00:19&lt;00:06,  6.18it/s]Locating and converting where necessary:  67%|██████████████████████████████████████████████████▋                         | 80/120 [00:19&lt;00:07,  5.36it/s]Locating and converting where necessary:  68%|███████████████████████████████████████████████████▎                        | 81/120 [00:20&lt;00:10,  3.73it/s]Locating and converting where necessary:  68%|███████████████████████████████████████████████████▉                        | 82/120 [00:20&lt;00:10,  3.52it/s]Locating and converting where necessary:  69%|████████████████████████████████████████████████████▌                       | 83/120 [00:20&lt;00:09,  3.81it/s]Locating and converting where necessary:  72%|██████████████████████████████████████████████████████▍                     | 86/120 [00:21&lt;00:05,  5.89it/s]Locating and converting where necessary:  73%|███████████████████████████████████████████████████████▋                    | 88/120 [00:21&lt;00:07,  4.38it/s]Locating and converting where necessary:  75%|█████████████████████████████████████████████████████████                   | 90/120 [00:22&lt;00:08,  3.44it/s]Locating and converting where necessary:  76%|█████████████████████████████████████████████████████████▋                  | 91/120 [00:22&lt;00:07,  3.81it/s]Locating and converting where necessary:  77%|██████████████████████████████████████████████████████████▎                 | 92/120 [00:22&lt;00:06,  4.22it/s]Locating and converting where necessary:  78%|███████████████████████████████████████████████████████████▌                | 94/120 [00:23&lt;00:05,  4.53it/s]Locating and converting where necessary:  80%|████████████████████████████████████████████████████████████▊               | 96/120 [00:23&lt;00:05,  4.61it/s]Locating and converting where necessary:  81%|█████████████████████████████████████████████████████████████▍              | 97/120 [00:23&lt;00:04,  4.68it/s]Locating and converting where necessary:  82%|██████████████████████████████████████████████████████████████              | 98/120 [00:24&lt;00:06,  3.67it/s]Locating and converting where necessary:  82%|██████████████████████████████████████████████████████████████▋             | 99/120 [00:24&lt;00:04,  4.26it/s]Locating and converting where necessary:  85%|███████████████████████████████████████████████████████████████▊           | 102/120 [00:24&lt;00:03,  5.41it/s]Locating and converting where necessary:  86%|████████████████████████████████████████████████████████████████▍          | 103/120 [00:25&lt;00:03,  5.45it/s]Locating and converting where necessary:  87%|█████████████████████████████████████████████████████████████████          | 104/120 [00:25&lt;00:03,  4.16it/s]Locating and converting where necessary:  88%|█████████████████████████████████████████████████████████████████▋         | 105/120 [00:25&lt;00:03,  4.56it/s]Locating and converting where necessary:  88%|██████████████████████████████████████████████████████████████████▎        | 106/120 [00:26&lt;00:03,  3.66it/s]Locating and converting where necessary:  89%|██████████████████████████████████████████████████████████████████▉        | 107/120 [00:26&lt;00:03,  4.14it/s]Locating and converting where necessary:  91%|████████████████████████████████████████████████████████████████████▏      | 109/120 [00:26&lt;00:01,  6.07it/s]Locating and converting where necessary:  92%|████████████████████████████████████████████████████████████████████▊      | 110/120 [00:26&lt;00:02,  4.93it/s]Locating and converting where necessary:  92%|█████████████████████████████████████████████████████████████████████▍     | 111/120 [00:26&lt;00:01,  5.22it/s]Locating and converting where necessary:  93%|██████████████████████████████████████████████████████████████████████     | 112/120 [00:27&lt;00:01,  4.13it/s]Locating and converting where necessary:  94%|██████████████████████████████████████████████████████████████████████▋    | 113/120 [00:27&lt;00:01,  4.85it/s]Locating and converting where necessary:  95%|███████████████████████████████████████████████████████████████████████▎   | 114/120 [00:27&lt;00:01,  4.01it/s]Locating and converting where necessary:  96%|███████████████████████████████████████████████████████████████████████▉   | 115/120 [00:28&lt;00:01,  3.58it/s]Locating and converting where necessary:  98%|█████████████████████████████████████████████████████████████████████████▊ | 118/120 [00:28&lt;00:00,  4.25it/s]Locating and converting where necessary:  99%|██████████████████████████████████████████████████████████████████████████▍| 119/120 [00:29&lt;00:00,  3.52it/s]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████| 120/120 [00:30&lt;00:00,  2.11it/s]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████| 120/120 [00:30&lt;00:00,  3.97it/s]\nReading netCDF files... took 3.42 s. Size is 17888.977 Mb\n\n\n\nprint(raw_data)\n\n&lt;xarray.Dataset&gt; Size: 19GB\nDimensions:   (filename: 120, dim_0: 6160, dim_1: 6344)\nCoordinates:\n  * filename  (filename) &lt;U8 4kB 'r1003314' 'r1003319' ... 'r1004152' 'r1004151'\n    RUN       (filename) int64 960B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n    CAMERA    (filename) &lt;U4 2kB dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n    MJD       (filename) float64 960B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n    NIGHT     (filename) &lt;U8 4kB dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n    OBID      (filename) int64 960B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nDimensions without coordinates: dim_0, dim_1\nData variables:\n    counts1   (filename, dim_0, dim_1) uint16 9GB dask.array&lt;chunksize=(1, 6160, 6344), meta=np.ndarray&gt;\n    counts2   (filename, dim_0, dim_1) uint16 9GB dask.array&lt;chunksize=(1, 6160, 6344), meta=np.ndarray&gt;\n\n\nIt is a good idea to close a Dataset when you are finished with it, as otherwise other processes may not be able to access the same underlying files.\n\nraw_data.close()\n\n\n\nFIBTABLE\nThe FIBTABLE extension contains information about the fibre allocations.\nCode is included to display example content of FITS tables, but commented out as it does not display well online.\n\n# Table.read(raw_hdus[\"FIBTABLE\"])\n\n\nraw_fibre_table = read_fibre_table(lr_raw_files)\n\nReading files:   0%|                                                                                                               | 0/120 [00:00&lt;?, ?it/s]Reading files:   1%|▊                                                                                                      | 1/120 [00:00&lt;00:18,  6.53it/s]Reading files:   9%|█████████▎                                                                                            | 11/120 [00:00&lt;00:02, 51.12it/s]Reading files:  17%|█████████████████                                                                                     | 20/120 [00:00&lt;00:01, 66.77it/s]Reading files:  27%|███████████████████████████▏                                                                          | 32/120 [00:00&lt;00:01, 82.79it/s]Reading files:  34%|██████████████████████████████████▊                                                                   | 41/120 [00:00&lt;00:00, 83.31it/s]Reading files:  44%|█████████████████████████████████████████████                                                         | 53/120 [00:00&lt;00:00, 93.29it/s]Reading files:  52%|█████████████████████████████████████████████████████▌                                                | 63/120 [00:00&lt;00:00, 85.78it/s]Reading files:  61%|██████████████████████████████████████████████████████████████                                        | 73/120 [00:00&lt;00:00, 88.48it/s]Reading files:  69%|██████████████████████████████████████████████████████████████████████▌                               | 83/120 [00:01&lt;00:00, 89.89it/s]Reading files:  78%|███████████████████████████████████████████████████████████████████████████████                       | 93/120 [00:01&lt;00:00, 60.01it/s]Reading files:  86%|██████████████████████████████████████████████████████████████████████████████████████▋              | 103/120 [00:01&lt;00:00, 65.18it/s]Reading files:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████▍  | 117/120 [00:01&lt;00:00, 81.74it/s]Reading files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 120/120 [00:01&lt;00:00, 74.99it/s]\nCreating Dataset... took 0.74 s. Size is 22.621 Mb\n\n\n\nprint(raw_fibre_table)\n\n&lt;xarray.Dataset&gt; Size: 24MB\nDimensions:    (APS_ID: 1008, filename: 120)\nCoordinates:\n  * APS_ID     (APS_ID) int16 2kB 0 1 2 3 4 5 ... 1002 1003 1004 1005 1006 1007\n  * filename   (filename) object 960B 'r1003316' 'r1003318' ... 'r1004151'\n    RUN        (filename) int64 960B 1003316 1003318 1003313 ... 1004152 1004151\n    CAMERA     (filename) &lt;U4 2kB 'BLUE' 'BLUE' 'RED' ... 'BLUE' 'BLUE' 'RED'\n    MJD        (filename) float64 960B 5.781e+04 5.781e+04 ... 5.803e+04\n    NIGHT      (filename) &lt;U8 4kB '20170224' '20170224' ... '20170930'\n    OBID       (filename) int64 960B 3802 3802 3802 3802 ... 3936 3936 3936 3936\nData variables: (12/36)\n    CNAME      (filename, APS_ID) object 968kB nan nan nan nan ... nan nan nan\n    FIBRERA    (filename, APS_ID) float64 968kB nan nan nan nan ... nan nan nan\n    FIBREDEC   (filename, APS_ID) float64 968kB nan nan nan nan ... nan nan nan\n    XPOSITION  (filename, APS_ID) float32 484kB nan nan nan nan ... nan nan nan\n    YPOSITION  (filename, APS_ID) float32 484kB nan nan nan nan ... nan nan nan\n    STATUS     (filename, APS_ID) object 968kB nan nan nan nan ... nan nan nan\n    ...         ...\n    MAG_GG     (filename, APS_ID) float32 484kB nan nan nan nan ... nan nan nan\n    EMAG_GG    (filename, APS_ID) float32 484kB nan nan nan nan ... nan nan nan\n    MAG_BP     (filename, APS_ID) float32 484kB nan nan nan nan ... nan nan nan\n    EMAG_BP    (filename, APS_ID) float32 484kB nan nan nan nan ... nan nan nan\n    MAG_RP     (filename, APS_ID) float32 484kB nan nan nan nan ... nan nan nan\n    EMAG_RP    (filename, APS_ID) float32 484kB nan nan nan nan ... nan nan nan\n\n\n\n\nGUIDINFO\nThe GUIDINFO extension contains info about the guiding. Currently not sure of the best way to organise this data.\n\n# Table.read(raw_hdus[\"GUIDINFO\"])\n\n\n\nMETINFO\nThe METINFO extension contains meteographical information. Currently not sure of the best way to organise this data.\n\n# Table.read(raw_hdus[\"METINFO\"], unit_parse_strict=\"silent\")",
    "crumbs": [
      "data"
    ]
  },
  {
    "objectID": "data.html#l1-files",
    "href": "data.html#l1-files",
    "title": "data",
    "section": "L1 files",
    "text": "L1 files\nThese contain lower-level processed data products. There are single files, which contain info for a single exposure, and stack files, which contain the same info for stacked exposures.\nWe will read some simulated single files to show examples.\n\nlr_l1_single_files = get_lr_l1_single_files(date=\"2017*\")\nprint(len(lr_l1_single_files), \"low-res L1 single files\")\n\n60 low-res L1 single files\n\n\n\nl1_hdus = fits.open(lr_l1_single_files[0])\n\nWEAVE L1 single files contain seven extensions:\n\nprint([hdu.name for hdu in l1_hdus])\n\n['PRIMARY', 'RED_DATA', 'RED_IVAR', 'RED_DATA_NOSS', 'RED_IVAR_NOSS', 'RED_SENSFUNC', 'FIBTABLE']\n\n\n\nPRIMARY\nThe PRIMARY extension contains only a header with lots of information about the observation.\n\nl1_hdus[\"PRIMARY\"].header[:15]\n\nSIMPLE  =                    T / file does conform to FITS standard             \nBITPIX  =                    8 / number of bits per data pixel                  \nNAXIS   =                    0 / number of data axes                            \nEXTEND  =                    T / FITS dataset may contain extensions            \nCOMMENT   FITS (Flexible Image Transport System) format is defined in 'Astronomy\nCOMMENT   and Astrophysics', volume 376, page 359; bibcode: 2001A&A...376..359H \nCOMMENT -------- Start of the CAMERA Packet -------                             \nRUN     =              1003317                                                  \nIRAFNAME= 'r1003317'           / redir r2840376.fit &gt; r1003317                  \nDETECTOR= 'WVRED   '           / Selected by inference                          \nCCDSPEED= 'SLOW    '                                                            \nCCDXBIN =                    1                                                  \nCCDYBIN =                    1                                                  \nCCDSUM  = '1 1     '                                                            \nCCDTEMP =    180.2992022070757 / Randomly generated                             \n\n\n\nl1_primary_header = read_primary_header(lr_l1_single_files)\n\nReading files:   0%|                                                                                                                | 0/60 [00:00&lt;?, ?it/s]Reading files:   2%|█▋                                                                                                      | 1/60 [00:00&lt;00:07,  8.32it/s]Reading files:  18%|██████████████████▉                                                                                    | 11/60 [00:00&lt;00:00, 54.18it/s]Reading files:  42%|██████████████████████████████████████████▉                                                            | 25/60 [00:00&lt;00:00, 88.79it/s]Reading files:  58%|████████████████████████████████████████████████████████████                                           | 35/60 [00:00&lt;00:00, 54.47it/s]Reading files:  70%|████████████████████████████████████████████████████████████████████████                               | 42/60 [00:00&lt;00:00, 55.52it/s]Reading files:  93%|████████████████████████████████████████████████████████████████████████████████████████████████▏      | 56/60 [00:00&lt;00:00, 71.21it/s]Reading files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00&lt;00:00, 66.01it/s]\nCreating Dataset... took 1.04 s. Size is 0.379 Mb\n\n\n\nprint(l1_primary_header)\n\n&lt;xarray.Dataset&gt; Size: 397kB\nDimensions:   (filename: 60)\nCoordinates:\n  * filename  (filename) object 480B 'single_1003320' ... 'single_1004149'\n    RUN       (filename) int64 480B 1003320 1003318 1003317 ... 1004150 1004149\n    CAMERA    (filename) &lt;U4 960B 'BLUE' 'BLUE' 'RED' ... 'BLUE' 'BLUE' 'RED'\n    OBID      (filename) int64 480B 3802 3802 3802 3802 ... 3936 3936 3936 3936\n    MJD       (filename) float64 480B 5.781e+04 5.781e+04 ... 5.803e+04\n    NIGHT     (filename) &lt;U8 2kB '20170224' '20170224' ... '20170930' '20170930'\nData variables: (12/447)\n    SIMPLE    (filename) bool 60B True True True True ... True True True True\n    BITPIX    (filename) int64 480B 8 8 8 8 8 8 8 8 8 8 ... 8 8 8 8 8 8 8 8 8 8\n    NAXIS     (filename) int64 480B 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0\n    EXTEND    (filename) bool 60B True True True True ... True True True True\n    IRAFNAME  (filename) &lt;U8 2kB 'r1003320' 'r1003318' ... 'r1004150' 'r1004149'\n    DETECTOR  (filename) &lt;U6 1kB 'WVBLUE' 'WVBLUE' 'WVRED' ... 'WVBLUE' 'WVRED'\n    ...        ...\n    NCOMB     (filename) int64 480B 1 1 1 1 1 1 1 1 1 1 ... 1 1 1 1 1 1 1 1 1 1\n    PROV0000  (filename) &lt;U18 4kB 'single_1003320.fit' ... 'single_1004149.fit'\n    CHECKSUM  (filename) &lt;U16 4kB 'VEl6WDj6VDj6VDj6' ... 'cbhAeaZ6cafAcaZ3'\n    DATASUM   (filename) &lt;U1 240B '0' '0' '0' '0' '0' ... '0' '0' '0' '0' '0'\n    DELZPGRA  (filename) float64 480B 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n    CALDATE   (filename) int64 480B 20161225 20161225 ... 20161225 20161225\n\n\n\n\nDATA and SENSFUNC\nThe RED/BLUE_DATA, RED/BLUE_IVAR, RED/BLUE_DATA_NOSS, RED/BLUE_IVAR_NOSS and RED_BLUE_SENSFUNC extensions contain the reduced binned spectra and their inverse variance, with and without sky subtraction, plus the sensitivity function. Implementation TBD, but I think it makes sense for all of these to be stored in a single Dataset.\n\nl1_data = read_l1_data(lr_l1_single_files)\n\nLocating and converting where necessary:   0%|                                                                                      | 0/60 [00:00&lt;?, ?it/s]Locating and converting where necessary:   2%|█▎                                                                            | 1/60 [00:01&lt;01:36,  1.63s/it]Locating and converting where necessary:   3%|██▌                                                                           | 2/60 [00:01&lt;00:48,  1.20it/s]Locating and converting where necessary:  10%|███████▊                                                                      | 6/60 [00:02&lt;00:11,  4.63it/s]Locating and converting where necessary:  13%|██████████▍                                                                   | 8/60 [00:02&lt;00:10,  4.89it/s]Locating and converting where necessary:  17%|████████████▊                                                                | 10/60 [00:03&lt;00:15,  3.18it/s]Locating and converting where necessary:  18%|██████████████                                                               | 11/60 [00:03&lt;00:13,  3.56it/s]Locating and converting where necessary:  22%|████████████████▋                                                            | 13/60 [00:03&lt;00:10,  4.58it/s]Locating and converting where necessary:  25%|███████████████████▎                                                         | 15/60 [00:04&lt;00:09,  4.68it/s]Locating and converting where necessary:  28%|█████████████████████▊                                                       | 17/60 [00:05&lt;00:12,  3.56it/s]Locating and converting where necessary:  32%|████████████████████████▍                                                    | 19/60 [00:05&lt;00:09,  4.46it/s]Locating and converting where necessary:  33%|█████████████████████████▋                                                   | 20/60 [00:05&lt;00:10,  3.76it/s]Locating and converting where necessary:  35%|██████████████████████████▉                                                  | 21/60 [00:05&lt;00:09,  4.11it/s]Locating and converting where necessary:  40%|██████████████████████████████▊                                              | 24/60 [00:06&lt;00:06,  5.29it/s]Locating and converting where necessary:  43%|█████████████████████████████████▎                                           | 26/60 [00:07&lt;00:09,  3.71it/s]Locating and converting where necessary:  45%|██████████████████████████████████▋                                          | 27/60 [00:07&lt;00:07,  4.17it/s]Locating and converting where necessary:  48%|█████████████████████████████████████▏                                       | 29/60 [00:07&lt;00:08,  3.61it/s]Locating and converting where necessary:  52%|███████████████████████████████████████▊                                     | 31/60 [00:08&lt;00:06,  4.48it/s]Locating and converting where necessary:  57%|███████████████████████████████████████████▋                                 | 34/60 [00:08&lt;00:05,  4.38it/s]Locating and converting where necessary:  63%|████████████████████████████████████████████████▊                            | 38/60 [00:09&lt;00:03,  5.64it/s]Locating and converting where necessary:  67%|███████████████████████████████████████████████████▎                         | 40/60 [00:09&lt;00:03,  5.97it/s]Locating and converting where necessary:  68%|████████████████████████████████████████████████████▌                        | 41/60 [00:09&lt;00:03,  5.70it/s]Locating and converting where necessary:  70%|█████████████████████████████████████████████████████▉                       | 42/60 [00:10&lt;00:03,  5.65it/s]Locating and converting where necessary:  72%|███████████████████████████████████████████████████████▏                     | 43/60 [00:10&lt;00:03,  5.47it/s]Locating and converting where necessary:  77%|███████████████████████████████████████████████████████████                  | 46/60 [00:10&lt;00:01,  7.58it/s]Locating and converting where necessary:  80%|█████████████████████████████████████████████████████████████▌               | 48/60 [00:10&lt;00:01,  7.22it/s]Locating and converting where necessary:  83%|████████████████████████████████████████████████████████████████▏            | 50/60 [00:11&lt;00:01,  5.06it/s]Locating and converting where necessary:  87%|██████████████████████████████████████████████████████████████████▋          | 52/60 [00:11&lt;00:01,  6.22it/s]Locating and converting where necessary:  93%|███████████████████████████████████████████████████████████████████████▊     | 56/60 [00:12&lt;00:00,  6.97it/s]Locating and converting where necessary:  98%|███████████████████████████████████████████████████████████████████████████▋ | 59/60 [00:12&lt;00:00,  8.63it/s]Locating and converting where necessary: 100%|█████████████████████████████████████████████████████████████████████████████| 60/60 [00:14&lt;00:00,  4.22it/s]\nReading netCDF files... took 3.54 s. Size is 27397.910 Mb\n\n\n\nprint(l1_data)\n\n&lt;xarray.Dataset&gt; Size: 29GB\nDimensions:         (NSPEC: 960, LAMBDA_B: 9649, filename: 60, LAMBDA_R: 15289)\nCoordinates:\n  * NSPEC           (NSPEC) int64 8kB 1 2 3 4 5 6 7 ... 955 956 957 958 959 960\n  * LAMBDA_B        (LAMBDA_B) float64 77kB 3.676e+03 3.676e+03 ... 6.088e+03\n  * filename        (filename) &lt;U14 3kB 'single_1003330' ... 'single_1004121'\n    RUN             (filename) int64 480B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n    CAMERA          (filename) &lt;U4 960B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n    MJD             (filename) float64 480B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n    NIGHT           (filename) &lt;U8 2kB dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n    OBID            (filename) int64 480B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\n  * LAMBDA_R        (LAMBDA_R) float64 122kB 5.772e+03 5.772e+03 ... 9.594e+03\nData variables:\n    BLUE_FLUX       (filename, NSPEC, LAMBDA_B) float32 2GB dask.array&lt;chunksize=(1, 960, 9649), meta=np.ndarray&gt;\n    BLUE_IVAR       (filename, NSPEC, LAMBDA_B) float32 2GB dask.array&lt;chunksize=(1, 960, 9649), meta=np.ndarray&gt;\n    BLUE_FLUX_NOSS  (filename, NSPEC, LAMBDA_B) float32 2GB dask.array&lt;chunksize=(1, 960, 9649), meta=np.ndarray&gt;\n    BLUE_IVAR_NOSS  (filename, NSPEC, LAMBDA_B) float32 2GB dask.array&lt;chunksize=(1, 960, 9649), meta=np.ndarray&gt;\n    BLUE_SENSFUNC   (filename, NSPEC, LAMBDA_B) float32 2GB dask.array&lt;chunksize=(1, 960, 9649), meta=np.ndarray&gt;\n    RED_FLUX        (filename, NSPEC, LAMBDA_R) float32 4GB dask.array&lt;chunksize=(4, 960, 15289), meta=np.ndarray&gt;\n    RED_IVAR        (filename, NSPEC, LAMBDA_R) float32 4GB dask.array&lt;chunksize=(4, 960, 15289), meta=np.ndarray&gt;\n    RED_FLUX_NOSS   (filename, NSPEC, LAMBDA_R) float32 4GB dask.array&lt;chunksize=(4, 960, 15289), meta=np.ndarray&gt;\n    RED_IVAR_NOSS   (filename, NSPEC, LAMBDA_R) float32 4GB dask.array&lt;chunksize=(4, 960, 15289), meta=np.ndarray&gt;\n    RED_SENSFUNC    (filename, NSPEC, LAMBDA_R) float32 4GB dask.array&lt;chunksize=(4, 960, 15289), meta=np.ndarray&gt;\n\n\nIt is a good idea to close a Dataset when you are finished with it, as otherwise other processes may not be able to access the same underlying files.\n\nl1_data.close()\n\n\n\nFIBTABLE\nThe FIBTABLE extension contains information about the fibre allocations, plus some basic measurements.\n\n# Table.read(l1_hdus[\"FIBTABLE\"])\n\n\nl1_fibre_table = read_fibre_table(lr_l1_single_files)\n\nReading files:   0%|                                                                                                                | 0/60 [00:00&lt;?, ?it/s]Reading files:   2%|█▋                                                                                                      | 1/60 [00:00&lt;00:13,  4.53it/s]Reading files:  15%|███████████████▌                                                                                        | 9/60 [00:00&lt;00:01, 30.88it/s]Reading files:  28%|█████████████████████████████▏                                                                         | 17/60 [00:00&lt;00:01, 37.79it/s]Reading files:  42%|██████████████████████████████████████████▉                                                            | 25/60 [00:00&lt;00:00, 46.30it/s]Reading files:  55%|████████████████████████████████████████████████████████▋                                              | 33/60 [00:00&lt;00:00, 52.62it/s]Reading files:  70%|████████████████████████████████████████████████████████████████████████                               | 42/60 [00:00&lt;00:00, 59.38it/s]Reading files:  83%|█████████████████████████████████████████████████████████████████████████████████████▊                 | 50/60 [00:00&lt;00:00, 63.31it/s]Reading files:  97%|███████████████████████████████████████████████████████████████████████████████████████████████████▌   | 58/60 [00:01&lt;00:00, 64.68it/s]Reading files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01&lt;00:00, 52.99it/s]\nCreating Dataset... took 0.51 s. Size is 18.850 Mb\n\n\n\nprint(l1_fibre_table)\n\n&lt;xarray.Dataset&gt; Size: 20MB\nDimensions:       (APS_ID: 1004, filename: 60)\nCoordinates:\n  * APS_ID        (APS_ID) int16 2kB 1 2 3 4 5 6 ... 1003 1004 1005 1006 1007\n  * filename      (filename) object 480B 'single_1003317' ... 'single_1004148'\n    RUN           (filename) int64 480B 1003317 1003330 ... 1004149 1004148\n    CAMERA        (filename) &lt;U4 960B 'RED' 'BLUE' 'RED' ... 'BLUE' 'RED' 'BLUE'\n    MJD           (filename) float64 480B 5.781e+04 5.781e+04 ... 5.803e+04\n    NIGHT         (filename) &lt;U8 2kB '20170224' '20170224' ... '20170930'\n    OBID          (filename) int64 480B 3802 3900 3900 3802 ... 3936 3936 3936\nData variables: (12/59)\n    NSPEC         (filename, APS_ID) float32 241kB nan nan nan ... nan nan nan\n    CNAME         (filename, APS_ID) object 482kB nan nan nan ... nan nan nan\n    FIBRERA       (filename, APS_ID) float64 482kB nan nan nan ... nan nan nan\n    FIBREDEC      (filename, APS_ID) float64 482kB nan nan nan ... nan nan nan\n    XPOSITION     (filename, APS_ID) float32 241kB nan nan nan ... nan nan nan\n    YPOSITION     (filename, APS_ID) float32 241kB nan nan nan ... nan nan nan\n    ...            ...\n    MEANFLUX_G    (filename, APS_ID) float32 241kB nan nan nan ... nan nan nan\n    MEANFLUX_R    (filename, APS_ID) float32 241kB nan nan nan ... nan nan nan\n    MEANFLUX_I    (filename, APS_ID) float32 241kB nan nan nan ... nan nan nan\n    MEANFLUX_GG   (filename, APS_ID) float32 241kB nan nan nan ... nan nan nan\n    MEANFLUX_BP   (filename, APS_ID) float32 241kB nan nan nan ... nan nan nan\n    MEANFLUX_RP   (filename, APS_ID) float32 241kB nan nan nan ... nan nan nan\n\n\n\nl1_fibre_table_nspec = read_fibre_table_nspec(lr_l1_single_files)\n\nReading files:   0%|                                                                                                                | 0/60 [00:00&lt;?, ?it/s]Reading files:   2%|█▋                                                                                                      | 1/60 [00:00&lt;00:10,  5.79it/s]Reading files:   5%|█████▏                                                                                                  | 3/60 [00:00&lt;00:06,  9.38it/s]Reading files:  17%|█████████████████▏                                                                                     | 10/60 [00:00&lt;00:01, 29.46it/s]Reading files:  28%|█████████████████████████████▏                                                                         | 17/60 [00:00&lt;00:01, 42.26it/s]Reading files:  43%|████████████████████████████████████████████▋                                                          | 26/60 [00:00&lt;00:00, 57.15it/s]Reading files:  58%|████████████████████████████████████████████████████████████                                           | 35/60 [00:00&lt;00:00, 66.21it/s]Reading files:  72%|█████████████████████████████████████████████████████████████████████████▊                             | 43/60 [00:00&lt;00:00, 70.29it/s]Reading files:  85%|███████████████████████████████████████████████████████████████████████████████████████▌               | 51/60 [00:01&lt;00:00, 56.87it/s]Reading files:  97%|███████████████████████████████████████████████████████████████████████████████████████████████████▌   | 58/60 [00:01&lt;00:00, 55.20it/s]Reading files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01&lt;00:00, 50.71it/s]\nCreating Dataset... took 0.47 s. Size is 18.024 Mb\n\n\n\nprint(l1_fibre_table_nspec)\n\n&lt;xarray.Dataset&gt; Size: 19MB\nDimensions:       (NSPEC: 960, filename: 60)\nCoordinates:\n  * NSPEC         (NSPEC) int16 2kB 1 2 3 4 5 6 7 ... 955 956 957 958 959 960\n  * filename      (filename) object 480B 'single_1003330' ... 'single_1004150'\n    RUN           (filename) int64 480B 1003330 1003329 ... 1004146 1004150\n    CAMERA        (filename) &lt;U4 960B 'BLUE' 'RED' 'RED' ... 'BLUE' 'BLUE'\n    MJD           (filename) float64 480B 5.781e+04 5.781e+04 ... 5.803e+04\n    NIGHT         (filename) &lt;U8 2kB '20170224' '20170224' ... '20170930'\n    OBID          (filename) int64 480B 3900 3900 3802 3802 ... 3936 3936 3936\nData variables: (12/59)\n    CNAME         (filename, NSPEC) object 461kB b'WVE_10502409+5829229' ... nan\n    FIBRERA       (filename, NSPEC) float64 461kB 162.6 162.6 162.4 ... nan nan\n    FIBREDEC      (filename, NSPEC) float64 461kB 58.49 58.62 58.6 ... nan nan\n    XPOSITION     (filename, NSPEC) float32 230kB 10.87 10.85 -8.676 ... nan nan\n    YPOSITION     (filename, NSPEC) float32 230kB 161.6 189.6 185.4 ... nan nan\n    STATUS        (filename, NSPEC) object 461kB b'A' b'A' b'A' ... nan nan nan\n    ...            ...\n    MEANFLUX_R    (filename, NSPEC) float32 230kB -0.05591 1.852 ... nan nan\n    MEANFLUX_I    (filename, NSPEC) float32 230kB nan nan nan ... nan nan nan\n    MEANFLUX_GG   (filename, NSPEC) float32 230kB -0.03694 2.017 ... nan nan\n    MEANFLUX_BP   (filename, NSPEC) float32 230kB -0.03693 2.017 ... nan nan\n    MEANFLUX_RP   (filename, NSPEC) float32 230kB nan nan nan ... nan nan nan\n    APS_ID        (filename, NSPEC) float32 230kB 1.007e+03 1.006e+03 ... nan",
    "crumbs": [
      "data"
    ]
  },
  {
    "objectID": "data.html#l2-files",
    "href": "data.html#l2-files",
    "title": "data",
    "section": "L2 files",
    "text": "L2 files\nThese contain higher-level processed data products. There are single files, which contain meaurements on a single exposure, and stack files, which contain the same measurements on stacked exposures.\nWe will read some simulated stack files to show examples.\n\nlr_l2_stack_files = get_lr_l2_stack_files(date=\"2017*\")\nprint(len(lr_l2_stack_files), \"low-res L2 stack files\")\n\n6 low-res L2 stack files\n\n\n\nl2_hdus = fits.open(lr_l2_stack_files[0])\n\nWEAVE L2 stack files contain six extensions:\n\nprint([hdu.name for hdu in l2_hdus])\n\n['PRIMARY', 'CLASS_TABLE', 'STAR_TABLE', 'GALAXY_TABLE', 'CLASS_SPEC', 'STAR_SPEC', 'GALAXY_SPEC']\n\n\n\nPRIMARY\nThe PRIMARY extension contains only a header with some basic information.\n\nl2_hdus[\"PRIMARY\"].header\n\nSIMPLE  =                    T / conforms to FITS standard                      \nBITPIX  =                    8 / array data type                                \nNAXIS   =                    0 / number of array dimensions                     \nEXTEND  =                    T                                                  \nL1_REF_0= 'stack_1003318.fit'  / L1 reference file                              \nL1_REF_1= 'stack_1003317.fit'  / L1 reference file                              \nL1_REF_2= '' / L1 reference file                                                \nDATE-OBS= '20170224'           / L1: OBS-DATE                                   \nOBSMODE = 'MOS     '           / L1: OBSMODE                                    \nRES-OBS = 'LR      '           / L2: RES-DATE                                   \nOBID    = '3802    '           / L1: OBID                                       \nCHECKSUM= '97WQA7WO97WOA7WO'   / HDU checksum updated 2022-02-08T02:11:32       \nDATASUM = '0       '           / data unit checksum updated 2022-02-08T02:11:32 \n\n\n\nl2_primary_header = read_primary_header(lr_l2_stack_files)\n\nReading files:   0%|                                                                                                                 | 0/6 [00:00&lt;?, ?it/s]Reading files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00&lt;00:00, 108.00it/s]\nCreating Dataset... took 0.01 s. Size is 0.002 Mb\n\n\n\nprint(l2_primary_header)\n\n&lt;xarray.Dataset&gt; Size: 2kB\nDimensions:   (filename: 6)\nCoordinates:\n  * filename  (filename) object 48B 'stack_1003318__stack_1003317_APS' ... 's...\n    OBID      (filename) &lt;U4 96B '3802' '3900' '3803' '3653' '3806' '3756'\nData variables:\n    SIMPLE    (filename) bool 6B True True True True True True\n    BITPIX    (filename) int64 48B 8 8 8 8 8 8\n    NAXIS     (filename) int64 48B 0 0 0 0 0 0\n    EXTEND    (filename) bool 6B True True True True True True\n    L1_REF_0  (filename) &lt;U17 408B 'stack_1003318.fit' ... 'stack_1003438.fit'\n    L1_REF_1  (filename) &lt;U17 408B 'stack_1003317.fit' ... 'stack_1003437.fit'\n    L1_REF_2  (filename) &lt;U1 24B '' '' '' '' '' ''\n    DATE-OBS  (filename) &lt;U8 192B '20170224' '20170225' ... '20170227'\n    OBSMODE   (filename) &lt;U3 72B 'MOS' 'MOS' 'MOS' 'MOS' 'MOS' 'MOS'\n    RES-OBS   (filename) &lt;U2 48B 'LR' 'LR' 'LR' 'LR' 'LR' 'LR'\n    CHECKSUM  (filename) &lt;U16 384B '97WQA7WO97WOA7WO' ... '36TMA6RK46RKA6RK'\n    DATASUM   (filename) &lt;U1 24B '0' '0' '0' '0' '0' '0'\n\n\n\n\nCLASS_TABLE\nThe CLASS_TABLE extension contains information from matching various templates to the spectra. The redshift and class of the best fitting template are given, as well as the full cross-correlation results of each template as a function of redshift.\n\n# Table.read(l2_hdus[\"CLASS_TABLE\"]) # contains multidimensional columns, so not shown\n\n\nclass_table = read_class_table(lr_l2_stack_files)\n\nLocating and converting where necessary:   0%|                                                                                       | 0/6 [00:00&lt;?, ?it/s]Locating and converting where necessary:  17%|█████████████▏                                                                 | 1/6 [00:01&lt;00:05,  1.13s/it]Locating and converting where necessary:  50%|███████████████████████████████████████▌                                       | 3/6 [00:01&lt;00:01,  3.00it/s]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████████| 6/6 [00:01&lt;00:00,  4.42it/s]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████████| 6/6 [00:01&lt;00:00,  3.49it/s]\nReading netCDF files... took 1.19 s. Size is 178.858 Mb\n\n\n\nprint(class_table)\n\n&lt;xarray.Dataset&gt; Size: 188MB\nDimensions:           (APS_ID: 995, CZZ_GALAXY: 1446, CZZ_QSO: 1648,\n                       CZZ_STAR_A: 101, CZZ_STAR_B: 101, CZZ_STAR_CV: 101,\n                       CZZ_STAR_F: 101, CZZ_STAR_G: 101, CZZ_STAR_K: 101,\n                       CZZ_STAR_M: 101, CZZ_STAR_WD: 101, filename: 6,\n                       I_COEFF: 10)\nCoordinates: (12/13)\n  * APS_ID            (APS_ID) int64 8kB 1 2 3 4 5 ... 1003 1004 1005 1006 1007\n  * CZZ_GALAXY        (CZZ_GALAXY) float64 12kB -0.005 -0.004312 ... 1.698 1.7\n  * CZZ_QSO           (CZZ_QSO) float64 13kB 0.05 0.05121 ... 5.985 5.993\n  * CZZ_STAR_A        (CZZ_STAR_A) float64 808B -0.002 -0.00196 ... 0.002\n  * CZZ_STAR_B        (CZZ_STAR_B) float64 808B -0.002 -0.00196 ... 0.002\n  * CZZ_STAR_CV       (CZZ_STAR_CV) float64 808B -0.002 -0.00196 ... 0.002\n    ...                ...\n  * CZZ_STAR_G        (CZZ_STAR_G) float64 808B -0.002 -0.00196 ... 0.002\n  * CZZ_STAR_K        (CZZ_STAR_K) float64 808B -0.002 -0.00196 ... 0.002\n  * CZZ_STAR_M        (CZZ_STAR_M) float64 808B -0.002 -0.00196 ... 0.002\n  * CZZ_STAR_WD       (CZZ_STAR_WD) float64 808B -0.002 -0.00196 ... 0.002\n  * filename          (filename) &lt;U32 768B 'stack_1003330__stack_1003329_APS'...\n    OBID              (filename) &lt;U4 96B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nDimensions without coordinates: I_COEFF\nData variables: (12/25)\n    TARGID            (filename, APS_ID) object 48kB dask.array&lt;chunksize=(1, 995), meta=np.ndarray&gt;\n    CNAME             (filename, APS_ID) object 48kB dask.array&lt;chunksize=(1, 995), meta=np.ndarray&gt;\n    Z                 (filename, APS_ID) float64 48kB dask.array&lt;chunksize=(1, 995), meta=np.ndarray&gt;\n    ZERR              (filename, APS_ID) float64 48kB dask.array&lt;chunksize=(1, 995), meta=np.ndarray&gt;\n    ZWARN             (filename, APS_ID) float64 48kB dask.array&lt;chunksize=(1, 995), meta=np.ndarray&gt;\n    CLASS             (filename, APS_ID) object 48kB dask.array&lt;chunksize=(1, 995), meta=np.ndarray&gt;\n    ...                ...\n    CZZ_CHI2_STAR_CV  (filename, APS_ID, CZZ_STAR_CV) float64 5MB dask.array&lt;chunksize=(1, 995, 101), meta=np.ndarray&gt;\n    CZZ_CHI2_STAR_F   (filename, APS_ID, CZZ_STAR_F) float64 5MB dask.array&lt;chunksize=(1, 995, 101), meta=np.ndarray&gt;\n    CZZ_CHI2_STAR_G   (filename, APS_ID, CZZ_STAR_G) float64 5MB dask.array&lt;chunksize=(1, 995, 101), meta=np.ndarray&gt;\n    CZZ_CHI2_STAR_K   (filename, APS_ID, CZZ_STAR_K) float64 5MB dask.array&lt;chunksize=(1, 995, 101), meta=np.ndarray&gt;\n    CZZ_CHI2_STAR_M   (filename, APS_ID, CZZ_STAR_M) float64 5MB dask.array&lt;chunksize=(1, 995, 101), meta=np.ndarray&gt;\n    CZZ_CHI2_STAR_WD  (filename, APS_ID, CZZ_STAR_WD) float64 5MB dask.array&lt;chunksize=(1, 995, 101), meta=np.ndarray&gt;\n\n\n\nclass_table.close()\n\n\n\nSTAR_TABLE\nThe STAR_TABLE extension contains measurements of stellar parameters.\n\n# Table.read(l2_hdus[\"STAR_TABLE\"])  # contains multidimensional columns, so not shown\n\n\nstar_table = read_star_table(lr_l2_stack_files)\n\nLocating and converting where necessary:   0%|                                                                                       | 0/6 [00:00&lt;?, ?it/s]Locating and converting where necessary:  17%|█████████████▏                                                                 | 1/6 [00:00&lt;00:02,  2.32it/s]Locating and converting where necessary:  67%|████████████████████████████████████████████████████▋                          | 4/6 [00:00&lt;00:00,  8.56it/s]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████████| 6/6 [00:01&lt;00:00,  5.61it/s]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████████| 6/6 [00:01&lt;00:00,  5.56it/s]\nReading netCDF files... took 1.03 s. Size is 0.065 Mb\n\n\n\nprint(star_table)\n\n&lt;xarray.Dataset&gt; Size: 69kB\nDimensions:        (APS_ID: 24, I_COVAR: 5, J_COVAR: 5, filename: 6, I_ELEM: 2)\nCoordinates:\n  * APS_ID         (APS_ID) int64 192B 194 222 283 304 329 ... 922 946 948 992\n  * I_COVAR        (I_COVAR) &lt;U5 100B 'TEFF' 'LOGG' 'FEH' 'ALPHA' 'MICRO'\n  * J_COVAR        (J_COVAR) &lt;U5 100B 'TEFF' 'LOGG' 'FEH' 'ALPHA' 'MICRO'\n  * filename       (filename) &lt;U32 768B 'stack_1003354__stack_1003353_APS' .....\n    OBID           (filename) &lt;U4 96B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nDimensions without coordinates: I_ELEM\nData variables: (12/33)\n    TARGID         (filename, APS_ID) object 1kB dask.array&lt;chunksize=(1, 24), meta=np.ndarray&gt;\n    CNAME          (filename, APS_ID) object 1kB dask.array&lt;chunksize=(1, 24), meta=np.ndarray&gt;\n    VRAD           (filename, APS_ID) float64 1kB dask.array&lt;chunksize=(1, 24), meta=np.ndarray&gt;\n    VRAD_ERR       (filename, APS_ID) float64 1kB dask.array&lt;chunksize=(1, 24), meta=np.ndarray&gt;\n    SKEWNESS_RVS   (filename, APS_ID) float64 1kB dask.array&lt;chunksize=(1, 24), meta=np.ndarray&gt;\n    KURTOSIS_RVS   (filename, APS_ID) float64 1kB dask.array&lt;chunksize=(1, 24), meta=np.ndarray&gt;\n    ...             ...\n    COVAR          (filename, APS_ID, I_COVAR, J_COVAR) float64 29kB dask.array&lt;chunksize=(1, 24, 5, 5), meta=np.ndarray&gt;\n    ELEM           (filename, APS_ID, I_ELEM) float64 2kB dask.array&lt;chunksize=(1, 24, 2), meta=np.ndarray&gt;\n    ELEM_ERR       (filename, APS_ID, I_ELEM) float64 2kB dask.array&lt;chunksize=(1, 24, 2), meta=np.ndarray&gt;\n    SNR_FR         (filename, APS_ID) float64 1kB dask.array&lt;chunksize=(1, 24), meta=np.ndarray&gt;\n    CHISQ_TOT      (filename, APS_ID) float64 1kB dask.array&lt;chunksize=(1, 24), meta=np.ndarray&gt;\n    FLAG_FR        (filename, APS_ID) float64 1kB dask.array&lt;chunksize=(1, 24), meta=np.ndarray&gt;\n\n\n\nstar_table.close()\n\n\n\nGALAXY_TABLE\nThe GALAXY_TABLE extension contains measurements of galaxy parameters, including Hubble-flow corrected redshifts, stellar kinematics, line fits and indices.\n\n# Table.read(l2_hdus[\"GALAXY_TABLE\"], unit_parse_strict=\"silent\")  # contains multidimensional columns, so not shown\n\n\ngalaxy_table = read_galaxy_table(lr_l2_stack_files)\n\nLocating and converting where necessary:   0%|                                                                                       | 0/6 [00:00&lt;?, ?it/s]Locating and converting where necessary:  17%|█████████████▏                                                                 | 1/6 [00:01&lt;00:05,  1.03s/it]Locating and converting where necessary:  83%|█████████████████████████████████████████████████████████████████▊             | 5/6 [00:01&lt;00:00,  5.42it/s]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████████| 6/6 [00:01&lt;00:00,  4.88it/s]\nReading netCDF files... took 1.14 s. Size is 27.393 Mb\n\n\n\nprint(galaxy_table)\n\n&lt;xarray.Dataset&gt; Size: 29MB\nDimensions:         (APS_ID: 994, LINE: 22, QTY: 13, INDEX: 292, filename: 6)\nCoordinates:\n  * APS_ID          (APS_ID) int32 4kB 1 2 3 4 5 6 ... 1003 1004 1005 1006 1007\n  * LINE            (LINE) &lt;U15 1kB 'HeII_3203.15' ... '[ArIII]_7135.67'\n  * QTY             (QTY) &lt;U9 468B 'FLUX' 'AMPL' 'Z' ... 'ERR_EBMV0' 'ERR_EBMV1'\n  * INDEX           (INDEX) &lt;U16 19kB 'BL1719' 'ERR_BL1719' ... 'ERR_MgI2.28'\n  * filename        (filename) &lt;U32 768B 'stack_1003426__stack_1003425_APS' ....\n    OBID            (filename) &lt;U4 96B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nData variables: (12/26)\n    TARGID          (filename, APS_ID) object 48kB dask.array&lt;chunksize=(1, 994), meta=np.ndarray&gt;\n    CNAME           (filename, APS_ID) object 48kB dask.array&lt;chunksize=(1, 994), meta=np.ndarray&gt;\n    ZCORR           (filename, APS_ID) float64 48kB dask.array&lt;chunksize=(1, 994), meta=np.ndarray&gt;\n    V               (filename, APS_ID) float64 48kB dask.array&lt;chunksize=(1, 994), meta=np.ndarray&gt;\n    SIGMA           (filename, APS_ID) float64 48kB dask.array&lt;chunksize=(1, 994), meta=np.ndarray&gt;\n    H3              (filename, APS_ID) float64 48kB dask.array&lt;chunksize=(1, 994), meta=np.ndarray&gt;\n    ...              ...\n    FORM_ERR_H4     (filename, APS_ID) float64 48kB dask.array&lt;chunksize=(1, 994), meta=np.ndarray&gt;\n    FORM_ERR_H5     (filename, APS_ID) float64 48kB dask.array&lt;chunksize=(1, 994), meta=np.ndarray&gt;\n    FORM_ERR_H6     (filename, APS_ID) float64 48kB dask.array&lt;chunksize=(1, 994), meta=np.ndarray&gt;\n    FWHM_FLAG       (filename, APS_ID) float32 24kB dask.array&lt;chunksize=(1, 994), meta=np.ndarray&gt;\n    LINES           (filename, QTY, LINE, APS_ID) float64 14MB dask.array&lt;chunksize=(1, 13, 22, 994), meta=np.ndarray&gt;\n    INDICES         (filename, INDEX, APS_ID) float64 14MB dask.array&lt;chunksize=(1, 292, 994), meta=np.ndarray&gt;\n\n\n\ngalaxy_table.close()\n\n\n\nCLASS_SPEC\nThe CLASS_SPEC extension contains spectra and model fits, performed separately for the red and blue arms.\n\n# Table.read(l2_hdus[\"CLASS_SPEC\"], unit_parse_strict=\"silent\")  # contains multidimensional columns, so not shown\n\n\nclass_spec = read_class_spec(lr_l2_stack_files)\n\nLocating and converting where necessary:   0%|                                                                                       | 0/6 [00:00&lt;?, ?it/s]Locating and converting where necessary:  17%|█████████████▏                                                                 | 1/6 [00:02&lt;00:14,  2.97s/it]Locating and converting where necessary:  33%|██████████████████████████▎                                                    | 2/6 [00:03&lt;00:06,  1.64s/it]Locating and converting where necessary:  50%|███████████████████████████████████████▌                                       | 3/6 [00:04&lt;00:04,  1.48s/it]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████████| 6/6 [00:07&lt;00:00,  1.01s/it]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████████| 6/6 [00:07&lt;00:00,  1.21s/it]\nReading netCDF files... took 0.52 s. Size is 1703.853 Mb\n\n\n\nprint(class_spec)\n\n&lt;xarray.Dataset&gt; Size: 2GB\nDimensions:     (APS_ID: 995, LAMBDA_B: 9648, LAMBDA_R: 15288, filename: 6)\nCoordinates:\n  * APS_ID      (APS_ID) int64 8kB 1 2 3 4 5 6 ... 1002 1003 1004 1005 1006 1007\n  * LAMBDA_B    (LAMBDA_B) float32 39kB 3.677e+03 3.677e+03 ... 6.089e+03\n  * LAMBDA_R    (LAMBDA_R) float32 61kB 5.774e+03 5.774e+03 ... 9.596e+03\n  * filename    (filename) &lt;U32 768B 'stack_1003330__stack_1003329_APS' ... '...\n    OBID        (filename) &lt;U4 96B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nData variables:\n    TARGID      (filename, APS_ID) object 48kB dask.array&lt;chunksize=(1, 995), meta=np.ndarray&gt;\n    CNAME       (filename, APS_ID) object 48kB dask.array&lt;chunksize=(1, 995), meta=np.ndarray&gt;\n    FLUX_RR_B   (filename, APS_ID, LAMBDA_B) float32 230MB dask.array&lt;chunksize=(1, 995, 9648), meta=np.ndarray&gt;\n    IVAR_RR_B   (filename, APS_ID, LAMBDA_B) float32 230MB dask.array&lt;chunksize=(1, 995, 9648), meta=np.ndarray&gt;\n    MODEL_RR_B  (filename, APS_ID, LAMBDA_B) float32 230MB dask.array&lt;chunksize=(1, 995, 9648), meta=np.ndarray&gt;\n    FLUX_RR_R   (filename, APS_ID, LAMBDA_R) float32 365MB dask.array&lt;chunksize=(1, 995, 15288), meta=np.ndarray&gt;\n    IVAR_RR_R   (filename, APS_ID, LAMBDA_R) float32 365MB dask.array&lt;chunksize=(1, 995, 15288), meta=np.ndarray&gt;\n    MODEL_RR_R  (filename, APS_ID, LAMBDA_R) float32 365MB dask.array&lt;chunksize=(1, 995, 15288), meta=np.ndarray&gt;\n\n\n\nclass_spec.close()\n\n\n\nSTAR_SPEC\nThe STAR_SPEC extension contains spectra and model fits for stellar measurements.\n\n# Table.read(l2_hdus[\"STAR_SPEC\"], unit_parse_strict=\"silent\")\n\n\nstar_spec = read_star_spec(lr_l2_stack_files)\n\nLocating and converting where necessary:   0%|                                                                                       | 0/6 [00:00&lt;?, ?it/s]Locating and converting where necessary:  17%|█████████████▏                                                                 | 1/6 [00:00&lt;00:02,  1.87it/s]Locating and converting where necessary:  50%|███████████████████████████████████████▌                                       | 3/6 [00:00&lt;00:00,  4.95it/s]Locating and converting where necessary:  67%|████████████████████████████████████████████████████▋                          | 4/6 [00:00&lt;00:00,  4.47it/s]Locating and converting where necessary:  83%|█████████████████████████████████████████████████████████████████▊             | 5/6 [00:01&lt;00:00,  4.01it/s]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████████| 6/6 [00:03&lt;00:00,  1.04it/s]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████████| 6/6 [00:03&lt;00:00,  1.61it/s]\nReading netCDF files... took 0.74 s. Size is 106.808 Mb\n\n\n\nprint(star_spec)\n\n&lt;xarray.Dataset&gt; Size: 112MB\nDimensions:       (APS_ID: 24, filename: 6, LAMBIN_B: 9648, LAMBIN_R: 15288,\n                   LAMBIN_C: 23672)\nCoordinates:\n  * APS_ID        (APS_ID) int64 192B 194 222 283 304 329 ... 922 946 948 992\n  * filename      (filename) &lt;U32 768B 'stack_1003342__stack_1003341_APS' ......\n    OBID          (filename) &lt;U4 96B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nDimensions without coordinates: LAMBIN_B, LAMBIN_R, LAMBIN_C\nData variables: (12/14)\n    TARGID        (filename, APS_ID) object 1kB dask.array&lt;chunksize=(1, 24), meta=np.ndarray&gt;\n    CNAME         (filename, APS_ID) object 1kB dask.array&lt;chunksize=(1, 24), meta=np.ndarray&gt;\n    LAMBDA_RVS_B  (filename, APS_ID, LAMBIN_B) float32 6MB dask.array&lt;chunksize=(1, 24, 9648), meta=np.ndarray&gt;\n    FLUX_RVS_B    (filename, APS_ID, LAMBIN_B) float32 6MB dask.array&lt;chunksize=(1, 24, 9648), meta=np.ndarray&gt;\n    ERROR_RVS_B   (filename, APS_ID, LAMBIN_B) float32 6MB dask.array&lt;chunksize=(1, 24, 9648), meta=np.ndarray&gt;\n    MODEL_RVS_B   (filename, APS_ID, LAMBIN_B) float32 6MB dask.array&lt;chunksize=(1, 24, 9648), meta=np.ndarray&gt;\n    ...            ...\n    ERROR_RVS_R   (filename, APS_ID, LAMBIN_R) float32 9MB dask.array&lt;chunksize=(1, 24, 15288), meta=np.ndarray&gt;\n    MODEL_RVS_R   (filename, APS_ID, LAMBIN_R) float32 9MB dask.array&lt;chunksize=(1, 24, 15288), meta=np.ndarray&gt;\n    LAMBDA_FR_C   (filename, APS_ID, LAMBIN_C) float32 14MB dask.array&lt;chunksize=(1, 24, 23672), meta=np.ndarray&gt;\n    FLUX_FR_C     (filename, APS_ID, LAMBIN_C) float32 14MB dask.array&lt;chunksize=(1, 24, 23672), meta=np.ndarray&gt;\n    ERROR_FR_C    (filename, APS_ID, LAMBIN_C) float32 14MB dask.array&lt;chunksize=(1, 24, 23672), meta=np.ndarray&gt;\n    MODEL_FR_C    (filename, APS_ID, LAMBIN_C) float32 14MB dask.array&lt;chunksize=(1, 24, 23672), meta=np.ndarray&gt;\n\n\n\nstar_spec.close()\n\n\n\nGALAXY_SPEC\nThe GALAXY_SPEC extension contains log-wavelength-binned spectra and model fits by PPXF and GANDALF.\n\n# Table.read(l2_hdus[\"GALAXY_SPEC\"], unit_parse_strict=\"silent\")\n\n\ngalaxy_spec = read_galaxy_spec(lr_l2_stack_files)\n\nLocating and converting where necessary:   0%|                                                                                       | 0/6 [00:00&lt;?, ?it/s]Locating and converting where necessary:  17%|█████████████▏                                                                 | 1/6 [00:12&lt;01:04, 12.86s/it]Locating and converting where necessary:  33%|██████████████████████████▎                                                    | 2/6 [00:16&lt;00:28,  7.23s/it]Locating and converting where necessary:  50%|███████████████████████████████████████▌                                       | 3/6 [00:16&lt;00:12,  4.13s/it]Locating and converting where necessary:  67%|████████████████████████████████████████████████████▋                          | 4/6 [00:16&lt;00:05,  2.63s/it]Locating and converting where necessary:  83%|█████████████████████████████████████████████████████████████████▊             | 5/6 [00:17&lt;00:01,  1.84s/it]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████████| 6/6 [00:19&lt;00:00,  1.88s/it]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████████| 6/6 [00:19&lt;00:00,  3.22s/it]\nReading netCDF files... took 0.81 s. Size is 10232.270 Mb\n\n\n\nprint(galaxy_spec)\n\n&lt;xarray.Dataset&gt; Size: 11GB\nDimensions:           (APS_ID: 994, filename: 6, LOGLAMBIN: 23671)\nCoordinates:\n  * APS_ID            (APS_ID) int32 4kB 1 2 3 4 5 ... 1003 1004 1005 1006 1007\n  * filename          (filename) &lt;U32 768B 'stack_1003330__stack_1003329_APS'...\n    OBID              (filename) &lt;U4 96B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nDimensions without coordinates: LOGLAMBIN\nData variables: (12/15)\n    TARGID            (filename, APS_ID) object 48kB dask.array&lt;chunksize=(1, 994), meta=np.ndarray&gt;\n    CNAME             (filename, APS_ID) object 48kB dask.array&lt;chunksize=(1, 994), meta=np.ndarray&gt;\n    LOGLAM_PPXF       (filename, APS_ID, LOGLAMBIN) float32 565MB dask.array&lt;chunksize=(1, 994, 23671), meta=np.ndarray&gt;\n    FLUX_PPXF         (filename, APS_ID, LOGLAMBIN) float32 565MB dask.array&lt;chunksize=(1, 994, 23671), meta=np.ndarray&gt;\n    ERROR_PPXF        (filename, APS_ID, LOGLAMBIN) float32 565MB dask.array&lt;chunksize=(1, 994, 23671), meta=np.ndarray&gt;\n    MODEL_PPXF        (filename, APS_ID, LOGLAMBIN) float32 565MB dask.array&lt;chunksize=(1, 994, 23671), meta=np.ndarray&gt;\n    ...                ...\n    ERROR_GAND        (filename, APS_ID, LOGLAMBIN) float32 565MB dask.array&lt;chunksize=(1, 994, 23671), meta=np.ndarray&gt;\n    MODEL_GAND        (filename, APS_ID, LOGLAMBIN) float64 1GB dask.array&lt;chunksize=(1, 994, 23671), meta=np.ndarray&gt;\n    EMISSION_GAND     (filename, APS_ID, LOGLAMBIN) float64 1GB dask.array&lt;chunksize=(1, 994, 23671), meta=np.ndarray&gt;\n    FLUX_CLEAN_GAND   (filename, APS_ID, LOGLAMBIN) float64 1GB dask.array&lt;chunksize=(1, 994, 23671), meta=np.ndarray&gt;\n    MODEL_CLEAN_GAND  (filename, APS_ID, LOGLAMBIN) float64 1GB dask.array&lt;chunksize=(1, 994, 23671), meta=np.ndarray&gt;\n    GOODPIX_GAND      (filename, APS_ID, LOGLAMBIN) float64 1GB dask.array&lt;chunksize=(1, 994, 23671), meta=np.ndarray&gt;\n\n\n\ngalaxy_spec.close()",
    "crumbs": [
      "data"
    ]
  },
  {
    "objectID": "diagnostics/raw_spectrum_value_check.html",
    "href": "diagnostics/raw_spectrum_value_check.html",
    "title": "Raw spectrum value check",
    "section": "",
    "text": "To write checks of the data, we create a subclass of Diagnostics and implement the tests method.\nsource",
    "crumbs": [
      "diagnostics",
      "Raw spectrum value check"
    ]
  },
  {
    "objectID": "diagnostics/raw_spectrum_value_check.html#demonstration-tests",
    "href": "diagnostics/raw_spectrum_value_check.html#demonstration-tests",
    "title": "Raw spectrum value check",
    "section": "Demonstration tests",
    "text": "Demonstration tests\nHere we use multiple dask workers to speed up this test. We are checking 10 billion pixel values. On a single core, this takes ~110 seconds. With 8 workers, it takes ~22 seconds.\n\ntests = RawSpectrumValueCheck(n_processes=8)\ntests.run(date=\"201*\")\n\nLocating and converting where necessary:   0%|                                                                                     | 0/252 [00:00&lt;?, ?it/s]Locating and converting where necessary: 100%|█████████████████████████████████████████████████████████████████████████| 252/252 [00:00&lt;00:00, 6093.70it/s]\nReading netCDF files... took 6.40 s. Size is 37566.851 Mb\nTests took 10.47 s to prepare (including reading data).\nTests took 32.23 s to perform.\ntoo_many_sat_in_counts1:\n    Are there too many pixels saturated above the ADU threshold in counts1?\nneg_pixels_in_counts1:\n    Are there negative pixel values in counts1?\nnan_pixels_in_counts1:\n    Are there non-finite pixel values in counts1?\ntoo_many_sat_in_counts2:\n    Are there too many pixels saturated above the ADU threshold in counts2?\nneg_pixels_in_counts2:\n    Are there negative pixel values in counts2?\nnan_pixels_in_counts2:\n    Are there non-finite pixel values in counts2?\n\n\n\ntests.summary()\n\n6 varieties of test and 252 tested elements per variety, for total of 1512 tests.\n7 tests failed (0.46%) and 1505 tests passed (99.54%).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\n\n\n\n\n\ntest\ntoo_many_sat_in_counts1\ntoo_many_sat_in_counts2\n\n\n\nfilename\nRUN\nCAMERA\nMJD\nNIGHT\nOBID\n\n\n\n\n\n\n\nr1002213\n1002213\nRED\n57639.865255\n20160908\n3191\nTrue\nFalse\n1\n\n\nr1002215\n1002215\nRED\n57639.878449\n20160908\n3191\nTrue\nFalse\n1\n\n\nr1002217\n1002217\nRED\n57639.891644\n20160908\n3191\nTrue\nFalse\n1\n\n\nr1002219\n1002219\nRED\n57639.904838\n20160908\n3191\nFalse\nTrue\n1\n\n\nr1002243\n1002243\nRED\n57639.993993\n20160908\n3346\nFalse\nTrue\n1\n\n\nr1002307\n1002307\nRED\n57640.999641\n20160909\n3217\nFalse\nTrue\n1\n\n\nr1003335\n1003335\nRED\n57809.064769\n20170224\n3900\nFalse\nTrue\n1",
    "crumbs": [
      "diagnostics",
      "Raw spectrum value check"
    ]
  },
  {
    "objectID": "diagnostics/raw_spectrum_value_check.html#validation",
    "href": "diagnostics/raw_spectrum_value_check.html#validation",
    "title": "Raw spectrum value check",
    "section": "Validation",
    "text": "Validation\n\ndf = tests.stats.to_dataframe()\ndf = df.reset_index().set_index([c for c in tests.stats.coords])\ndf = df[df.sum(axis=\"columns\") &gt; 0]\ndf\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncounts1_sat\ncounts1_neg\ncounts1_nan\ncounts2_sat\ncounts2_neg\ncounts2_nan\n\n\nfilename\nRUN\nCAMERA\nMJD\nNIGHT\nOBID\n\n\n\n\n\n\n\n\n\n\nr1002217\n1002217\nRED\n57639.891644\n20160908\n3191\n4\n0\n0\n0\n0\n0\n\n\nr1002219\n1002219\nRED\n57639.904838\n20160908\n3191\n0\n0\n0\n1\n0\n0\n\n\nr1002213\n1002213\nRED\n57639.865255\n20160908\n3191\n1\n0\n0\n0\n0\n0\n\n\nr1002215\n1002215\nRED\n57639.878449\n20160908\n3191\n1\n0\n0\n0\n0\n0\n\n\nr1002243\n1002243\nRED\n57639.993993\n20160908\n3346\n0\n0\n0\n2\n0\n0\n\n\nr1002307\n1002307\nRED\n57640.999641\n20160909\n3217\n0\n0\n0\n1\n0\n0\n\n\nr1003335\n1003335\nRED\n57809.064769\n20170224\n3900\n0\n0\n0\n1\n0\n0",
    "crumbs": [
      "diagnostics",
      "Raw spectrum value check"
    ]
  },
  {
    "objectID": "diagnostics/measured_sky_check.html",
    "href": "diagnostics/measured_sky_check.html",
    "title": "Measured sky check",
    "section": "",
    "text": "To write checks of the data, we create a subclass of Diagnostics and implement the tests method.\nsource",
    "crumbs": [
      "diagnostics",
      "Measured sky check"
    ]
  },
  {
    "objectID": "diagnostics/measured_sky_check.html#demonstration-tests",
    "href": "diagnostics/measured_sky_check.html#demonstration-tests",
    "title": "Measured sky check",
    "section": "Demonstration tests",
    "text": "Demonstration tests\n\ntests = MeasuredSkyCheck(n_processes=1)\ntests.run(date=\"201*\")\n\nLocating and converting where necessary:   0%|                                                                                      | 0/34 [00:00&lt;?, ?it/s]Locating and converting where necessary: 100%|███████████████████████████████████████████████████████████████████████████| 34/34 [00:00&lt;00:00, 2960.42it/s]\nReading netCDF files... took 1.85 s. Size is 15525.568 Mb\nReading files:   0%|                                                                                                                | 0/34 [00:00&lt;?, ?it/s]Reading files:   3%|███                                                                                                     | 1/34 [00:00&lt;00:05,  6.01it/s]Reading files:  29%|██████████████████████████████▎                                                                        | 10/34 [00:00&lt;00:00, 44.20it/s]Reading files:  56%|█████████████████████████████████████████████████████████▌                                             | 19/34 [00:00&lt;00:00, 60.01it/s]Reading files:  79%|█████████████████████████████████████████████████████████████████████████████████▊                     | 27/34 [00:00&lt;00:00, 66.82it/s]Reading files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00&lt;00:00, 57.60it/s]\nCreating Dataset... took 0.28 s. Size is 10.214 Mb\nReading files:   0%|                                                                                                                | 0/34 [00:00&lt;?, ?it/s]Reading files:   3%|███                                                                                                     | 1/34 [00:00&lt;00:03,  9.10it/s]Reading files:  26%|███████████████████████████▌                                                                            | 9/34 [00:00&lt;00:00, 25.40it/s]Reading files:  47%|████████████████████████████████████████████████▍                                                      | 16/34 [00:00&lt;00:00, 25.54it/s]Reading files:  82%|████████████████████████████████████████████████████████████████████████████████████▊                  | 28/34 [00:00&lt;00:00, 45.67it/s]Reading files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00&lt;00:00, 41.60it/s]\nCreating Dataset... took 0.61 s. Size is 0.222 Mb\nTests took 5.36 s to prepare (including reading data).\nTests took 14.76 s to perform.\nsky_too_bright:\n    Does the measured sky brightness in the raw spectra satisfy the observational requirement?\nsky_too_variable:\n    Does the measured sky brightness vary substantially (&gt; 0.2 mag) between the sky fibres for each OB?\n\n\n\ntests.summary()\n\n2 varieties of test and 17 tested elements per variety, for total of 34 tests.\n12 tests failed (35.29%) and 22 tests passed (64.71%).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\n\n\n\n\n\ntest\nsky_too_bright\n\n\n\nOBID\nfilename\nRUN\nCAMERA\nMJD\nNIGHT\n\n\n\n\n\n\n3170\nstack_1002286\n1002286\nBLUE\n57640.911400\n20160909\nTrue\n1\n\n\n3175\nstack_1002334\n1002334\nBLUE\n57641.137905\n20160909\nTrue\n1\n\n\n3191\nstack_1002214\n1002214\nBLUE\n57639.865255\n20160908\nTrue\n1\n\n\n3217\nstack_1002310\n1002310\nBLUE\n57641.001725\n20160909\nTrue\n1\n\n\n3295\nstack_1002346\n1002346\nBLUE\n57641.183009\n20160909\nTrue\n1\n\n\n3346\nstack_1002238\n1002238\nBLUE\n57639.954410\n20160908\nTrue\n1\n\n\n3372\nstack_1002262\n1002262\nBLUE\n57640.180567\n20160908\nTrue\n1\n\n\n3380\nstack_1002322\n1002322\nBLUE\n57641.092604\n20160909\nTrue\n1\n\n\n3434\nstack_1002250\n1002250\nBLUE\n57639.999560\n20160908\nTrue\n1\n\n\n3653\nstack_1003354\n1003354\nBLUE\n57809.111794\n20170224\nTrue\n1\n\n\n3756\nstack_1003438\n1003438\nBLUE\n57811.080127\n20170226\nTrue\n1\n\n\n3900\nstack_1003330\n1003330\nBLUE\n57809.025185\n20170224\nTrue\n1",
    "crumbs": [
      "diagnostics",
      "Measured sky check"
    ]
  },
  {
    "objectID": "diagnostics/measured_sky_check.html#verification",
    "href": "diagnostics/measured_sky_check.html#verification",
    "title": "Measured sky check",
    "section": "Verification",
    "text": "Verification\nWe now do some spot checks to verify and expand upon the above test results. Note that we assigned self.stats inside tests. This provides a way of accessing the statistics used in the tests, without having to construct them again. However, we still need to recompute the statistics (or whatever is derived from the self.stats DataArray), which takes a little time.\n\ntests.stats.to_dataframe()[tests.stats.data_vars]\n\n\n\n\n\n\n\n\n\nmedian_sky\nsky_limit\nsigma_sky\n\n\nOBID\n\n\n\n\n\n\n\n3191\n20.603799\n21.0\n0.074585\n\n\n3133\n20.773965\n20.5\n0.004181\n\n\n3346\n20.820886\n21.0\n0.010860\n\n\n3434\n21.248163\n21.7\n0.005929\n\n\n3372\n21.114255\n21.5\n0.005882\n\n\n3170\n20.483335\n20.5\n0.003557\n\n\n3189\n20.549922\n20.5\n0.019661\n\n\n3217\n20.489997\n21.0\n0.012291\n\n\n3380\n21.393496\n21.7\n0.007065\n\n\n3175\n21.381906\n21.7\n0.005771\n\n\n3295\n21.220036\n21.5\n0.005482\n\n\n3802\n21.532988\n21.5\n0.007846\n\n\n3900\n21.368027\n21.5\n0.007033\n\n\n3803\n21.513620\n21.5\n0.007022\n\n\n3653\n21.340145\n21.5\n0.006760\n\n\n3806\n21.546429\n21.5\n0.007333\n\n\n3756\n21.368030\n21.5\n0.005959",
    "crumbs": [
      "diagnostics",
      "Measured sky check"
    ]
  },
  {
    "objectID": "diagnostics/line_flux_check.html",
    "href": "diagnostics/line_flux_check.html",
    "title": "Line flux existence check",
    "section": "",
    "text": "To write checks of the data, we create a subclass of Diagnostics and implement the tests method.\nsource",
    "crumbs": [
      "diagnostics",
      "Line flux existence check"
    ]
  },
  {
    "objectID": "diagnostics/line_flux_check.html#demonstration-tests",
    "href": "diagnostics/line_flux_check.html#demonstration-tests",
    "title": "Line flux existence check",
    "section": "Demonstration tests",
    "text": "Demonstration tests\n\ntests = LineFluxCheck()\ntests.run(date=\"201*\")\n\nLocating and converting where necessary:   0%|                                                                                      | 0/17 [00:00&lt;?, ?it/s]Locating and converting where necessary:   6%|████▌                                                                         | 1/17 [00:03&lt;01:01,  3.85s/it]Locating and converting where necessary:  12%|█████████▏                                                                    | 2/17 [00:04&lt;00:28,  1.89s/it]Locating and converting where necessary:  18%|█████████████▊                                                                | 3/17 [00:05&lt;00:20,  1.43s/it]Locating and converting where necessary:  24%|██████████████████▎                                                           | 4/17 [00:05&lt;00:13,  1.04s/it]Locating and converting where necessary:  71%|██████████████████████████████████████████████████████▎                      | 12/17 [00:05&lt;00:01,  4.80it/s]Locating and converting where necessary:  82%|███████████████████████████████████████████████████████████████▍             | 14/17 [00:06&lt;00:00,  4.60it/s]Locating and converting where necessary:  94%|████████████████████████████████████████████████████████████████████████▍    | 16/17 [00:08&lt;00:00,  2.15it/s]Locating and converting where necessary: 100%|█████████████████████████████████████████████████████████████████████████████| 17/17 [00:09&lt;00:00,  2.38it/s]Locating and converting where necessary: 100%|█████████████████████████████████████████████████████████████████████████████| 17/17 [00:09&lt;00:00,  1.89it/s]\nReading netCDF files... took 1.33 s. Size is 4851.652 Mb\nLocating and converting where necessary:   0%|                                                                                      | 0/17 [00:00&lt;?, ?it/s]Locating and converting where necessary:   6%|████▌                                                                         | 1/17 [00:00&lt;00:13,  1.17it/s]Locating and converting where necessary:  24%|██████████████████▎                                                           | 4/17 [00:01&lt;00:02,  4.83it/s]Locating and converting where necessary:  65%|█████████████████████████████████████████████████▊                           | 11/17 [00:01&lt;00:00, 11.45it/s]Locating and converting where necessary:  76%|██████████████████████████████████████████████████████████▉                  | 13/17 [00:01&lt;00:00, 11.78it/s]Locating and converting where necessary:  88%|███████████████████████████████████████████████████████████████████▉         | 15/17 [00:01&lt;00:00, 12.33it/s]Locating and converting where necessary: 100%|█████████████████████████████████████████████████████████████████████████████| 17/17 [00:01&lt;00:00, 10.04it/s]Locating and converting where necessary: 100%|█████████████████████████████████████████████████████████████████████████████| 17/17 [00:01&lt;00:00,  8.85it/s]\nReading netCDF files... took 2.83 s. Size is 77.962 Mb\nLocating and converting where necessary:   0%|                                                                                      | 0/17 [00:00&lt;?, ?it/s]Locating and converting where necessary:   6%|████▌                                                                         | 1/17 [00:00&lt;00:11,  1.43it/s]Locating and converting where necessary:  24%|██████████████████▎                                                           | 4/17 [00:01&lt;00:03,  4.31it/s]Locating and converting where necessary:  71%|██████████████████████████████████████████████████████▎                      | 12/17 [00:01&lt;00:00, 12.23it/s]Locating and converting where necessary:  82%|███████████████████████████████████████████████████████████████▍             | 14/17 [00:01&lt;00:00, 12.39it/s]Locating and converting where necessary:  94%|████████████████████████████████████████████████████████████████████████▍    | 16/17 [00:01&lt;00:00, 12.64it/s]Locating and converting where necessary: 100%|█████████████████████████████████████████████████████████████████████████████| 17/17 [00:01&lt;00:00,  9.64it/s]\nReading netCDF files... took 3.16 s. Size is 509.241 Mb\nTests took 21.74 s to prepare (including reading data).\nTests took 10.73 s to perform.\nline_in_null_spectrum:\n    Do non-null line fluxes appear in completely null spectra?\nline_in_blue_chip_gap:\n    Do non-null line fluxes appear in the blue chip gap?\nline_in_red_chip_gap:\n    Do non-null line fluxes appear in the red chip gap?\nline_off_spectrum:\n    Do non-null line fluxes appear outside the observed wavelength range?\nnull_line_on_spectrum:\n    Do null line fluxes appear in an observed wavelength range?\n\n\n\ntests.summary(by=\"OBID\", top=None, show_passed_tests=True)\n\n5 varieties of test and 374000 tested elements per variety, for total of 1870000 tests.\n30640 tests failed (1.64%) and 1839360 tests passed (98.36%).\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\ntest\nline_in_blue_chip_gap\nline_in_null_spectrum\nline_in_red_chip_gap\nline_off_spectrum\nnull_line_on_spectrum\n\n\n\nOBID\n\n\n\n\n\n\n\n\n\n\n3900\n162\n0\n226\n2646\n2\n3036\n\n\n3372\n144\n0\n178\n2695\n4\n3021\n\n\n3756\n161\n0\n194\n2651\n1\n3007\n\n\n3653\n165\n0\n196\n2558\n1\n2920\n\n\n3295\n141\n0\n200\n2541\n0\n2882\n\n\n3803\n164\n0\n195\n2519\n3\n2881\n\n\n3806\n165\n0\n202\n2497\n4\n2868\n\n\n3802\n158\n0\n185\n2508\n5\n2856\n\n\n3217\n37\n0\n87\n1781\n1\n1906\n\n\n3346\n22\n0\n94\n1684\n1\n1801\n\n\n3434\n37\n0\n63\n747\n0\n847\n\n\n3175\n52\n0\n44\n709\n0\n805\n\n\n3380\n32\n0\n46\n674\n0\n752\n\n\n3133\n10\n0\n22\n288\n1\n321\n\n\n3189\n20\n0\n26\n267\n2\n315\n\n\n3170\n15\n0\n37\n261\n0\n313\n\n\n3191\n5\n0\n7\n97\n0\n109\n\n\n\n\n\n\n\n\n\ntests.summary(by=\"LINE\")\n\n5 varieties of test and 374000 tested elements per variety, for total of 1870000 tests.\n30640 tests failed (1.64%) and 1839360 tests passed (98.36%).\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\ntest\nline_in_blue_chip_gap\nline_in_red_chip_gap\nline_off_spectrum\nnull_line_on_spectrum\n\n\n\nLINE\n\n\n\n\n\n\n\n\n\n[ArIII]_7135.67\n0\n55\n4343\n0\n4398\n\n\n[SII2]_6730.68\n0\n53\n3583\n0\n3636\n\n\n[SII]_6716.31\n0\n51\n3576\n0\n3627\n\n\n[NII]_6583.34\n0\n47\n3361\n0\n3408\n\n\nHa_6562.80\n0\n52\n3313\n0\n3365\n\n\n[OI]_6300.20\n0\n73\n2776\n0\n2849\n\n\nHeI_5875.60\n1\n136\n1837\n1\n1975\n\n\nHeII_3203.15\n160\n0\n1159\n2\n1321\n\n\n[NeV]_3345.81\n135\n0\n969\n0\n1104\n\n\n[NeV]_3425.81\n115\n0\n871\n1\n987\n\n\n[NI]_5197.90\n51\n118\n566\n0\n735\n\n\n[NI]_5200.39\n51\n115\n569\n0\n735\n\n\n[OIII]_5006.77\n45\n182\n200\n0\n427\n\n\n[NeIII]_3967.40\n81\n229\n0\n4\n314\n\n\n[ArIV]_4711.30\n84\n211\n0\n1\n296\n\n\nHeII_4685.74\n84\n191\n0\n0\n275\n\n\n[OIII]_4363.15\n136\n137\n0\n0\n273\n\n\nHb_4861.32\n44\n194\n0\n1\n239\n\n\n[ArIV]_4740.10\n50\n158\n0\n1\n209\n\n\n[OII]_3726.03\n178\n0\n0\n2\n180\n\n\n[OII]_3728.73\n172\n0\n0\n2\n174\n\n\n[NeIII]_3868.69\n103\n0\n0\n10\n113\n\n\n\n\n\n\n\n\n\ntests.summary(by=\"APS_ID\", top=10)\n\n5 varieties of test and 374000 tested elements per variety, for total of 1870000 tests.\n30640 tests failed (1.64%) and 1839360 tests passed (98.36%).\n\n\n\n\n\n\n\n\n\n\nfailed\ntotal fails\n\n\ntest\nline_in_blue_chip_gap\nline_in_red_chip_gap\nline_off_spectrum\nnull_line_on_spectrum\n\n\n\nAPS_ID\n\n\n\n\n\n\n\n\n\n456\n0\n5\n79\n0\n84\n\n\n766\n1\n7\n74\n0\n82\n\n\n728\n3\n3\n74\n0\n80\n\n\n989\n2\n8\n69\n0\n79\n\n\n746\n1\n1\n72\n0\n74\n\n\n40\n1\n5\n67\n0\n73\n\n\n615\n5\n15\n53\n0\n73\n\n\n62\n2\n6\n64\n0\n72\n\n\n273\n2\n3\n67\n0\n72\n\n\n308\n4\n3\n65\n0\n72",
    "crumbs": [
      "diagnostics",
      "Line flux existence check"
    ]
  }
]